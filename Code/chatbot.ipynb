{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def read_squad(path):\n",
    "    path = Path(path)\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "    #print(questions[:5])\n",
    "    return contexts, questions, answers\n",
    "\n",
    "train_contexts, train_questions, train_answers = read_squad('answers_squad_format.json')\n",
    "#val_contexts, val_questions, val_answers = read_squad('squad/dev-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Being able to assist customers remotely, service technicians could support their customers at any time and from anywhere, without necessarily having to visit the customer site. Remote access could also help to better prepare service technicians with the necessary information for their tasks. Knowing about the machine or system error in more detail beforehand saves valuable time because required spare parts or other equipment can ordered, prepared and brought along. Moreover, due to a shorter reaction time, the customer�s machines are up and running much faster, saving them from costly downtime.\\n \\nFor a machine and equipment manufacturer, using remote access also means that the same number of service technicians could support more customers or offer additional services.',\n",
       "  'answer_start': 0},\n",
       " {'text': 'Cyber-physical systems (CPS) are enabling technologies which bring the virtual and physical worlds together to create a truly networked world in which intelligent objects communicate and interact with each other. They are \"enabling technologies\" which make multiple innovative applications and processes a reality as the boundaries between the real and virtual worlds disappear. Cyber-physical systems provide the basis the creation of an Internet of Things (IoT) which makes smart services and products possible. A cyber-physical system (CPS) is a �thing� in the Internet of Things. It is a combination of mechanical, electronic and software components that communicate via a data infrastructure such as the Internet, react flexibly to external influences and exchange data with information systems and other CPSs. In manufacturing facilities, cyber-physical systems will communicate with intelligent, networked industrial production and logistics units-also known as cyber-physical production systems (CPPS). The CPSs exchange information, trigger actions in production and reciprocally control themselves autonomously. This enables industrial processes in manufacturing, engineering, use of materials, supply chain management and life cycle management to be fundamentally restructured and optimized. Currently, manufacturing data are segmented, detailed and planned for a single scope, stored within the legacy systems, thus preventing the digital continuity that would let use them in the optimal way, independently from where and how they have been collected. Cyber Physical System (CPS) will instead be able to provide the needed information from the physical world while cyber-physical-collaboration environment will enable an efficient analysis, management, sharing and usage of the data and the knowledge elaborated from them and from the experience of involved people',\n",
       "  'answer_start': 0}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_idx(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        gold_text = answer['text']\n",
    "        start_idx = answer['answer_start']\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "\n",
    "        # sometimes squad answers are off by a character or two – fix this\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            answer['answer_end'] = end_idx\n",
    "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
    "            answer['answer_start'] = start_idx - 1\n",
    "            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
    "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
    "            answer['answer_start'] = start_idx - 2\n",
    "            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
    "\n",
    "add_end_idx(train_answers, train_contexts)\n",
    "#add_end_idx(val_answers, val_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Being able to assist customers remotely, service technicians could support their customers at any time and from anywhere, without necessarily having to visit the customer site. Remote access could also help to better prepare service technicians with the necessary information for their tasks. Knowing about the machine or system error in more detail beforehand saves valuable time because required spare parts or other equipment can ordered, prepared and brought along. Moreover, due to a shorter reaction time, the customer�s machines are up and running much faster, saving them from costly downtime.\\n \\nFor a machine and equipment manufacturer, using remote access also means that the same number of service technicians could support more customers or offer additional services.',\n",
       "  'answer_start': 0,\n",
       "  'answer_end': 779},\n",
       " {'text': 'Cyber-physical systems (CPS) are enabling technologies which bring the virtual and physical worlds together to create a truly networked world in which intelligent objects communicate and interact with each other. They are \"enabling technologies\" which make multiple innovative applications and processes a reality as the boundaries between the real and virtual worlds disappear. Cyber-physical systems provide the basis the creation of an Internet of Things (IoT) which makes smart services and products possible. A cyber-physical system (CPS) is a �thing� in the Internet of Things. It is a combination of mechanical, electronic and software components that communicate via a data infrastructure such as the Internet, react flexibly to external influences and exchange data with information systems and other CPSs. In manufacturing facilities, cyber-physical systems will communicate with intelligent, networked industrial production and logistics units-also known as cyber-physical production systems (CPPS). The CPSs exchange information, trigger actions in production and reciprocally control themselves autonomously. This enables industrial processes in manufacturing, engineering, use of materials, supply chain management and life cycle management to be fundamentally restructured and optimized. Currently, manufacturing data are segmented, detailed and planned for a single scope, stored within the legacy systems, thus preventing the digital continuity that would let use them in the optimal way, independently from where and how they have been collected. Cyber Physical System (CPS) will instead be able to provide the needed information from the physical world while cyber-physical-collaboration environment will enable an efficient analysis, management, sharing and usage of the data and the knowledge elaborated from them and from the experience of involved people',\n",
       "  'answer_start': 0,\n",
       "  'answer_end': 1877},\n",
       " {'text': 'Smart sensors are a prerequisite for creating the best possible basis for a future-oriented automation system. This is because the smart factory needs data that can principally only be provided by smart, intelligent and communication-enabled sensors. Communication-enabled means being able to exchange sensor data with a machine controller or a cloud-based application. Thus, for example, sensor parameters are automatically adapted to new production orders within seconds. Or a light barrier detects contamination of its optics and reports this directly to the control center.',\n",
       "  'answer_start': 0,\n",
       "  'answer_end': 577},\n",
       " {'text': 'Smart Sensors cover up to four dimensions of Smart Sensor technology.   1. Enhanced sensing 2. Efficient communication 3. Diagnostics 4. Smart tasks',\n",
       "  'answer_start': 886,\n",
       "  'answer_end': 1034},\n",
       " {'text': ' Some of the smart features possessed by different types of actuators are:   Open standards: Multi-protocol communication interface allow universal operation with diverse, ethernet-based communication protocols Web-based commissioning and diagnostics via integrated web server Comprehensive access to actuator data (e.g. torque or power), via web connector for preventive maintenance or database interfacing and data analysis Inbuilt smart sensors for capturing data Flexible configuration according to requirement Comprehensive condition monitoring for fast identification of critical conditions and comfortable analysis Simple connection to higher-level data systems without additional hardware Workpiece-dependent parameters setting guaranteeing quality results Integrated control system with browser-based operating system allows for information sharing across multi vendor data systems',\n",
       "  'answer_start': 1116,\n",
       "  'answer_end': 2006}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "#val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2108,\n",
       " 2583,\n",
       " 2000,\n",
       " 6509,\n",
       " 6304,\n",
       " 19512,\n",
       " 1010,\n",
       " 2326,\n",
       " 20202,\n",
       " 2071,\n",
       " 2490,\n",
       " 2037,\n",
       " 6304,\n",
       " 2012,\n",
       " 2151,\n",
       " 2051,\n",
       " 1998,\n",
       " 2013,\n",
       " 5973,\n",
       " 1010,\n",
       " 2302,\n",
       " 9352,\n",
       " 2383,\n",
       " 2000,\n",
       " 3942,\n",
       " 1996,\n",
       " 8013,\n",
       " 2609,\n",
       " 1012,\n",
       " 6556,\n",
       " 3229,\n",
       " 2071,\n",
       " 2036,\n",
       " 2393,\n",
       " 2000,\n",
       " 2488,\n",
       " 7374,\n",
       " 2326,\n",
       " 20202,\n",
       " 2007,\n",
       " 1996,\n",
       " 4072,\n",
       " 2592,\n",
       " 2005,\n",
       " 2037,\n",
       " 8518,\n",
       " 1012,\n",
       " 4209,\n",
       " 2055,\n",
       " 1996,\n",
       " 3698,\n",
       " 2030,\n",
       " 2291,\n",
       " 7561,\n",
       " 1999,\n",
       " 2062,\n",
       " 6987,\n",
       " 25828,\n",
       " 13169,\n",
       " 7070,\n",
       " 2051,\n",
       " 2138,\n",
       " 3223,\n",
       " 8622,\n",
       " 3033,\n",
       " 2030,\n",
       " 2060,\n",
       " 3941,\n",
       " 2064,\n",
       " 3641,\n",
       " 1010,\n",
       " 4810,\n",
       " 1998,\n",
       " 2716,\n",
       " 2247,\n",
       " 1012,\n",
       " 9308,\n",
       " 1010,\n",
       " 2349,\n",
       " 2000,\n",
       " 1037,\n",
       " 7820,\n",
       " 4668,\n",
       " 2051,\n",
       " 1010,\n",
       " 1996,\n",
       " 6304,\n",
       " 6681,\n",
       " 2024,\n",
       " 2039,\n",
       " 1998,\n",
       " 2770,\n",
       " 2172,\n",
       " 5514,\n",
       " 1010,\n",
       " 7494,\n",
       " 2068,\n",
       " 2013,\n",
       " 17047,\n",
       " 2091,\n",
       " 7292,\n",
       " 1012,\n",
       " 2005,\n",
       " 1037,\n",
       " 3698,\n",
       " 1998,\n",
       " 3941,\n",
       " 7751,\n",
       " 1010,\n",
       " 2478,\n",
       " 6556,\n",
       " 3229,\n",
       " 2036,\n",
       " 2965,\n",
       " 2008,\n",
       " 1996,\n",
       " 2168,\n",
       " 2193,\n",
       " 1997,\n",
       " 2326,\n",
       " 20202,\n",
       " 2071,\n",
       " 2490,\n",
       " 2062,\n",
       " 6304,\n",
       " 2030,\n",
       " 3749,\n",
       " 3176,\n",
       " 2578,\n",
       " 1012,\n",
       " 1037,\n",
       " 5851,\n",
       " 6556,\n",
       " 4434,\n",
       " 2000,\n",
       " 5500,\n",
       " 10394,\n",
       " 1998,\n",
       " 3941,\n",
       " 2003,\n",
       " 2036,\n",
       " 1996,\n",
       " 3978,\n",
       " 2005,\n",
       " 2116,\n",
       " 2047,\n",
       " 8474,\n",
       " 1998,\n",
       " 2578,\n",
       " 2306,\n",
       " 3068,\n",
       " 1018,\n",
       " 1012,\n",
       " 1014,\n",
       " 2107,\n",
       " 2004,\n",
       " 16014,\n",
       " 3512,\n",
       " 6032,\n",
       " 1010,\n",
       " 2073,\n",
       " 1037,\n",
       " 5851,\n",
       " 4434,\n",
       " 2003,\n",
       " 2511,\n",
       " 2000,\n",
       " 8145,\n",
       " 2951,\n",
       " 2013,\n",
       " 6681,\n",
       " 1010,\n",
       " 3941,\n",
       " 2030,\n",
       " 5733,\n",
       " 1012,\n",
       " 1996,\n",
       " 2951,\n",
       " 2003,\n",
       " 2084,\n",
       " 16578,\n",
       " 1998,\n",
       " 2109,\n",
       " 2000,\n",
       " 11487,\n",
       " 10697,\n",
       " 1998,\n",
       " 2825,\n",
       " 15428,\n",
       " 2012,\n",
       " 2019,\n",
       " 2220,\n",
       " 2754,\n",
       " 2000,\n",
       " 4468,\n",
       " 4895,\n",
       " 24759,\n",
       " 20147,\n",
       " 2094,\n",
       " 2091,\n",
       " 7292,\n",
       " 1012,\n",
       " 102,\n",
       " 4863,\n",
       " 6556,\n",
       " 6032,\n",
       " 1029,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] being able to assist customers remotely, service technicians could support their customers at any time and from anywhere, without necessarily having to visit the customer site. remote access could also help to better prepare service technicians with the necessary information for their tasks. knowing about the machine or system error in more detail beforehand saves valuable time because required spare parts or other equipment can ordered, prepared and brought along. moreover, due to a shorter reaction time, the customers machines are up and running much faster, saving them from costly downtime. for a machine and equipment manufacturer, using remote access also means that the same number of service technicians could support more customers or offer additional services. a secure remote connection to distributed machinery and equipment is also the basis for many new concepts and services within industry 4. 0 such as predictive maintenance, where a secure connection is established to collect data from machines, equipment or devices. the data is than analyzed and used to detect errors and possible failures at an early stage to avoid unplanned downtime. [SEP] explain remote maintenance? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_encodings['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.char_to_token(0, train_answers[0]['answer_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "        # if None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        go_back=1\n",
    "        while end_positions[-1] is None:\n",
    "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - go_back)\n",
    "            go_back+=1\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "#add_token_positions(val_encodings, val_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 148, 512, 1, 512, 323, 1, 512]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings['start_positions'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "#val_dataset = SquadDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.SquadDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForQuestionAnswering\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm \n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3/3 [11:58<00:00, 239.51s/it, loss=<built-in method item of Tensor object at 0x0000009135C04E00>]\n",
      "Epoch 1: 100%|██████████| 3/3 [11:09<00:00, 223.10s/it, loss=<built-in method item of Tensor object at 0x00000091350F2110>]\n",
      "Epoch 2: 100%|██████████| 3/3 [11:07<00:00, 222.51s/it, loss=<built-in method item of Tensor object at 0x000000913501B650>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(3):\n",
    "    loop=tqdm(train_loader)\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model/distilbert-custom\\\\tokenizer_config.json',\n",
       " 'model/distilbert-custom\\\\special_tokens_map.json',\n",
       " 'model/distilbert-custom\\\\vocab.txt',\n",
       " 'model/distilbert-custom\\\\added_tokens.json',\n",
       " 'model/distilbert-custom\\\\tokenizer.json')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path='model/distilbert-custom'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_answer(tokenizer, question, context):\n",
    "#   inputs = tokenizer([question], [context])\n",
    "#   outputs = model(inputs_ids,attention_mask=attention mask)\n",
    "#   start_position = torch.argmax(outputs['start_logits'], dim=1)\n",
    "#   end_position = torch.argmax(outputs['end_logits'], dim=1)\n",
    "#   answer = inputs[\"input_ids\"][0, int(start_position) : int(end_position) + 1]\n",
    "#   return tokenizer.decode(answer).strip()\n",
    "def get_answer(question, context):\n",
    "    inputs = tokenizer.encode_plus(question, context, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        output_start, output_end = model(**inputs)\n",
    "        \n",
    "        answer_start = torch.argmax(output_start)  \n",
    "        answer_end = torch.argmax(output_end) \n",
    "\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "\n",
    "        return(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m context\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe Foundation of Smart Manufacturing at the Indian Institute of Technology (IIT) is a research and development center dedicated to advancing the field of smart manufacturing in India. IITs are a group of autonomous technical institutions established by the Indian government to promote higher education and research in information technology.The Foundation of Smart Manufacturing focuses on integrating information technology and manufacturing processes to create intelligent and efficient manufacturing systems.Its primary goal is to develop and implement cutting-edge technologies to enhance the productivity, quality, and sustainability of Indian manufacturing industries.During the months of June-July 2021, FSM organized a Summer Online Internship.900+ applications were received and 150+ students were accepted for internships in various domains such as Augmented Reality, Machine Learning, Automation, IIoT, Realtime Dashboards, and Robotics. More than 45 projects were conceptualized and completed during the internship and 20+ Research Papers were prepared by the interns.The FSM Masterclass Series was a 4-month program, having 4 different masterclasses for technologies such as \u001b[39m\u001b[39m\\u201c\u001b[39;00m\u001b[39mAugmented Reality\u001b[39m\u001b[39m\\u201d\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m\\u201c\u001b[39;00m\u001b[39mMachine Learning\u001b[39m\u001b[39m\\u201d\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\\u201c\u001b[39;00m\u001b[39mAutomation\u001b[39m\u001b[39m\\u201d\u001b[39;00m\u001b[39m, and \u001b[39m\u001b[39m\\u201c\u001b[39;00m\u001b[39mIIot\u001b[39m\u001b[39m\\u201d\u001b[39;00m\u001b[39m.The program was attended by college students, college professors and employees from various industries. Each course was a month-long program, consisting of 4 live classes, 4 hands-on lab sessions, e-learning modules and 1 major project.Masterclass Series reviews\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m question\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWhat is Foundation of Smart Manufacturing?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicted Answer: \u001b[39m\u001b[39m{\u001b[39;00mget_answer(question,\u001b[39m \u001b[39;49mcontext)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m#input_ids=test_encodings['input_ids'].to(device)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m#outputs=model(test_encodings['input_ids'],test_encodings['attention_mask'])\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[144], line 13\u001b[0m, in \u001b[0;36mget_answer\u001b[1;34m(question, context)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     11\u001b[0m     output_start, output_end \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[1;32m---> 13\u001b[0m     answer_start \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49margmax(output_start)  \n\u001b[0;32m     14\u001b[0m     answer_end \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(output_end) \n\u001b[0;32m     16\u001b[0m     answer \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mconvert_tokens_to_string(tokenizer\u001b[39m.\u001b[39mconvert_ids_to_tokens(inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][answer_start:answer_end]))\n",
      "\u001b[1;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "context=\"The Foundation of Smart Manufacturing at the Indian Institute of Technology (IIT) is a research and development center dedicated to advancing the field of smart manufacturing in India. IITs are a group of autonomous technical institutions established by the Indian government to promote higher education and research in information technology.The Foundation of Smart Manufacturing focuses on integrating information technology and manufacturing processes to create intelligent and efficient manufacturing systems.Its primary goal is to develop and implement cutting-edge technologies to enhance the productivity, quality, and sustainability of Indian manufacturing industries.During the months of June-July 2021, FSM organized a Summer Online Internship.900+ applications were received and 150+ students were accepted for internships in various domains such as Augmented Reality, Machine Learning, Automation, IIoT, Realtime Dashboards, and Robotics. More than 45 projects were conceptualized and completed during the internship and 20+ Research Papers were prepared by the interns.The FSM Masterclass Series was a 4-month program, having 4 different masterclasses for technologies such as \\u201cAugmented Reality\\u201d,\\u201cMachine Learning\\u201d, \\u201cAutomation\\u201d, and \\u201cIIot\\u201d.The program was attended by college students, college professors and employees from various industries. Each course was a month-long program, consisting of 4 live classes, 4 hands-on lab sessions, e-learning modules and 1 major project.Masterclass Series reviews\"\n",
    "question=\"What is Foundation of Smart Manufacturing?\"\n",
    "print(f\"Predicted Answer: {get_answer(question, context)}\")\n",
    "#input_ids=test_encodings['input_ids'].to(device)\n",
    "#outputs=model(test_encodings['input_ids'],test_encodings['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m attention_mask \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m \u001b[39m#start_positions = batch['start_positions'].to(device)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m#end_positions = batch['end_positions'].to(device)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m,outputs[\u001b[39m'\u001b[39m\u001b[39mstart_logits\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(outputs[\u001b[39m'\u001b[39m\u001b[39mend_logits\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:885\u001b[0m, in \u001b[0;36mDistilBertForQuestionAnswering.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[39mstart_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[39m    Labels for position (index) of the start of the labelled span for computing the token classification loss.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[39m    are not taken into account for computing the loss.\u001b[39;00m\n\u001b[0;32m    882\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    883\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m--> 885\u001b[0m distilbert_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistilbert(\n\u001b[0;32m    886\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m    887\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    888\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    889\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    890\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    891\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    892\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    893\u001b[0m )\n\u001b[0;32m    894\u001b[0m hidden_states \u001b[39m=\u001b[39m distilbert_output[\u001b[39m0\u001b[39m]  \u001b[39m# (bs, max_query_len, dim)\u001b[39;00m\n\u001b[0;32m    896\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)  \u001b[39m# (bs, max_query_len, dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:581\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    579\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 581\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(input_ids, inputs_embeds)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(\n\u001b[0;32m    584\u001b[0m     x\u001b[39m=\u001b[39membeddings,\n\u001b[0;32m    585\u001b[0m     attn_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m    590\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:135\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[1;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[0;32m    131\u001b[0m     position_ids \u001b[39m=\u001b[39m position_ids\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mexpand_as(input_ids)  \u001b[39m# (bs, max_seq_length)\u001b[39;00m\n\u001b[0;32m    133\u001b[0m position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m embeddings \u001b[39m=\u001b[39m input_embeds \u001b[39m+\u001b[39;49m position_embeddings  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    137\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# \n",
    "def get_answer(question, context):\n",
    "    inputs = tokenizer.encode_plus(question, context, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        output_start, output_end = model(**inputs)\n",
    "        \n",
    "        answer_start = torch.argmax(output_start)  \n",
    "        answer_end = torch.argmax(output_end) \n",
    "\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "\n",
    "        return(answer)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer and model successfully initialized.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model1 = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "print(\"Tokenizer and model successfully initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_logits\n",
      "end_logits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#question, passage,\n",
    "#def distilbert_question_answer( max_len=500):\n",
    "passage=\"\"\"Contact us for Call us for any query011-26582053, 8076197190 or email us oninfo@iafsm.in. The program is entirely online and will run full-time from June 1, 2023, to July 31, 2023, for a duration of two months. The focus of the internship is on the theme of 'Smart Factory,' which is a rapidly growing industry. This internship program is an excellent chance for individuals to gain valuable knowledge and experience in this field. It is an excellent opportunity for those who are looking to expand their skills and gain practical experience in this exciting area. If you are interested, don't miss this chance to be a part of the program and enhance your career prospects.. Foundation for Smart Manufacturing (FSM) helps, supports, and develops Smart Manufacturing concepts for Indian Industry to witness, ideate, and try out in their plants. FSM also aims for a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment. FSM Skills is a holistic platform for providing immersive training experience through Live lectures, Online learning, Live demonstrations, Live Labs & Self paced exercises on remotely accessible actual hardware. FSM is focussed on enabling people from becoming Smart to Samarth (capable) fraternity by creating awareness, step-wise learning and becoming an expert from domains driving Industry 4.0. Academic strength of IIT Delhi brought interdisciplinary learnings to FSM. Expert Faculty members from various departments contribute to it. FSM has highly trained manpower to implement the Industry 4.0 projects in guidance with experienced faculty members and industry partners. M.Tech and Ph.D students doing research in Smart manufacturing are contributing to FSM technologies and increase its knowledgebase. FSM brought industry partners from MNCs operating all across the globe to bring rich experience in the smart manufacturing technologies. Automation Industries Association (AIA) in its quest to set up a Common Engineering Facility Center (CEFC) at IIT Delhi has brought together experts from various industries in the sector of automation. These experts look forward to work together and use their industrial experience along with various verticals to initiate smart manufacturing in India. The following firms have agreed to come together to set up the CEFC. They comprise Technology & Investment Partners, Simulation &amp; Integration Partners and Machinery Partners. under Samarth Udyog Mission of the Ministry of Heavy Industry , Govt. of India, IIT Delhi, and Automation Industry Association (AIA) together with Industry sponsors have set up common engineering facilities under the aegis of the IITD - AIA Foundation for Smart Manufacturing (FSM). These facilities are meant to demonstrate, support, and develop Smart Manufacturing concepts for Indian Industry & try them out in their own plants. The collaboration is also aimed at developing a holistic educational curriculum and skill-building program through a vibrant incubation and administrative .We are happy to inform that on December 22, 2022, IITD-AIA Foundation For Smart Manufacturing presented various industry 4.0 technologies at Workshop on Automation for Smart Manufacturing organized by Automation Industry Association in Pune. Visitors were given Live Demonstrations of technologies created for smart manufacturing in the cyber-physical lab at the Indian Institute of Technology, Delhi\"\"\"\n",
    "question =\"What are details of Internship 2023? \"\n",
    "max_len=500\n",
    "inputs = tokenizer.encode_plus(question, passage, add_special_tokens=True, max_length=max_len, truncation=True, return_tensors='pt',return_attention_mask=True)\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "start_scores, end_scores = model1(input_ids, attention_mask=attention_mask)\n",
    "print(start_scores)\n",
    "print(end_scores)\n",
    "    # start_scores = start_scores.cpu().numpy().flatten()\n",
    "    # end_scores = end_scores.cpu().numpy().flatten()\n",
    "\n",
    "    # answer_start_index = np.argmax(start_scores)\n",
    "    # answer_end_index = np.argmax(end_scores)\n",
    "\n",
    "    # tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "    # answer = tokens[answer_start_index]\n",
    "\n",
    "    # for i in range(answer_start_index + 1, answer_end_index + 1):\n",
    "    #     if tokens[i][0:2] == '##':\n",
    "    #         answer += tokens[i][2:]\n",
    "    #     else:\n",
    "    #         answer += ' ' + tokens[i]\n",
    "\n",
    "    # start_token_score = np.round(start_scores[answer_start_index], 2)\n",
    "    # end_token_score = np.round(end_scores[answer_end_index], 2)\n",
    "\n",
    "    # if (\n",
    "    #     answer_start_index == 0\n",
    "    #     or start_token_score < 0\n",
    "    #     or answer == '[SEP]'\n",
    "    #     or answer_end_index < answer_start_index\n",
    "    # ):\n",
    "    #     answer = \"Sorry, I could not find an answer in the passage.\"\n",
    "\n",
    "    # return answer_start_index, answer_end_index, start_token_score, end_token_score, answer\n",
    "    #return start_scores,end_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#\n",
    "def distilbert_question_answer( question, passage,max_len=500):\n",
    "# passage=\"\"\"Contact us for Call us for any query011-26582053, 8076197190 or email us oninfo@iafsm.in. The program is entirely online and will run full-time from June 1, 2023, to July 31, 2023, for a duration of two months. The focus of the internship is on the theme of 'Smart Factory,' which is a rapidly growing industry. This internship program is an excellent chance for individuals to gain valuable knowledge and experience in this field. It is an excellent opportunity for those who are looking to expand their skills and gain practical experience in this exciting area. If you are interested, don't miss this chance to be a part of the program and enhance your career prospects.. Foundation for Smart Manufacturing (FSM) helps, supports, and develops Smart Manufacturing concepts for Indian Industry to witness, ideate, and try out in their plants. FSM also aims for a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment. FSM Skills is a holistic platform for providing immersive training experience through Live lectures, Online learning, Live demonstrations, Live Labs & Self paced exercises on remotely accessible actual hardware. FSM is focussed on enabling people from becoming Smart to Samarth (capable) fraternity by creating awareness, step-wise learning and becoming an expert from domains driving Industry 4.0. Academic strength of IIT Delhi brought interdisciplinary learnings to FSM. Expert Faculty members from various departments contribute to it. FSM has highly trained manpower to implement the Industry 4.0 projects in guidance with experienced faculty members and industry partners. M.Tech and Ph.D students doing research in Smart manufacturing are contributing to FSM technologies and increase its knowledgebase. FSM brought industry partners from MNCs operating all across the globe to bring rich experience in the smart manufacturing technologies. Automation Industries Association (AIA) in its quest to set up a Common Engineering Facility Center (CEFC) at IIT Delhi has brought together experts from various industries in the sector of automation. These experts look forward to work together and use their industrial experience along with various verticals to initiate smart manufacturing in India. The following firms have agreed to come together to set up the CEFC. They comprise Technology & Investment Partners, Simulation &amp; Integration Partners and Machinery Partners. under Samarth Udyog Mission of the Ministry of Heavy Industry , Govt. of India, IIT Delhi, and Automation Industry Association (AIA) together with Industry sponsors have set up common engineering facilities under the aegis of the IITD - AIA Foundation for Smart Manufacturing (FSM). These facilities are meant to demonstrate, support, and develop Smart Manufacturing concepts for Indian Industry & try them out in their own plants. The collaboration is also aimed at developing a holistic educational curriculum and skill-building program through a vibrant incubation and administrative .We are happy to inform that on December 22, 2022, IITD-AIA Foundation For Smart Manufacturing presented various industry 4.0 technologies at Workshop on Automation for Smart Manufacturing organized by Automation Industry Association in Pune. Visitors were given Live Demonstrations of technologies created for smart manufacturing in the cyber-physical lab at the Indian Institute of Technology, Delhi\"\"\"\n",
    "# question =\"What are details of Internship 2023? \"\n",
    "# max_len=500\n",
    "    inputs = tokenizer.encode_plus(question, passage, add_special_tokens=True, max_length=max_len, truncation=True, return_tensors='pt',return_attention_mask=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    start_scores, end_scores = model1(input_ids, attention_mask=attention_mask)\n",
    "    print(start_scores)\n",
    "    print(end_scores)\n",
    "    start_scores = start_scores.cpu().numpy().flatten()\n",
    "    end_scores = end_scores.cpu().numpy().flatten()\n",
    "\n",
    "    answer_start_index = np.argmax(start_scores)\n",
    "    answer_end_index = np.argmax(end_scores)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "    answer = tokens[answer_start_index]\n",
    "\n",
    "    for i in range(answer_start_index + 1, answer_end_index + 1):\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "\n",
    "    start_token_score = np.round(start_scores[answer_start_index], 2)\n",
    "    end_token_score = np.round(end_scores[answer_end_index], 2)\n",
    "\n",
    "    if (\n",
    "        answer_start_index == 0\n",
    "        or start_token_score < 0\n",
    "        or answer == '[SEP]'\n",
    "        or answer_end_index < answer_start_index\n",
    "    ):\n",
    "        answer = \"Sorry, I could not find an answer in the passage.\"\n",
    "\n",
    "    return answer_start_index, answer_end_index, start_token_score, end_token_score, answer\n",
    "    #return start_scores,end_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the passage: 511 words\n"
     ]
    }
   ],
   "source": [
    "passage=\"\"\"Contact us for Call us for any query011-26582053, 8076197190 or email us oninfo@iafsm.in. The program is entirely online and will run full-time from June 1, 2023, to July 31, 2023, for a duration of two months. The focus of the internship is on the theme of 'Smart Factory,' which is a rapidly growing industry. This internship program is an excellent chance for individuals to gain valuable knowledge and experience in this field. It is an excellent opportunity for those who are looking to expand their skills and gain practical experience in this exciting area. If you are interested, don't miss this chance to be a part of the program and enhance your career prospects.. Foundation for Smart Manufacturing (FSM) helps, supports, and develops Smart Manufacturing concepts for Indian Industry to witness, ideate, and try out in their plants. FSM also aims for a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment. FSM Skills is a holistic platform for providing immersive training experience through Live lectures, Online learning, Live demonstrations, Live Labs & Self paced exercises on remotely accessible actual hardware. FSM is focussed on enabling people from becoming Smart to Samarth (capable) fraternity by creating awareness, step-wise learning and becoming an expert from domains driving Industry 4.0. Academic strength of IIT Delhi brought interdisciplinary learnings to FSM. Expert Faculty members from various departments contribute to it. FSM has highly trained manpower to implement the Industry 4.0 projects in guidance with experienced faculty members and industry partners. M.Tech and Ph.D students doing research in Smart manufacturing are contributing to FSM technologies and increase its knowledgebase. FSM brought industry partners from MNCs operating all across the globe to bring rich experience in the smart manufacturing technologies. Automation Industries Association (AIA) in its quest to set up a Common Engineering Facility Center (CEFC) at IIT Delhi has brought together experts from various industries in the sector of automation. These experts look forward to work together and use their industrial experience along with various verticals to initiate smart manufacturing in India. The following firms have agreed to come together to set up the CEFC. They comprise Technology & Investment Partners, Simulation &amp; Integration Partners and Machinery Partners. under Samarth Udyog Mission of the Ministry of Heavy Industry , Govt. of India, IIT Delhi, and Automation Industry Association (AIA) together with Industry sponsors have set up common engineering facilities under the aegis of the IITD - AIA Foundation for Smart Manufacturing (FSM). These facilities are meant to demonstrate, support, and develop Smart Manufacturing concepts for Indian Industry & try them out in their own plants. The collaboration is also aimed at developing a holistic educational curriculum and skill-building program through a vibrant incubation and administrative .We are happy to inform that on December 22, 2022, IITD-AIA Foundation For Smart Manufacturing presented various industry 4.0 technologies at Workshop on Automation for Smart Manufacturing organized by Automation Industry Association in Pune. Visitors were given Live Demonstrations of technologies created for smart manufacturing in the cyber-physical lab at the Indian Institute of Technology, Delhi\"\"\"\n",
    "print (f'Length of the passage: {len(passage.split())} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_logits\n",
      "end_logits\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m question \u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWhat are details of Internship 2023? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m answer_tuple \u001b[39m=\u001b[39m distilbert_question_answer(question, passage)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(answer_tuple)\n\u001b[0;32m      5\u001b[0m \u001b[39m# answer = answer_tuple[-1]  # Extract the answer string from the tuple\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[39m# print(\"Question:\", question)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# print(\"Answer:\", answer)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[56], line 14\u001b[0m, in \u001b[0;36mdistilbert_question_answer\u001b[1;34m(question, passage, max_len)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(start_scores)\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(end_scores)\n\u001b[1;32m---> 14\u001b[0m start_scores \u001b[39m=\u001b[39m start_scores\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     15\u001b[0m end_scores \u001b[39m=\u001b[39m end_scores\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     17\u001b[0m answer_start_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(start_scores)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "question =\"What are details of Internship 2023? \"\n",
    "\n",
    "answer_tuple = distilbert_question_answer(question, passage)\n",
    "print(answer_tuple)\n",
    "# answer = answer_tuple[-1]  # Extract the answer string from the tuple\n",
    "\n",
    "# print(\"Question:\", question)\n",
    "# print(\"Answer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
