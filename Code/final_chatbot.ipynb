{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "model_path = 'model/distilbert-custom'\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy with small context of size 512**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"The Foundation of Smart Manufacturing at the Indian Institute of Technology (IIT) is a research and development center dedicated to advancing the field of smart manufacturing in India. IITs are a group of autonomous technical institutions established by the Indian government to promote higher education and research in information technology.The Foundation of Smart Manufacturing focuses on integrating information technology and manufacturing processes to create intelligent and efficient manufacturing systems.Its primary goal is to develop and implement cutting-edge technologies to enhance the productivity, quality, and sustainability of Indian manufacturing industries.During the months of June-July 2021, FSM organized a Summer Online Internship.900+ applications were received and 150+ students were accepted for internships in various domains such as Augmented Reality, Machine Learning, Automation, IIoT, Realtime Dashboards, and Robotics. More than 45 projects were conceptualized and completed during the internship and 20+ Research Papers were prepared by the interns.The FSM Masterclass Series was a 4-month program, having 4 different masterclasses for technologies such as \\u201cAugmented Reality\\u201d,\\u201cMachine Learning\\u201d, \\u201cAutomation\\u201d, and \\u201cIIot\\u201d.The program was attended by college students, college professors and employees from various industries. Each course was a month-long program, consisting of 4 live classes, 4 hands-on lab sessions, e-learning modules and 1 major project.Masterclass Series reviews\"\n",
    "question=\"What is iit?\"\n",
    "inputs = tokenizer.encode_plus(question, context, truncation=True, padding=True, return_tensors='pt')\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "print(tokenizer.decode(input_ids[0])) # format of tokenizer with special tokens after tokenizing \n",
    "print(attention_mask[0]) # 1 if the words are relevant and 0 in order to make context size of 512 if it is less\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids, attention_mask=attention_mask) # model calling which is fine-tuned\n",
    "\n",
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the answer of question has all the process as explained above\n",
    "def get_answers(question, context):\n",
    "    inputs = tokenizer.encode_plus(question, context, truncation=True, padding=True, return_tensors='pt')\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "     \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"The Foundation of Smart Manufacturing at the Indian Institute of Technology (IIT) is a research and development center dedicated to advancing the field of smart manufacturing in India. IITs are a group of autonomous technical institutions established by the Indian government to promote higher education and research in information technology.The Foundation of Smart Manufacturing focuses on integrating information technology and manufacturing processes to create intelligent and efficient manufacturing systems.Its primary goal is to develop and implement cutting-edge technologies to enhance the productivity, quality, and sustainability of Indian manufacturing industries.During the months of June-July 2021, FSM organized a Summer Online Internship.900+ applications were received and 150+ students were accepted for internships in various domains such as Augmented Reality, Machine Learning, Automation, IIoT, Realtime Dashboards, and Robotics. More than 45 projects were conceptualized and completed during the internship and 20+ Research Papers were prepared by the interns.The FSM Masterclass Series was a 4-month program, having 4 different masterclasses for technologies such as \\u201cAugmented Reality\\u201d,\\u201cMachine Learning\\u201d, \\u201cAutomation\\u201d, and \\u201cIIot\\u201d.The program was attended by college students, college professors and employees from various industries. Each course was a month-long program, consisting of 4 live classes, 4 hands-on lab sessions, e-learning modules and 1 major project.Masterclass Series reviews\"\n",
    "question=\"What is fsm masterclass?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\") # calling of function get_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"The Foundation of Smart Manufacturing at the Indian Institute of Technology (IIT) is a research and development center dedicated to advancing the field of smart manufacturing in India. IITs are a group of autonomous technical institutions established by the Indian government to promote higher education and research in information technology.The Foundation of Smart Manufacturing focuses on integrating information technology and manufacturing processes to create intelligent and efficient manufacturing systems.Its primary goal is to develop and implement cutting-edge technologies to enhance the productivity, quality, and sustainability of Indian manufacturing industries.During the months of June-July 2021, FSM organized a Summer Online Internship.900+ applications were received and 150+ students were accepted for internships in various domains such as Augmented Reality, Machine Learning, Automation, IIoT, Realtime Dashboards, and Robotics. More than 45 projects were conceptualized and completed during the internship and 20+ Research Papers were prepared by the interns.The FSM Masterclass Series was a 4-month program, having 4 different masterclasses for technologies such as \\u201cAugmented Reality\\u201d,\\u201cMachine Learning\\u201d, \\u201cAutomation\\u201d, and \\u201cIIot\\u201d.The program was attended by college students, college professors and employees from various industries. Each course was a month-long program, consisting of 4 live classes, 4 hands-on lab sessions, e-learning modules and 1 major project.Masterclass Series reviews\"\n",
    "question=\"Explain foundation for smart manufacturing?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"The Foundation of Smart Manufacturing at the Indian Institute of Technology (IIT) is a research and development center dedicated to advancing the field of smart manufacturing in India. IITs are a group of autonomous technical institutions established by the Indian government to promote higher education and research in information technology.The Foundation of Smart Manufacturing focuses on integrating information technology and manufacturing processes to create intelligent and efficient manufacturing systems.Its primary goal is to develop and implement cutting-edge technologies to enhance the productivity, quality, and sustainability of Indian manufacturing industries.During the months of June-July 2021, FSM organized a Summer Online Internship.900+ applications were received and 150+ students were accepted for internships in various domains such as Augmented Reality, Machine Learning, Automation, IIoT, Realtime Dashboards, and Robotics. More than 45 projects were conceptualized and completed during the internship and 20+ Research Papers were prepared by the interns.The FSM Masterclass Series was a 4-month program, having 4 different masterclasses for technologies such as \\u201cAugmented Reality\\u201d,\\u201cMachine Learning\\u201d, \\u201cAutomation\\u201d, and \\u201cIIot\\u201d.The program was attended by college students, college professors and employees from various industries. Each course was a month-long program, consisting of 4 live classes, 4 hands-on lab sessions, e-learning modules and 1 major project.Masterclass Series reviews\"\n",
    "question=\"Explain internship 2023?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"The Foundation of Smart Manufacturing at the Indian Institute of Technology (IIT) is a research and development center dedicated to advancing the field of smart manufacturing in India. IITs are a group of autonomous technical institutions established by the Indian government to promote higher education and research in information technology.The Foundation of Smart Manufacturing focuses on integrating information technology and manufacturing processes to create intelligent and efficient manufacturing systems.Its primary goal is to develop and implement cutting-edge technologies to enhance the productivity, quality, and sustainability of Indian manufacturing industries.During the months of June-July 2021, FSM organized a Summer Online Internship.900+ applications were received and 150+ students were accepted for internships in various domains such as Augmented Reality, Machine Learning, Automation, IIoT, Realtime Dashboards, and Robotics. More than 45 projects were conceptualized and completed during the internship and 20+ Research Papers were prepared by the interns.The FSM Masterclass Series was a 4-month program, having 4 different masterclasses for technologies such as \\u201cAugmented Reality\\u201d,\\u201cMachine Learning\\u201d, \\u201cAutomation\\u201d, and \\u201cIIot\\u201d.The program was attended by college students, college professors and employees from various industries. Each course was a month-long program, consisting of 4 live classes, 4 hands-on lab sessions, e-learning modules and 1 major project.Masterclass Series reviews\"\n",
    "question=\"What are the process of internship ?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"Contact us today for implementing Call us for any query011-26582053, 8076197190 or email us oninfo@iafsm.in. The program is entirely online and will run full-time from June 1, 2023, to July 31, 2023, for a duration of two months. The focus of the internship is on the theme of 'Smart Factory,' which is a rapidly growing industry. This internship program is an excellent chance for individuals to gain valuable knowledge and experience in this field. It is an excellent opportunity for those who are looking to expand their skills and gain practical experience in this exciting area. If you are interested, don't miss this chance to be a part of the program and enhance your career prospects.. Foundation for Smart Manufacturing (FSM) helps, supports, and develops Smart Manufacturing concepts for Indian Industry to witness, ideate, and try out in their plants. FSM also aims for a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment. FSM Skills is a holistic platform for providing immersive training experience through Live lectures, Online learning, Live demonstrations, Live Labs & Self paced exercises on remotely accessible actual hardware. FSM is focussed on enabling people from becoming Smart to Samarth (capable) fraternity by creating awareness, step-wise learning and becoming an expert from domains driving Industry 4.0. Academic strength of IIT Delhi brought interdisciplinary learnings to FSM. Expert Faculty members from various departments contribute to it. FSM has highly trained manpower to implement the Industry 4.0 projects in guidance with experienced faculty members and industry partners. M.Tech and Ph.D students doing research in Smart manufacturing are contributing to FSM technologies and increase its knowledgebase. FSM brought industry partners from MNCs operating all across the globe to bring rich experience in the smart manufacturing technologies. Automation Industries Association (AIA) in its quest to set up a Common Engineering Facility Center (CEFC) at IIT Delhi has brought together experts from various industries in the sector of automation. These experts look forward to work together and use their industrial experience along with various verticals to initiate smart manufacturing in India. The following firms have agreed to come together to set up the CEFC. They comprise Technology & Investment Partners, Simulation &amp; Integration Partners and Machinery Partners. Contact us today for implementing. Call us for any query011-26582053, 8076197190 or email us oninfo@iafsm.in. Under Samarth Udyog Mission of the Ministry of Heavy Industry (MHI), Govt. of India, IIT Delhi, and Automation Industry Association (AIA) together with Industry sponsors have set up common engineering facilities under the aegis of the IITD - AIA Foundation for Smart Manufacturing (FSM). These facilities are meant to demonstrate, support, and develop Smart Manufacturing concepts for Indian Industry & try them out in their own plants. \"\n",
    "question=\"What is Foundation of Smart Manufacturing?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "context=\"Contact us today for implementing Call us for any query011-26582053, 8076197190 or email us oninfo@iafsm.in. The program is entirely online and will run full-time from June 1, 2023, to July 31, 2023, for a duration of two months. The focus of the internship is on the theme of 'Smart Factory,' which is a rapidly growing industry. This internship program is an excellent chance for individuals to gain valuable knowledge and experience in this field. It is an excellent opportunity for those who are looking to expand their skills and gain practical experience in this exciting area. If you are interested, don't miss this chance to be a part of the program and enhance your career prospects.. Foundation for Smart Manufacturing (FSM) helps, supports, and develops Smart Manufacturing concepts for Indian Industry to witness, ideate, and try out in their plants. FSM also aims for a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment. FSM Skills is a holistic platform for providing immersive training experience through Live lectures, Online learning, Live demonstrations, Live Labs & Self paced exercises on remotely accessible actual hardware. FSM is focussed on enabling people from becoming Smart to Samarth (capable) fraternity by creating awareness, step-wise learning and becoming an expert from domains driving Industry 4.0. Academic strength of IIT Delhi brought interdisciplinary learnings to FSM. Expert Faculty members from various departments contribute to it. FSM has highly trained manpower to implement the Industry 4.0 projects in guidance with experienced faculty members and industry partners. M.Tech and Ph.D students doing research in Smart manufacturing are contributing to FSM technologies and increase its knowledgebase. FSM brought industry partners from MNCs operating all across the globe to bring rich experience in the smart manufacturing technologies. Automation Industries Association (AIA) in its quest to set up a Common Engineering Facility Center (CEFC) at IIT Delhi has brought together experts from various industries in the sector of automation. These experts look forward to work together and use their industrial experience along with various verticals to initiate smart manufacturing in India. The following firms have agreed to come together to set up the CEFC. They comprise Technology & Investment Partners, Simulation &amp; Integration Partners and Machinery Partners. Contact us today for implementing. Call us for any query011-26582053, 8076197190 or email us oninfo@iafsm.in. Under Samarth Udyog Mission of the Ministry of Heavy Industry (MHI), Govt. of India, IIT Delhi, and Automation Industry Association (AIA) together with Industry sponsors have set up common engineering facilities under the aegis of the IITD - AIA Foundation for Smart Manufacturing (FSM). These facilities are meant to demonstrate, support, and develop Smart Manufacturing concepts for Indian Industry & try them out in their own plants. \"\n",
    "question=\"What are contact information ?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"IITD-AIA Foundation For Smart Manufacturing is delighted to announce the successful conclusion of our week long training program titled 'Competency Building in Industry 4.0' for industry experts from Hindustan Aeronautics Limited (HAL) in the field of smartmanufacturing. HAL has entrusted us with the task of upskilling their experts from various domains. Our carefully crafted learning sessions provided valuable insights into the major domains of Industry 4.0. Including Automation, IIoT, AugmentedReality, Robotics, AI, MLIITD-AIA Foundation For Smart Manufacturing got an opportunity to be a part of G20 Digital Economy Working Group (DEWG) in Lucknow hosted by UP Government. These type of events helps all the segments of nation like Politicians, Economic dignitaries, Business leader, Entrepreneurs, Industry Associates etc. to come on a common platform and take nation towards a bright and better future and we are proud to be participating and showcasing live demonstrations of our work to the visitors.We are happy to inform that on December 22, 2022, IITD-AIA Foundation For Smart Manufacturing presented various industry 4.0 technologies at Workshop on Automation for Smart Manufacturing organized by Automation Industry Association in Pune. Visitors were given Live Demonstrations of technologies created for smart manufacturing in the cyber-physical lab at the Indian Institute of Technology, Delhi. Here are some of the day's highlights. \"\n",
    "question=\"What on December 22, 2022?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"IITD-AIA Foundation For Smart Manufacturing is delighted to announce the successful conclusion of our week long training program titled 'Competency Building in Industry 4.0' for industry experts from Hindustan Aeronautics Limited (HAL) in the field of smartmanufacturing. HAL has entrusted us with the task of upskilling their experts from various domains. Our carefully crafted learning sessions provided valuable insights into the major domains of Industry 4.0. Including Automation, IIoT, AugmentedReality, Robotics, AI, MLIITD-AIA Foundation For Smart Manufacturing got an opportunity to be a part of G20 Digital Economy Working Group (DEWG) in Lucknow hosted by UP Government. These type of events helps all the segments of nation like Politicians, Economic dignitaries, Business leader, Entrepreneurs, Industry Associates etc. to come on a common platform and take nation towards a bright and better future and we are proud to be participating and showcasing live demonstrations of our work to the visitors.We are happy to inform that on December 22, 2022, IITD-AIA Foundation For Smart Manufacturing presented various industry 4.0 technologies at Workshop on Automation for Smart Manufacturing organized by Automation Industry Association in Pune. Visitors were given Live Demonstrations of technologies created for smart manufacturing in the cyber-physical lab at the Indian Institute of Technology, Delhi. Here are some of the day's highlights. \"\n",
    "question=\"what is DEWG?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"IITD-AIA Foundation For Smart Manufacturing is delighted to announce the successful conclusion of our week long training program titled 'Competency Building in Industry 4.0' for industry experts from Hindustan Aeronautics Limited (HAL) in the field of smartmanufacturing. HAL has entrusted us with the task of upskilling their experts from various domains. Our carefully crafted learning sessions provided valuable insights into the major domains of Industry 4.0. Including Automation, IIoT, AugmentedReality, Robotics, AI, MLIITD-AIA Foundation For Smart Manufacturing got an opportunity to be a part of G20 Digital Economy Working Group (DEWG) in Lucknow hosted by UP Government. These type of events helps all the segments of nation like Politicians, Economic dignitaries, Business leader, Entrepreneurs, Industry Associates etc. to come on a common platform and take nation towards a bright and better future and we are proud to be participating and showcasing live demonstrations of our work to the visitors.We are happy to inform that on December 22, 2022, IITD-AIA Foundation For Smart Manufacturing presented various industry 4.0 technologies at Workshop on Automation for Smart Manufacturing organized by Automation Industry Association in Pune. Visitors were given Live Demonstrations of technologies created for smart manufacturing in the cyber-physical lab at the Indian Institute of Technology, Delhi. Here are some of the day's highlights. \"\n",
    "question=\" what is HAL?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"Contact us today for implementing Call us for any query011-26582053, 8076197190 or email us oninfo@iafsm.in. The program is entirely online and will run full-time from June 1, 2023, to July 31, 2023, for a duration of two months. The focus of the internship is on the theme of 'Smart Factory,' which is a rapidly growing industry. This internship program is an excellent chance for individuals to gain valuable knowledge and experience in this field. It is an excellent opportunity for those who are looking to expand their skills and gain practical experience in this exciting area. If you are interested, don't miss this chance to be a part of the program and enhance your career prospects.. Foundation for Smart Manufacturing (FSM) helps, supports, and develops Smart Manufacturing concepts for Indian Industry to witness, ideate, and try out in their plants. FSM also aims for a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment. FSM Skills is a holistic platform for providing immersive training experience through Live lectures, Online learning, Live demonstrations, Live Labs & Self paced exercises on remotely accessible actual hardware. FSM is focussed on enabling people from becoming Smart to Samarth (capable) fraternity by creating awareness, step-wise learning and becoming an expert from domains driving Industry 4.0. Academic strength of IIT Delhi brought interdisciplinary learnings to FSM. Expert Faculty members from various departments contribute to it. FSM has highly trained manpower to implement the Industry 4.0 projects in guidance with experienced faculty members and industry partners. M.Tech and Ph.D students doing research in Smart manufacturing are contributing to FSM technologies and increase its knowledgebase. At FSM we provide various Client services and training under the domain of Smart Manufacturing. The services will enable clients to test and debug problems before installing the solution at the site & also allow them to experiment and innovate with an appropriate mix of standard and customized solutions.\"\n",
    "question=\"What are the service provided?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"Contact us today for implementing Call us for any query011-26582053, 8076197190 or email us oninfo@iafsm.in. The program is entirely online and will run full-time from June 1, 2023, to July 31, 2023, for a duration of two months. The focus of the internship is on the theme of 'Smart Factory,' which is a rapidly growing industry. This internship program is an excellent chance for individuals to gain valuable knowledge and experience in this field. It is an excellent opportunity for those who are looking to expand their skills and gain practical experience in this exciting area. If you are interested, don't miss this chance to be a part of the program and enhance your career prospects.. Foundation for Smart Manufacturing (FSM) helps, supports, and develops Smart Manufacturing concepts for Indian Industry to witness, ideate, and try out in their plants. FSM also aims for a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment. FSM Skills is a holistic platform for providing immersive training experience through Live lectures, Online learning, Live demonstrations, Live Labs & Self paced exercises on remotely accessible actual hardware. FSM is focussed on enabling people from becoming Smart to Samarth (capable) fraternity by creating awareness, step-wise learning and becoming an expert from domains driving Industry 4.0. Academic strength of IIT Delhi brought interdisciplinary learnings to FSM. Expert Faculty members from various departments contribute to it. FSM has highly trained manpower to implement the Industry 4.0 projects in guidance with experienced faculty members and industry partners. M.Tech and Ph.D students doing research in Smart manufacturing are contributing to FSM technologies and increase its knowledgebase. At FSM we provide various Client services and training under the domain of Smart Manufacturing. The services will enable clients to test and debug problems before installing the solution at the site & also allow them to experiment and innovate with an appropriate mix of standard and customized solutions. The Automation Industries Association (AIA) in its quest to set up a Common Engineering Facility Center (CEFC) at IIT Delhi has brought together experts from various industries in the sector of automation. These experts look forward to work together and use their industrial experience along with various verticals to initiate smart manufacturing in India. The following firms have agreed to come together to set up the CEFC. They comprise Technology & Investment Partners, Simulation Integration Partners and Machinery Partners.\"\n",
    "question=\"who are partners at fsm?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"Contact us today for implementing Call us for any query011-26582053, 8076197190 or email us oninfo@iafsm.in. The program is entirely online and will run full-time from June 1, 2023, to July 31, 2023, for a duration of two months. The focus of the internship is on the theme of 'Smart Factory,' which is a rapidly growing industry. This internship program is an excellent chance for individuals to gain valuable knowledge and experience in this field. It is an excellent opportunity for those who are looking to expand their skills and gain practical experience in this exciting area. If you are interested, don't miss this chance to be a part of the program and enhance your career prospects.. Foundation for Smart Manufacturing (FSM) helps, supports, and develops Smart Manufacturing concepts for Indian Industry to witness, ideate, and try out in their plants. FSM also aims for a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment. FSM Skills is a holistic platform for providing immersive training experience through Live lectures, Online learning, Live demonstrations, Live Labs & Self paced exercises on remotely accessible actual hardware.. Fill out the online registration form Shortlisting based on the eligibility criteria Level 1: Learning modules (Approx. time: 24 hrs) will be made available on fsmskills website. To be completed by 20th May 2023. Post your signup on fsmskill, you will gain access to the Level-1 course of IAFSM. This step involves learning of Smart Manufacturing Concepts and is the foundation course that is mandatory for all interns to qualify latest by 20th May 2023. You are required to go through recorded lectures and study the content thoroughly to clear the assignments of Level-1 in maximum 2 attempts. After 2 attempts, if you are not able to qualify for Level-1, your candidature will no longer be considered for internship.    Level 2 : After successful completion of Level-1, You will be redirected to the Stream Learning module which involves learning of specific domains of your choice. You can choose from the available domains and try out a maximum of 3 domains of your choice. You are then required to undergo and clear the assignments based on your selection and qualify the Level 2 assignments after which you shall be taken forward for Project Based Learning under Summer Internship 2023. The assignments are to be attempted and cleared latest by 28th May 2023. Internship Projects: After successful completion of Level-2, Interns will be allocated projects based on domain preference, level-2 performance and interaction with the mentors. Final Selection and Project Allocation based on the Level 2 performance and preferences These are full-time internships and require 48 hours per week    \"\n",
    "question=\"what are the process for internship?\"\n",
    "print(f\"Predicted Answer: {get_answers(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy with comparatively large context of size 1355**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"At FSM we provide various Client services and training under the domain of Smart Manufacturing. The services will enable clients to test and debug problems before installing the solution at the site & also allow them to experiment and innovate with an appropriate mix of standard and customized solutions. ,   Consulting ,  Skill Certification ,  Research ,  Foundation for Smart Manufacturing (FSM) helps, supports, and develops Smart Manufacturing concepts for Indian Industry to witness, ideate, and try out in their plants. FSM also aims for a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment.FSM Skills is a holistic platform for providing immersive training experience through Live lectures, Online learning, Live demonstrations, Live Labs & Self paced exercises on remotely accessible actual hardware. ,  Academic strength of IIT Delhi brought interdisciplinary learnings to FSM. Expert Faculty members from various departments contribute to it. ,  FSM has highly trained manpower to implement the Industry 4.0 projects in guidance with experienced faculty members and industry partners. ,  M.Tech and Ph.D students doing research in Smart manufacturing are contributing to FSM technologies and increase its knowledgebase. ,  FSM brought industry partners from MNCs operating all across the globe to bring rich experience in the smart manufacturing technologies. ,  The Automation Industries Association (AIA) in its quest to set up a Common Engineering Facility Center (CEFC) at IIT Delhi has brought together experts from various industries in the sector of automation. These experts look forward to work together and use their industrial experience along with various verticals to initiate smart manufacturing in India. The following firms have agreed to come together to set up the CEFC. They comprise Technology & Investment Partners, Simulation &amp; Integration Partners and Machinery Partners. ,    Fill out the online registration form Shortlisting based on the eligibility criteria Level 1: Learning modules (Approx. time: 24 hrs) will be made available on fsmskills website. To be completed by 20th May 2023. Post your signup on fsmskill, you will gain access to the Level-1 course of IAFSM. This step involves learning of Smart Manufacturing Concepts and is the foundation course that is mandatory for all interns to qualify latest by 20th May 2023. You are required to go through recorded lectures and study the content thoroughly to clear the assignments of Level-1 in maximum 2 attempts. After 2 attempts, if you are not able to qualify for Level-1, your candidature will no longer be considered for internship.   Level 2 : After successful completion of Level-1, You will be redirected to the Stream Learning module which involves learning of specific domains of your choice. You can choose from the available domains and try out a maximum of 3 domains of your choice. You are then required to undergo and clear the assignments based on your selection and qualify the Level 2 assignments after which you shall be taken forward for Project Based Learning under Summer Internship 2023. The assignments are to be attempted and cleared latest by 28th May 2023.  Internship Projects: After successful completion of Level-2, Interns will be allocated projects based on domain preference, level-2 performance and interaction with the mentors.  Final Selection and Project Allocation based on the Level 2 performance and preferences These are full-time internships and require 48 hours per week  ,  The robot becomes the third arm of the human operator. This new form of collaboration opens up previously inconceivable possibilities for the smart factory of the future. As collaborative robots operate without physical safeguards, they have to permanently calculate the risk of colliding with humans, constantly checking this via the robot controller.   Collaborative robots works hand in hand with the operator, thereby enabling him to work more efficiently, more ergonomically, more precisely and with greater concentration. As a robot that can genuinely be deployed universally, it is defining new standards on the road to the fourth industrial revolution. Collaborative robots can be programmed onsite by the employees and can be quickly re-tasked to do multiple jobs quickly. They are lightweight and can be moved around easily in the production facility.Collaborative robot have integrated sensors, passive compliance or over current detection as safety features. The integrated sensors will feel external forces and, if this force is too high, the robot will stop its movement. Passive compliance is produced by mechanical components. If an external force acts on a joint, this joint will submit itself to this force. So, in case of a collision, the joint will move in the opposite direction avoiding any injury. Also, an over current can be detected when a collision occurs. This is another safety feature, because the software can generate a security stop when it detects a current spike. Some of the applications of collaborative robots can be:   Assembly  Soldering Vision based quality inspection Machine Tending Gluing Screwing Pick and place Operating hand tools Laboratory work   ,  Multi Process Robotic Cell demonstrates a flexible manufacturing cell. This cell is an assembly line where components of a main part gets assembled, the main part comprises of minimum of 7 sub-parts and more, which are then assembled by placing, inserting and part-screwing the main part. It has multiple stations which performs operation on the parts (like valve body assembly, vision inspection, testing, packaging). The main feature of the cell is exhibited using the programming, control and diagnosis of the robotic manipulator amongst other peripheral and safety devices. We call it as Multi Process robotic cell because it can be used for more than one manufacturing process.  There are different stations in the robotic cell: 1. Conveyor Station: Use to transfer the inventory tray or pallet to the place where robot can pick them.2. Assembly Station: All the parts (axisymmetric and prismatic parts) will be assembled and screwed on the valve body in this station. Along with that inventory scanning and vision inspection of the valve bodies will be done.3.Testing Station: All the pneumatic ports of the valve body will be tested in this station. If there is any leakage, valve body will be rejected.4. Hex-nut Assembly Station:- Hex nut will be assembled on the body in this station.5. Packaging Station: Assembled valve bodies will be placed in a box and packaging is done. A printing head will print the required details( type of bodies, number of bodies, date of assembly etc)  on the box and then the box will be dispatched. ,  The video here demonstrates the standalone function of loading inventory using trays from conveyor station to assembly station. The tray has multiple arrays of different sized part but same variety. There are trays with 3/2, 5/2, 5/2 double solenoid, 5/3 solenoid valve body. The end-effector of the robot have more than one tool attachments. This is possible due to tool changer allowing robot to perform multiple actions like pick and place, part screwing,  gripping via vacuum suction cup, bar code part scanning. ,  Training ,  <-Cyber Physical assembly line ,  Robotic Welding Cell-> ,  This Multi-purpose Robotic Cell is assembling different variants of direction control valves. It has different stations which performs different operations on the valve body. Assembly,Vision Inspection,Testing,Packaging are some of the operations that can be performed by this cell. The main feature of this cell is that all the programming is done on PLC, use of teach pendant or robot controller programming has been Bypassed. As we can use this cell for multiple purpose,we call it as Multi-Process Robotic Cell. ,  There are different station in the robotic cell:1.Conveyor station:- Use to transfer the inventory tray or pallet to the place where robot can pick them.2. Assembly Station:- All the parts (Axisymmetric and prismatic parts) will be assembled and screwed on the valve body in this station. Along with that inventory scanning and vision inspection of the valve bodies will be done in this station.3.Testing Station:- All the ports of the valve body will be tested in this station. If there is any leakage, valve body will be rejected.4.Hex nut assembly station:- Hex nut will be placed on the body in this station.5. Packaging station :- Assembled valve bodies will be placed in a box and packaging is done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to divide the large context in size of 512\n",
    "def divide_into_chunks(context, chunk_size=512, stride=50):\n",
    "    #\n",
    "    chunks = []\n",
    "    total_words = len(context.split())\n",
    "    start = 0\n",
    "    end=512\n",
    "    #print(total_words)\n",
    "    while end < total_words:\n",
    "        end = min(start + chunk_size, total_words)\n",
    "        #print(start,end)\n",
    "        chunk= \" \".join(context.split()[start:end]) # convert splitted words in string or continuous format\n",
    "        chunks.append(chunk)\n",
    "        start = end-stride\n",
    "        \n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is collaborative robots?\"\n",
    "question_tokens = tokenizer(question, return_tensors='pt')\n",
    "\n",
    "# Divide the large context into chunks of 512 size.\n",
    "chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "answers = []\n",
    "count=0\n",
    "# Iterate through each chunk and get the answer using the transformer model.\n",
    "for chunk in chunks:\n",
    "    # Combine the chunk with the question.\n",
    "    count+=1\n",
    "    print(\"loop:\",count)\n",
    "    print(chunk)\n",
    "    #input_text = question + \" \" + \" \".join(chunk)\n",
    "\n",
    "    # Tokenize the combined text.\n",
    "    inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "#print(len(input_ids))\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Get the start and end positions of the answer using the model.\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Find the answer span within the chunk.\n",
    "    start_idx = torch.argmax(output.start_logits)\n",
    "    end_idx = torch.argmax(output.end_logits) + 1  # +1 to include the end token.\n",
    "\n",
    "    # Convert token indices back to answer text.\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    " \n",
    "        \n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end ]))    \n",
    "    #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "    print (answer) \n",
    "    answers.append(answer)\n",
    "    \n",
    "#right now final answer is all the answer i.e. predicted by model from each chunk \n",
    "\n",
    "final_answer = answers\n",
    "\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "question=\"What  Packaging station in robotic cell?\"\n",
    "question_tokens = tokenizer(question, return_tensors='pt')\n",
    "\n",
    "# Divide the large context into chunks.\n",
    "chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "answers = []\n",
    "count=0\n",
    "# Iterate through each chunk and get the answer using the transformer model.\n",
    "for chunk in chunks:\n",
    "    # Combine the chunk with the question.\n",
    "    #count+=1\n",
    "    # print(\"loop:\",count)\n",
    "    # print(chunk)\n",
    "    #input_text = question + \" \" + \" \".join(chunk)\n",
    "\n",
    "    # Tokenize the combined text.\n",
    "    inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "#print(len(input_ids))\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Get the start and end positions of the answer using the model.\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Find the answer span within the chunk.\n",
    "    start_idx = torch.argmax(output.start_logits)\n",
    "    end_idx = torch.argmax(output.end_logits) + 1  # +1 to include the end token.\n",
    "\n",
    "    # Convert token indices back to answer text.\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "    \n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "    #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "    print (answer) \n",
    "    answers.append(answer)\n",
    "    \n",
    "\n",
    "final_answer = answers\n",
    "\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question=\"What is Conveyer station in robotic cell?\"\n",
    "question_tokens = tokenizer(question, return_tensors='pt')\n",
    "\n",
    "# Divide the large context into chunks.\n",
    "chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "answers = []\n",
    "count=0\n",
    "# Iterate through each chunk and get the answer using the transformer model.\n",
    "for chunk in chunks:\n",
    "    # Combine the chunk with the question.\n",
    "    # count+=1\n",
    "    # print(\"loop:\",count)\n",
    "    # print(chunk)\n",
    "    #input_text = question + \" \" + \" \".join(chunk)\n",
    "\n",
    "    # Tokenize the combined text.\n",
    "    inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "#print(len(input_ids))\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Get the start and end positions of the answer using the model.\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Find the answer span within the chunk.\n",
    "    start_idx = torch.argmax(output.start_logits)\n",
    "    end_idx = torch.argmax(output.end_logits) + 1  # +1 to include the end token.\n",
    "\n",
    "    # Convert token indices back to answer text.\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "   \n",
    "        \n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "    #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "    print (answer) \n",
    "    answers.append(answer)\n",
    "\n",
    "\n",
    "final_answer = answers\n",
    "\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**accuracy with complete context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\" At FSM we provide various Client services and training under the domain of Smart Manufacturing. The services will enable clients to test and debug problems before installing the solution at the site & also allow them to experiment and innovate with an appropriate mix of standard and customized solutions. ,   Consulting ,  Skill Certification ,  Research ,  Foundation for Smart Manufacturing (FSM) helps, supports, and develops Smart Manufacturing concepts for Indian Industry to witness, ideate, and try out in their plants. FSM also aims for a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment.FSM Skills is a holistic platform for providing immersive training experience through Live lectures, Online learning, Live demonstrations, Live Labs & Self paced exercises on remotely accessible actual hardware. ,  Academic strength of IIT Delhi brought interdisciplinary learnings to FSM. Expert Faculty members from various departments contribute to it. ,  FSM has highly trained manpower to implement the Industry 4.0 projects in guidance with experienced faculty members and industry partners. ,  M.Tech and Ph.D students doing research in Smart manufacturing are contributing to FSM technologies and increase its knowledgebase. ,  FSM brought industry partners from MNCs operating all across the globe to bring rich experience in the smart manufacturing technologies. ,  The Automation Industries Association (AIA) in its quest to set up a Common Engineering Facility Center (CEFC) at IIT Delhi has brought together experts from various industries in the sector of automation. These experts look forward to work together and use their industrial experience along with various verticals to initiate smart manufacturing in India. The following firms have agreed to come together to set up the CEFC. They comprise Technology & Investment Partners, Simulation &amp; Integration Partners and Machinery Partners. ,    Fill out the online registration form Shortlisting based on the eligibility criteria Level 1: Learning modules (Approx. time: 24 hrs) will be made available on fsmskills website. To be completed by 20th May 2023. Post your signup on fsmskill, you will gain access to the Level-1 course of IAFSM. This step involves learning of Smart Manufacturing Concepts and is the foundation course that is mandatory for all interns to qualify latest by 20th May 2023. You are required to go through recorded lectures and study the content thoroughly to clear the assignments of Level-1 in maximum 2 attempts. After 2 attempts, if you are not able to qualify for Level-1, your candidature will no longer be considered for internship.   Level 2 : After successful completion of Level-1, You will be redirected to the Stream Learning module which involves learning of specific domains of your choice. You can choose from the available domains and try out a maximum of 3 domains of your choice. You are then required to undergo and clear the assignments based on your selection and qualify the Level 2 assignments after which you shall be taken forward for Project Based Learning under Summer Internship 2023. The assignments are to be attempted and cleared latest by 28th May 2023.  Internship Projects: After successful completion of Level-2, Interns will be allocated projects based on domain preference, level-2 performance and interaction with the mentors.  Final Selection and Project Allocation based on the Level 2 performance and preferences These are full-time internships and require 48 hours per week  ,  The robot becomes the third arm of the human operator. This new form of collaboration opens up previously inconceivable possibilities for the smart factory of the future. As collaborative robots operate without physical safeguards, they have to permanently calculate the risk of colliding with humans, constantly checking this via the robot controller.   Collaborative robots works hand in hand with the operator, thereby enabling him to work more efficiently, more ergonomically, more precisely and with greater concentration. As a robot that can genuinely be deployed universally, it is defining new standards on the road to the fourth industrial revolution. Collaborative robots can be programmed onsite by the employees and can be quickly re-tasked to do multiple jobs quickly. They are lightweight and can be moved around easily in the production facility.   Collaborative robot have integrated sensors, passive compliance or over current detection as safety features. The integrated sensors will feel external forces and, if this force is too high, the robot will stop its movement. Passive compliance is produced by mechanical components. If an external force acts on a joint, this joint will submit itself to this force. So, in case of a collision, the joint will move in the opposite direction avoiding any injury. Also, an over current can be detected when a collision occurs. This is another safety feature, because the software can generate a security stop when it detects a current spike. Some of the applications of collaborative robots can be:   Assembly  Soldering Vision based quality inspection Machine Tending Gluing Screwing Pick and place Operating hand tools Laboratory work   ,  Multi Process Robotic Cell demonstrates a flexible manufacturing cell. This cell is an assembly line where components of a main part gets assembled, the main part comprises of minimum of 7 sub-parts and more, which are then assembled by placing, inserting and part-screwing the main part. It has multiple stations which performs operation on the parts (like valve body assembly, vision inspection, testing, packaging). The main feature of the cell is exhibited using the programming, control and diagnosis of the robotic manipulator amongst other peripheral and safety devices. We call it as Multi Process robotic cell because it can be used for more than one manufacturing process.  There are different stations in the robotic cell: 1. Conveyor Station: Use to transfer the inventory tray or pallet to the place where robot can pick them.2. Assembly Station: All the parts (axisymmetric and prismatic parts) will be assembled and screwed on the valve body in this station. Along with that inventory scanning and vision inspection of the valve bodies will be done.3.Testing Station: All the pneumatic ports of the valve body will be tested in this station. If there is any leakage, valve body will be rejected.4. Hex-nut Assembly Station:- Hex nut will be assembled on the body in this station.5. Packaging Station: Assembled valve bodies will be placed in a box and packaging is done. A printing head will print the required details( type of bodies, number of bodies, date of assembly etc)  on the box and then the box will be dispatched. ,  The video here demonstrates the standalone function of loading inventory using trays from conveyor station to assembly station. The tray has multiple arrays of different sized part but same variety. There are trays with 3/2, 5/2, 5/2 double solenoid, 5/3 solenoid valve body. The end-effector of the robot have more than one tool attachments. This is possible due to tool changer allowing robot to perform multiple actions like pick and place, part screwing,  gripping via vacuum suction cup, bar code part scanning. ,  Training ,  <-Cyber Physical assembly line ,  Robotic Welding Cell-> ,  This Multi-purpose Robotic Cell is assembling different variants of direction control valves. It has different stations which performs different operations on the valve body. Assembly,Vision Inspection,Testing,Packaging are some of the operations that can be performed by this cell. The main feature of this cell is that all the programming is done on PLC, use of teach pendant or robot controller programming has been Bypassed. As we can use this cell for multiple purpose,we call it as Multi-Process Robotic Cell. ,  There are different station in the robotic cell:1.Conveyor station:- Use to transfer the inventory tray or pallet to the place where robot can pick them.2. Assembly Station:- All the parts (Axisymmetric and prismatic parts) will be assembled and screwed on the valve body in this station. Along with that inventory scanning and vision inspection of the valve bodies will be done in this station.3.Testing Station:- All the ports of the valve body will be tested in this station. If there is any leakage, valve body will be rejected.4.Hex nut assembly station:- Hex nut will be placed on the body in this station.5. Packaging station :- Assembled valve bodies will be placed in a box and packaging is done. A printing head will print the required details( Type of bodies ,number of bodies, date of assembly etc\\u2026) on the box and then the box will be dispatched. ,  1.Siemens PLC:- Siemens S7 1516 is the master plc in this station and it is responsible for all the programming in the cell.2. DI and DO: - 32-point digital input and 32 point digital output module is connected on the base rack with the plc.3. 6 Axis Kuka robot and one axis:- 6 Axis kuka robot performs all the motion operation in the cell.7th axis rotates the valve body during assembly and inspection.4. QR code scanner:- QR code scanner performs the inventory check as it scans the QR code present on body. After scanning a body, plc gets the data of that particular body and its location on the tray.5. Laser based Vision sensor:- This sensor inspects all the four faces of the body and if it is OK then the station will pass the body to next station or else it will reject the body and picks another body of the same type.6. Tool Changers :- Different slave tool changersare used for different operations. These slave tool changers engages with the master tool changer(Present on the Robot arm) when required. Tool changers in this cell are used for:- QR code scanner,Pneumatic gripper and Screwdriver, Vacuum Gripper ,  Software ,  Mobile Collaborative Robot  ,  Cyber Physical Factory ,  We are providing following services:  3D printing Smart Manufacturing Training Kits for Industrial Automation learning MIG Welding (including Wire-arc-additive-manufacturing)  ,  Multimaterial 3D printer ,  Smart Manufacturing Training Kits ,  MIG Welding Cell ,  A system consisting of 3 parts 1. Python code 2. Notification System 3. AR Application The system is designed to automatically detect any error occurring in the Work Station 1 and raising an alert, the user then using HoloLens 2 will follow the steps to resolve the error ,  IIoTAugmented Reality ,  The Multi-material Additive Manufacturing Machine is a versatile machine made by Hyrel 3D and AMS. It is not 'just a 3D printer'. It is a Large format, Rapid Prototyping, Research, Manufacturing and Educational Platform. This 3D printer is customizable on various levels: build volume, print bed, extruder, and more. It is equipped with the capacity to attach 5 tool heads simulatneously. We have tool heads for printing common FDM filaments(PLA, ABS, PC, PEEK), clays, biologicals, flexibles, UV-curables, RTV Silicones, etc. It is highly evolutive and also offers options for 4th and 5th axes, PCB milling tool, 3-phase machining tool and CO2 or Diode lasers (laser cutting). ,  Smart Manufacturing Training Kit-> ,  Cyber Physical Assembly Line demonstrates smart manufacturing and comes with different functionalities. It includes the Custom order processing, valve body, spool, solenoid, connector, valve functioning testing, packaging, inkjet printing. It consists of three work stations and one MPRC.Workstation 1: It is also known as Raw part storage, part loading and quality check. It uses the Rockwell PLC. It stores Product and do Pick & place arrangement for mounting the product on pallet.  Workstation 2: It is also known as axisymmetric part storage quality check and inspection work station. It uses B & R PLC. It stores spool and do pick and place arrangement for inserting the spool in valve body. It uses proximity sensor for inventory check. Workstation 3: It is also known as Prismatic Part Assembly and Screwing Workstation. It uses the Mitsubishi PLC. It stores all prismatic parts. It is used to place and tighten all the parts to valve body.Multi Process Robotic Cell (MPRC) :Click here to know more. Conclusion: All the station can run in Auto/Manual Mode. This is how the cyber physical assembly line works. There are features in the line such as smart sensing, Machine to Machine communication, smart dashboard, remote monitoring, alerts and notifications on email, safety, remote maintenance and Augmented Reality. ,  Simulation & Testing Services ,  Prototyping, Consulting Services ,  Skills Certification ,  Site Integration Services ,  Job Work & Research ,  Multi Process Robotic Cell-> ,  Augmented reality is one of the cutting edge technologies involved in the industry 4.0 trend when talking about smart manufacturing, it is a technology which was seen just as a fancy toy until a few years back, but which has now reached the right level of maturity to be employed in a productive environment.    AR applications can become even more powerful by augmenting them with data generated by another set of technologies, revolutionizing the marketplace called the Internet of Things (IoT). Combining AR and the IoT allows employees, such as field maintenance workers, to access vital machine operating statistics to assist in maintenance decisions, or an assembly worker to visually receive pick and place instructions and alerts if tools are working incorrectly or are out of tolerance.   Key AR ecosystem components include device hardware, an OS open to third-party application development, and a platform for software, as well as content creation and management. The standard device hardware for viewing AR applications has predominantly been smartphones and tablets due to their wide availability and exceptional compute power. The newer devices expected to accelerate enterprise AR adoption because they allow hands-free access to information are smart glasses, HMDs, and other digital eyewear solutions from companies such as Microsoft, ODG, Epson, and Vuzix.   Augmented reality renders 3D objects in real time into your field of vision. For example, looking through the cover of a machine and seeing its internal component structure.   Augmented Reality (AR) is a technology enriching the real world with digital information and media, such as 3D models and videos, overlaying in real-time the camera view of your smartphone, tablet, PC or connected glasses.   On the spectrum between virtual reality, which creates immersive, computer-generated environments, and the real world, augmented reality is closer to the real world. Augmented reality adds graphics, sounds, haptic feedback and smell to the natural world as it exists. Both video games and cell phones are driving the development of augmented reality.   The methods by which AR is achieved can generally be split into two broad categories: Marker-based, and markerless.   Marker-based Systems: This technology uses physical-world symbols as a reference point for computer graphics to be overlaid. For example, a 2-dimensional printed marker is placed in front of a webcam. The computer then interprets this symbol to overlay an on-screen graphic as if it were directly on top of the marker in the physical world. There have been several notable uses, most commonly in marketing   Markerless Systems: By contrast, this technological approach has given rise to \\u2018mobile augmented reality\\u2019, denoting use of the technology with devices such as smartphones and tablets. This method uses a combination of an electronic devices\\u2019 accelerometer, compass and location data (such as the Global Positioning System \\u2013 GPS) to determine the position in the physical world, which way it is pointing and on which axis the device is operating. This location data can them be compared to a database to determine what the device is looking at, and thus allows computer data/graphics to be displayed on-screen.   Applications of AR in industrial environment: 1. Data Reuse: AR applications allow more efficient reuse of existing enterprise application data. Enterprise application data can include maintenance records, service tickets, and usage logs\\u2014any combination of which can be tapped into to decorate an AR experience that blends the physical and digital worlds. 2. Data Contextualization: AR applications can be used to better contextualize information across a range of industries and job functions. In manufacturing, this could mean giving linemen and plant personnel the ability to abstract backend systems information for 3D product navigation, step-by-step work instructions, and remote visual guidance. 3. Work Error Reduction: AR applications can reduce errors made by workers in various occupational tasks. Whether the error is caused by too little information, too much information, or poor quality information, AR applications place the right information and instructions at the location of the work task. 4. Workforce Multiplier: AR applications are a workforce multiplier in two ways. First, training resources are more effective and efficient. Training hours can be reduced because AR applications can include video instructions on repair/replacement tasks overlaid on the machines themselves. Second, workers can do more by themselves versus sending multiple workers or truck rolls to address the same problem or work task. 5. Safety: AR applications can also improve the safety of a work task. For instance, AR applications can include not only written instructions for removing or replacing a part on a machine, but can also include visual instructions. This assistance avoids unnecessary and possibly unsafe interaction with the machine or object.  ,  The Mobile Collaborative Robot (MCR) is developed to achieve autonomous material transportation within the Cyber Physical Factory. The MCR consists of a TM5M700 collaborative robot mounted on top of an Addverb Automated Mobile Robot (AMR). The AMR uses a LIDAR and two depth cameras to navigate using Natural Navigation. It has a payload of 150 kg. The AMR runs on Robot Operating System (ROS). The collaborative robot mounted on top of the AMR has a camera on it. The cobot can be programmed using ROS or the TMFlow software. The feed from the camera can be used for object detection. The cobot has a payload of 6 Kg. The MCR can also be controlled using a Fleet Management System. The MCR can be dispatched to various locations in the map using REST Api communication through the Fleet Management System. ,  Coming Soon.. ,  <-Robotic Welding Cell ,  Cyber Physical Factory-> ,  Short-term education and training courses will be offered along with on-line learning and assessment tools to educators and users on a chargeable basis. All the 12 technology streams will be covered. ,  The domain of Smart Manufacturing is expected to open up a new opportunity in industrial consulting, especially with regard to identification and removal of bottlenecks in current operations. The CEFC multi-disciplinary teams will undertake feasibility surveys, ROI analysis and process improvement studies for clients, prior to implementation and also post implementation. ,  Many times clients wish to test out the Proof-of-Concept on their actual production lines. The CEFC team assigned to the Client during concept formulation will undertake such site activities with a pool of industry solution providers and system integrators. ,  It is expected that Skill Councils such as Automotive Skill Council, Capital Goods Skill Council,Industrial Automation Skill Council and Tool Rooms will be creating their unique set of Role based competencies. The CEFC will offer them and their Training Partners, a gap filling option for theory and practical, and a brand-agnostic independent certification. ,  The research team will help users to bring uniqueness into their solution while providing adequate safeguards for IP protection. Users can sponsor prototyping or R&D projects as per their need. ,  IAFSM will take up research projects in consultation with industry for development of cyber physical systems for machine tools, industrial IoT, machine data cloud, machine controllers etc. to bridge the technology adoption gap in manufacturing. These research projects will be executed with clear objectives to meet focussed technology requirement for smart manufacturing and easy adoption by the industries. The developed technologies will be licensed further for commercialization to interested industries. ,  The CPS facility and the associated technologies will provide a one stop shop for users whose needs cut across multiple disciplines and who want to witness a comprehensive digital transformation before taking up for actual implementation. This will enable clients to experiment and innovate with an appropriate mix of standard and customised solutions. ,  The testing service will enable clients to test and debug problems before installing the solution at site. ,  Multi Process Robotic Cell ,  Smart Lathe Machine ,  Robotic Welding Cell ,  FSM AR Demo ,  Mechanism Kit Assembly and Disassembly ,  AR Maintenance Using HoloLens ,  Expert Maintenance System Using HoloLens ,  Cyber Physical Assembly Line ,  CP Lab Autonomy ,  Smart Mechanism Kit Realtime Values ,  PLC Kit Parts Introduction  ,  Smart Mechanism Kit Motor Replacement ,  To create user defined webpages to control and monitor different devices (Appliances,machines) present in CP lab. ,  01Remote Control and monitoring of assembly line, Compressor and MPRC ,  02Remote control and monitoring of domestic appliances (lights,fans,AC) ,  03User defined access to control the machines remotely ,  04Activity logging of users ,  05Remote Control of the training Kits to train people remotely  ,  Traditionally, manufacturing has been considered as a process that convert raw materials into physical products in the factories by managing resources with best automation practices available. Today, drivers such as technology, sustainability, optimization and the need to meet customer demands have once again encouraged the transformation of the manufacturing industry to become adaptive, fully connected, and aware of its own power quality. One of the most significant trends in manufacturing is of improved information technology solutions involving the union of conventional automation with the information technology. Cyber-physical systems (CPS) are enabling technologies which bring the virtual and physical worlds together to create a truly networked world in which intelligent objects communicate and interact with each other. They are \\ enabling technologies\\  which make multiple innovative applications and processes a reality as the boundaries between the real and virtual worlds disappear. Cyber-physical systems provide the basis the creation of an Internet of Things (IoT) which makes smart services and products possible. A cyber-physical system (CPS) is a  thing in the Internet of Things. It is a combination of mechanical, electronic and software components that communicate via a data infrastructure such as the Internet, react flexibly to external influences and exchange data with information systems and other CPSs. In manufacturing facilities, cyber-physical systems will communicate with intelligent, networked industrial production and logistics units-also known as cyber-physical production systems (CPPS). The CPSs exchange information, trigger actions in production and reciprocally control themselves autonomously. This enables industrial processes in manufacturing, engineering, use of materials, supply chain management and life cycle management to be fundamentally restructured and optimized.   Currently, manufacturing data are segmented, detailed and planned for a single scope, stored within the legacy systems, thus preventing the digital continuity that would let use them in the optimal way, independently from where and how they have been collected. Cyber Physical System (CPS) will instead be able to provide the needed information from the physical world while cyber-physical-collaboration environment will enable an efficient analysis, management, sharing and usage of the data and the knowledge elaborated from them and from the experience of involved people. Cyber-physical systems also represent a paradigm break from existing business and market models, as revolutionary new applications, service providers and value chains become possible.  ,  Being able to assist customers remotely, service technicians could support their customers at any time and from anywhere, without necessarily having to visit the customer site. Remote access could also help to better prepare service technicians with the necessary information for their tasks. Knowing about the machine or system error in more detail beforehand saves valuable time because required spare parts or other equipment can ordered, prepared and brought along. Moreover, due to a shorter reaction time, the customer\\u2019s machines are up and running much faster, saving them from costly downtime.   For a machine and equipment manufacturer, using remote access also means that the same number of service technicians could support more customers or offer additional services.   A secure remote connection to distributed machinery and equipment is also the basis for many new concepts and services within Industry 4.0 such as predictive maintenance, where a secure connection is established to collect data from machines, equipment or devices. The data is than analyzed and used to detect errors and possible failures at an early stage to avoid unplanned downtime. ,  Software used for AR : Here are various software we are using for the smart manufacturing purpose in AR. ,   It is an AR application designed and developed to provide a complete 3D CAD model of the FSM Smart Kits. The application uses a pre-defined Image Target and superimposes a 3D CAD of the Smart Manufacturing Training Kits. The user can visualize the smart kit without having access to the physical kit. He/She can click on the individual parts to display information about them. He/She can also get an exploded view of the CAD to understand the disassembly process. All activity of the user is also being logged on the cloud and displayed on a dashboard, this allows us to track the progress of the user. ,  It is an AR application which uses the physical FSM Smart Kit as an Image Target and adds information about their individual components. The app also allows the user to click on the individual parts and learn about them. ,  It is an AR application to help the surgeon in verifying and sensing the correctness of the bent plate. The application uses a 2D Image Target to superimpose the CAD of the bent plate on the Image Target. The surgeon will try to match the physical plate to the superimposed cad to confirm the correct bent. ,  It is an AR application to guide the surgeon for drilling correct holes in the spine to insert screws. The application uses a 3D spine as the Model Target, then superimposes the screws on the CAD. This will guide the surgeon to determine the angle and location of the screws.  ,   It is an AR application that provides a step-by-step process to assemble and disassemble the FSM Mechanism Kit. ,  It is an AR application that provides the user a 3D visualization of the Cobot joints' movements. Use sliders to move the joints and learn about the working of Cobots. ,  It is an AR application to scan the surroundings and place full-scale objects to confirm size requirements. ,  It is an AR application to get a 3D view of all the smart machines and kits at FSM. ,  It is an AR application that replicates the assembly process of the assembly line. It gives the user a complete visualization of every step of the assembly process. ,  Smart Catalogue & visualization ,  Education &  Training ,  Use as a teaching tool ,  Assess machinery before purchase ,  Maintenance Tool ,  <-Smart Manufacturing Training Kits ,  Cyber Physical Facilities-> ,  Cyber physical factory (CPF) is also known as Discrete Micro Production Facility or simply Micro Production Facility. It demonstrates the convergence of the Informational Technology (IT) and Operational Technology (OT) at micro factory level where the machines are discretely located. It has 18 varieties of machines for different manufacturing operations. The key features that this factory has: Customer Order Management Production Order Management Material Management Performance Management Customer Relationship Operations Intelligence Quality Management Error-Proofing Maintenance Management Energy Management Workforce Management Environment and Safety We have converted legacy machines into digitized smart machines like lathe machine, shearing machine. The Mobile Collaborative Robot is used for inbound logistics. The following image demonstrates the material and manufacturing process for a typical product like a hydraulic pump flange. ,  <-Mobile Collaborative Robot ,   Services-> ,  This course is designed on a Simulation platform. It\\u2019s a self-paced online course where you get to learn different domains of Automation like Pneumatic, Electro-Pneumatics, PLC programming and Electrical Connections of a PLC. You will create different industrial projects and simulate them on the software during the course tenure. This course is a blend of lecture videos, Step-by-step documents, and Live sessions to give a complete idea and knowledge of Industrial Automation to you. By the end of the course, you will be ready to write a PLC program for machines with DI, DO, AI and AO. You will be able to understand and create pneumatic and electro-pneumatic circuits depending on the industrial application. ,  Pneumatic Components Introduction, Creating Pneumatic connections on software and creating an Industrial Application ,  Electro-Pneumatic Components Introduction, Creating Pneumatic and electrical connections on software and creating an Industrial Application ,  Hardware identification of PLC , PLC Programming on basic instructions, Timers, Counters, and Digital I/OsProject: Programming a PLC for an Industrial Application ,  PLC programming on compare instructions and Analog I/Os Project: Programming a PLC (with analog Inputs and Outputs) for an Industrial Application ,  Self- project where in the participants will be given an opportunity to try out the use case that they have in mind using the simulation software to simulate and test their application ,   Is this limited to any stream?  Any knowledge of PLC is required before joining the course? Is this limited to any stream?No, Anyone interested in industrial Automation can join the course.Any knowledge of PLC is required before joining the course?No. You will be starting from the scratch but having prior knowledge will help you to complete the course early. ,  No, Anyone interested in industrial Automation can join the course. ,  No. You will be starting from the scratch but having prior knowledge will help you to complete the course early. ,  Workstation 1 is one of the assembly stations. This Station stores the raw part and inspects the parts using QR code scanner and vision sensor. Valve body is transferred from one station to another in a pallet. Pallet has a RFID tag,so that next station can read the value and get the information about the body present in the pallet. PLC Used: 1769-L33-ERM,Micrologix 1400 (Rockwell) Software Used: Studio 5000,RSlogix 500 and View ME(HMI designing)  Programming: Ladder Logic Programming, Safety Sensors (IO Link master), Pneumatics and 4 Axes Motion Programming. Workstation 2 is the next assembly station. This station inserts the child part in the base part. PLC Used: BnR Software Used: Automation Studio Programming: Ladder Logic/Structured text Programming, Safety Sensors (IO Link master), Pneumatics and 3 Axes Motion Programming.  Workstation 3 is one of the assembly stations. This Station assembles all the sub parts of Cotter joint assembly depending on the type of socket body approaching the station with the help of RFID. The Gripper Picks and Places the Cotter to engage socket and spigot. PLC Used: Mitsubishi MELSEC R-Series (Rack Type) Software Used: GX Works 3  Programming: Ladder Logic Programming, Safety Sensors, Pneumatics and 7 Axes Motion Programming.   ,  AutomationAugmented RealityIIoTMachine LearningDigital Twin ,  01Demonstration & Training ,  04Flexible Assembling ,  02Customer order processing ,  03Realtime dashboard ,  An AR application to show information about FSM Smart Manufacturing Kits  An AR application that gives the user a menu with 10 options for each of the FSM Smart Manufacturing Kit. The user can visualize all 3 components, the HMI, the Electronic Kit, and the Mechanism Kit. The user can click on the different parts and get to know about the parts. The user can also initiate the CAD explode view animation.  ,  An augmented reality application to provide self-guided training on the FSM PLC Kits. The user can scan the ThingMark on the Kit to load up the experience or can FSM PLC Kit Parts Introduction 2 use model target detection by aligning the on-screen guide with the real hardware and then click on the parts to know about them ,  This course is completely designed on the Codesys platform using Soft-PLC. Throughout this self-paced online course, participants will be trained on the basics of ladder logic programming, Visualization of a Human-Machine Interface for controlling the program parameters, and Motion programming with a basic linear axis motion to rotary of single-axis motion. This course also explains the communication between the edge tier & platform tier using a data aggregator software, an interface that is created between the Soft-PLC and the data aggregator using OPC-UA Server and Client plug-in. By the end of the course, you will be ready for programming a codesys platform-based hardware with HMI features, programming motion controller with Open PLC blocks, knowledge of how OPC-UA Server-Client works and how to communicate the data of a Soft-PLC on Codesys Driver. ,  Basics of codesys software and the basic instructions used in the ladder logic programming. ,  Designing a front-end UI for the operator to operate the parameters/tags of the program in the HMI. ,  Overview of function block programming, explaining how the single-axis linear system and the single-axis rotary index system with multiple stations. ,  Extracting the data out of the PLC to control and monitor the application remotely within the network. ,  Self- project where in the participants will be given an opportunity to try out the use case that they have in mind using the Soft-PLC along with HMI screens and remote monitoring. ,  Minimum hardware requirement1. 4GB Ram, i3 processor with windows 8 or above version. 2. Windows is a must. Software doesn\\u2019t run on macos or linux ,  1. 4GB Ram, i3 processor with windows 8 or above version. 2. Windows is a must. Software doesn\\u2019t run on macos or linux ,  PrerequisitesNo prerequisites are required ,  No prerequisites are required ,   Laptop/ PC minimum requirements  I don't know what PLC is should I join this course?  Is this limited to any Stream? Laptop/ PC minimum requirements?4GB Ram, i3 processor with windows 8 or above version.I don't know what PLC is should I join this course?Yes, you will get a chance to learn more about it.Where can I find The Economist?Its not limited, anyone with Automation interest can join this course. ,  4GB Ram, i3 processor with windows 8 or above version. ,  Yes, you will get a chance to learn more about it. ,  Its not limited, anyone with Automation interest can join this course. ,  Smart trainer kits are used to train industry and academic people and make them aware about Industry 4.0 technologies. It is a combination of three independent hardware accessories- PLC Trainer Kit, HMI Kit and Mechanism Kit. All these kits demonstrate the industry 4.0 technologies in the best possible way. These were designed, manufactured and integrated in FSM. Modules/Trainings covered in these kits: PLC Programming, Network Protocols HMI Designing Data Logging  Dashboard Designing, NodeRed IIOT gateways and platforms Augmented Reality Machine Learning Smart Sensing Motion configuration and programming Vision System   ,  This is one of the kits of the smart manufacturing trainer module. This kit has the brain of  the other two kits (HMI Kit and Mechanism Kit) as programming is done in this kit. It has a PLC for programming and digital inputs/outputs, analog inputs/outputs to connect the required sensors with the PLC. It has an IO link module to connect the smart sensors, so alongwith the 24VDC or analog input this module communicates the sensor status with the PLC. Data logging and data collection is one of the critical steps for IIOT  and for that we have integrated IOT gateway and other software platforms in this kit. To connect sensors with the PLC, banana connectors are used. It can communicate on a number of network protocols and it has the feature to communicate with multiple HMIs and Servo drives. In programming kit we have PLC hardwares from Rockwell, Siemens, Schneider, Omron, Delta, Turck and Mitsubishi for programming and various softwares. NUC is also integrated in the kit so that it can be used as CPU for softwares and PLC programming. So, this kit is more than sufficient to demonstrate the features of the PLC, gateways and software platforms (Data Logging, Augmented Reality ,IIOT gateways and platforms), Smart Sensing . ,  Human Machine Interface is used to monitor and access the PLC data. Screens can be created depending on the application.This is the second kit of the smart manufacturing trainer module. It has HMI to display the screens and monitor the PLC tags. The hardware buttons and LEDs as well which are connected with the PLC trainer kit using banana connectors, mostly like plug and play. These are used to test the PLC program and as input and output in the PLC program. HMIs used in these kits are smart HMIs which have smart features like OPC UA server/client, MQTT compatibility, user authentication on the screens, act as an edge device etc. So, kit is used to visualise the PLC logic. Additionally it demonstrates the HMI Designing and Dashboard designing feature. ,  This is the third kit of the smart trainer modules used to demonstrate a working manufacturing system. It has a servo motor and drive to rotate an indexing table. Along with the motion feature, it has four stations which can be used to demonstrate multiple operations. Each station has smart inductive sensors to sense the part's presence which consists of the distance and proximity sensors, servo drive, test product, RFID Reader, Solenoid, USB Camera mounted on them.Station 1: It has a RFID controller used to read and write the tag values of a product. It communicates with IO Link master (present in PLC trainer kit) and IO link master communicates the data with the PLC. So, RFID operation and use case is demonstrated. Station 2: This station consists of a distance sensor used to calculate the height or distance of the product. It is a smart sensor and communicates with IO Link master. So, along with the analog value it communicates it\\u2019s status to the PLC as well. Verification of product dimension is also demonstrated. Station 3: This station has a vision camera installed on it. This camera is used for image processing and product testing. Sorting operation is performed using the image processing feature. Station 4: This station has a solenoid which is directly connected with the digital output of the PLC. Extension and retraction of the solenoid is programmed in the PLC for this operation.This mechanism kit is used to demonstrate and train motion configuration and programming, Vision System, Smart Sensing, Machine Learning, Augmented Reality.  ,  Programming Kit ,  HMI Kit ,  Mechanism Kit ,  It is showing the working of Smart Manufacturing Kit ,  Education & Training ,  Device Services ,  Research & Skill Certification  ,  Software-> ,  Traditionally, manufacturing has been considered as a process that convert raw materials into physical products in the factories by managing resources with best automation practices available. ,  The digital factory concept offers an integrated approach to enhance the product and production engineering processes and simulation is a key technology within this concept. ,  Until now, industrial robots always worked separately from humans in specially safeguarded protected spaces. Smart manufacturing has broken down this barrier with a new generation of collaborative industrial robots. ,  A key component in making Industry 4.0 a reality are machines that can produce the desired components faster, more flexibly and more precisely than ever before. Also Consumers want products that reflect their individuality. ,  Augmented reality is the integration of digital information with the user's environment in real time. Unlike virtual reality, which creates a totally artificial environment, augmented reality uses the existing environment and overlays new information on top of it. ,  Networked production and control processes in complex machine environments determine the industrial future and make Industry 4.0 possible in the first place. Smart Sensors already today support dynamic, real-time-optimized, and self-organized industry processes. ,  Being able to assist customers remotely, service technicians could support their customers at any time and from anywhere, without necessarily having to visit the customer site. Remote access could also help to better prepare service technicians with the necessary information for their tasks. Knowing about the machine or system error in more detail beforehand saves valuable time because required spare parts or other equipment can ordered, prepared and brought along. ,  The world of automation is merging with the IT world. Safety & security is an important prerequisite for the function of Industry 4.0 systems, which in contrast to traditional production plants have interfaces to their environment. ,  An Augmented reality application that allows the user to understand about the mechanism kit and scan the image target and place a CAD model of the Mechanism Kit to understand it clearly. The user can create a new account and can access the application using the registered email id and password. If the user forgets the password associated with the registered email id, they can use the forgot password option and can create a new password for the registered email id. The user can the access the features of the application by using the main menu FSM Mechanism Kit Assembly and Disassembly 2 where different buttons are linked with the assembling and disassembling. The user can then play the animations of the screws, Allen Keys, screwdrivers, and the parts of mechanism kit. The steps can be played multiple times as per the requirements. The user can switch between the steps using the next and previous buttons. ,  Cloud DatabaseAugmented Reality ,  03Remote Maintenance ,  Mandated Guidelines  Awareness campaigns on Industry 4.0 Training for master trainers Active participation provisions for start-up / incubators Hand-holding of SMEs to plan and implement relevant Industry 4.0 projects to be done through consultancy services on a chargeable basis Collaborating with neighborhood universities for student training/internship programs Involving industry in SPV members model for sustainability Participating in a Government-formed platform for Industry 4.0 To make adequate provisions for e-waste management Involving as many clusters of 'capital goods' as possible  ,  At FSM we are committed to demystify the smart manufacturing technologies by learning ourselves and then transfer the learning through various training programs to industry and academicians. We are engaging researchers to indigenously develop technologies to make it affordable by Indian MSME and facilitate adoption of Industry 4.0. Our state of art cyber physical lab showcase technologies available across globe through our strong partnership with the automation industries. ,  With a far-sighted approach, the Government of India has supported Automation Industry and IIT Delhi in creation of advanced engineering and software facilities for smart manufacturing.  Prospective integrators, consultants and end users can use our training and tryout services to validate their proof-of-concept before scaling up. We help demystify and de-risk your investments in Industry 4.0 ,  Co-Creator ,  Dr. Sunil JhaDirector ,  Mr. Dilip SawhneyDirector ,  Dr. Anil WaliDirector ,  Sunil MehtaDirector ,  Mr. Anup WadhwaDirector Automation Industry Association ,  Mr. Ravi AgarwalDirector ,  The digital factory concept offers an integrated approach to enhance the product and production engineering processes and simulation is a key technology within this concept.  Simulation helps to create digital models of products, production systems, logistic systems so that one can explore a system\\u2019s characteristics and optimize its performance. These digital models have the ability to run experiments and what-if scenarios without disturbing existing production systems or \\u2013 when used in the planning process \\u2013 long before the real production systems are installed. Extensive analysis tools, such as bottleneck analysis, statistics and charts give us an opportunity to evaluate different manufacturing scenarios. The results provide us with the information needed to make fast, reliable, smarter decisions in the early stages of production planning. In addition, we can also optimize material flow, resource utilization and logistics for all levels of plant planning from global production facilities, through local plants, to specific lines. This helps to fulfil the user\\u2019s need to deliver just-in-time (JIT) or just-in-sequence (JIS).  Benefits  Increase existing system productivity  Optimize resource consumption and re-use  Optimize systems for reduced energy consumption  Shorten new product introduction, time-to market, and time-to-volume  Improve production layout and minimize investments  Ensure that machines and equipment are in the right place  Ensure that sufficient material handling equipment is available  Optimize buffer sizes  Ensure that product handling is kept to a minimumApart from advance simulation another disruptive innovation is the concept of digital twin. With the growing deployments of Internet of Things (IoT) systems, the importance of the concept of a digital avatar of a physical thing has gathered significant interest in the recent years. A digital twin can be defined, fundamentally, as an evolving digital profile of the historical and current behavior of a physical object or process that helps optimize business performance.A digital twin enables flexibility in manufacturing to reduce time needed for product design, manufacturing process and system planning and production facility design. A digital twin improves quality and even supports new business models that offer opportunities for small- to mid-size companies to expand and bring more high-tech capability into their shops. Digital twins will help all companies become more flexible, reduce time to market, reduce cost, improve quality and increase productivity at all levels of the organization. Digital twin business values: 1. Quality  Improve overall quality  Predict and detect quality trend defects sooner  Control quality escapes and be able to determine when quality issue started 2. Warranty cost and services  Understand current configuration of equipment in the field to be able to service more efficiently  Proactively and more accurately determine warranty and claims issues to reduce overall warranty cost and improve customer experiences 3. Operations cost  Improve product design and engineering change execution  Improve performance of manufacturing equipment  Reduce operations and process variability 4. Record retention and serialization  Create a digital record of serialized parts and raw materials to better manage recalls and warranty claims and meet mandated tracking requirements 5. New product introduction cost and lead time  Reduce the time to market for a new product  Reduce overall cost to produce new product 6. Revenue growth opportunities  Identify products in the field that are ready for upgrade   Improve efficiency and cost to service productThese digital twins use data from sensors that are installed on physical objects to represent their near real time status, working condition or position. Nonetheless, advances in computer science have made it possible to broaden the scope of the digital twin to include many more capabilities, information, inputs and outputs. It also helps you develop and introduce new products to the market much faster than ever.    ,  Under Samarth Udyog Mission of the Ministry of Heavy Industry (MHI), Govt. of India, IIT Delhi, and Automation Industry Association (AIA) together with Industry sponsors have set up common engineering facilities under the aegis of the IITD - AIA Foundation for Smart Manufacturing (FSM). These facilities are meant to demonstrate, support, and develop Smart Manufacturing concepts for Indian Industry & try them out in their own plants. The collaboration is also aimed at developing a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment.As part of our commitment to make FSM infrastructure available for the student community to explore and learn smart manufacturing technologies, FSM is offering 100 nos. 2-Months full-time Online Summer Internship from 01-June-2023 to 31-July-2023 under the theme of  Smart Factory\\u201d. ,  Registration Open ,  Last day to register ,  Short Listing ,  Orientation ,  Level 1 Learning Ends ,  Level 2 Technology Stream Learning Ends ,  Final Selection and Project Allocation ,  Orientation 2nd Programme & Internship Starts ,  Internship Ends ,  Registration  Short Listing Level 1 Learning Level 2 Technology Stream Learning Final Selection Project Allocation Internship Commencement  ,    Fill out the online registration form Shortlisting based on the eligibility criteria Level 1: Learning modules (Approx. time: 24 hrs) will be made available on fsmskills website. To be completed by 20th May 2023. Post your signup on fsmskill, you will gain access to the Level-1 course of IAFSM. This step involves learning of Smart Manufacturing Concepts and is the foundation course that is mandatory for all interns to qualify latest by 20th May 2023. You are required to go through recorded lectures and study the content thoroughly to clear the assignments of Level-1 in maximum 2 attempts. After 2 attempts, if you are not able to qualify for Level-1, your candidature will no longer be considered for internship.   Level 2 : After successful completion of Level-1, You will be redirected to the Stream Learning module which involves learning of specific domains of your choice. You can choose from the available domains and try out a maximum of 3 domains of your choice. You are then required to undergo and clear the assignments based on your selection and qualify the Level 2 assignments after which you shall be taken forward for Project Based Learning under Summer Internship 2023. The assignments are to be attempted and cleared latest by 28th May 2023. Internship Projects: After successful completion of Level-2, Interns will be allocated projects based on domain preference, level-2 performance and interaction with the mentors.  Final Selection and Project Allocation based on the Level 2 performance and preferences These are full-time internships and require 48 hours per week  ,   AR-based fault diagnosis of RWC Implementing AR for complete Demonstration of Robotic Welding Cell Unity ROS Cobot FSM AMR AR FSM Interactive lab introduction  ,  02Digital Twin ,   Digital Twin of Robotic Welding Cell for process optimization and Predictive Maintenance. Digital twin for Advanced Milling Machine Centre  ,  03Industrial Automation ,   CP Lab Autonomy Phase - 2 Multi Process Robotic Cell Simulation on a simulation platform Robotic Welding Cell Simulation on a simulation platform Training Course on Rockwell Kit Training Course on Siemens Kit  ,  04Industrial IoT ,   Implementing IIoT on CPL Autonomy Implementing IIoT for Plant Owner on Robotic Welding Cell  ,  05Machine Learning ,   Remaining Usable Life Estimation (NASA Turbine Dataset) Power Line Fault Detection Computer Vision to detect defects in PCB Power Line Fault Detection Steel Defect Detection Using Computer Vision  ,  06Manufacturing Execution System ,   Digital quality report generation for 3d prints. Admin & customer pages for Order Management Portal (RWC)  ,  07Real Time Dashboard ,   Visualization of Multi-Process Robotic Cell Interactive Portal for RWC: Supervisor  ,  08Robotics ,   MPRC OLP Generation using Sim4.1 for a product Use of AMR-Cobot to place pallet ROS Integration of AMR Integration of computer vision with Cobot Computer Vision Integration with Cobot  ,  0Project Domains ,  0No. of projects done ,  0Candidates completed the Internship ,  0Candidates applied ,  0Candidates achieved Level 1 proficiency ,  0Candidates were awarded with prize of INR 5000/- for Best Project Award ,  0Candidates were shortlisted ,  0Candidates were selected for presentation before Jury Members ,  0Research papers given merit certificate  ,  01Augmented Reality ,  02Industrial Automation ,  03Industrial IoT ,  04Machine Learning ,  05Real Time Dashboard ,  06Robotics ,  Here are some videos of our interns presenting their final projects in front of the jury members and their mentors. Jury members were invited from different industries with their expertise in respective domains. In the presentation, our interns explained their whole journey and gave the detailing of the projects. After reviewing all these projects, the top 10 interns got awarded the best project award in their domain and a cash prize of  5000. ,  The term safety denotes the functional safety of machinery or, put another way, the protection of people and the environment against threats that can proceed from machinery. Safety demands that residual risks arising from a plant or machine do not exceed acceptable values. This includes hazards to the plant environment (e.g. environmental damage) as well as hazards within the plant or machine (e.g. people inside the plant). One option for the worst case is simply to interrupt the energy supply straight away and bring the machine to a hard stop. The traditional way of providing scope for this is by means of special safety wiring and components such as safety relays. Because this approach is very much hardware-based and therefore static, it is not particularly suitable for intelligent manufacturing processes where plant layouts continually need to be changed. A hard shutdown is generally associated with further disadvantages, whether these involve loss of productivity, extended downtimes due to more complex recommissioning procedures or a restriction in the machine\\u2019s operating and maintenance concept.   An alternative is offered by dynamic safety concepts based on an integrated view of changing automation processes and functional safety requirements. This changes the view of safety itself; it is regarded less as a hardware characteristic and more as a cross-device function. This approach allows processes to be operated in a safely controlled manner without any need to interrupt them immediately every time a fault occurs. But the dynamic approach can only be implemented efficiently if functional safety is built into automation projects from the moment they are planned. ,  An Augmented Reality application to show the Real-time Values of the 4 stations of the FSM Smart Mechanism Kit by connecting with KEPServer and getting tag values ,  Augmented RealityIIoT ,  02Realtime Monitoring ,  Robotic Welding Cell demonstrates a flexible manufacturing cell meaning it has an inventory of its own, material handling system, variety of parts with dynamic-order.This welding cell can be a part of production line and act as standalone system.Use of single or multiple robots may involve use of a PLC also.This cell uses a saftey PLC.This cell has all these features and the basis of selection can be done in a way that the cell will be programmed, utilization of peripheral devices (proximity sensors, pneumatic cylinders), safety devices and Automatic Identification & Data Capturing (AIDC) devices like RFID, vision camera etc. The cell has following level of flexibility but the decision can be made on the basis of the flexibility required as per the following parameters:1. Variety of parts for simultaneous production 2. Change of schedule3. Ready for new partWorkstations and layout design :Workstations in the cell are as per the following given applications and subject to following parameters : 1. Load/Unload stations for the cell: It is the area where the raw materials are incepted in/out of the cell.2. Inventory storage area: An inventory storage where the storage of the raw material is kept.3. Inspection area: An area where the material post operations are inspected for quality. This is kept as a separate unit away from the cell but it can be an integral part of the cell itself.4. Operations area: An area where the operations like welding is performed. In the cell , this area is more of a workspace since two robots are responsible for performing welding on the material. And it can be anywhere in the robot's workspace. 5. Layout design: It is an integral part before identifying the robots and environment preparation and also plays a key role in safety of the cell.CAD Design & Simulation: The 3D visualization and detailing of the cell is done using a designing software. The robotic path simulation software asists in defining the best possible, collision free environment that is going to be the basis of the layout design and all other hardware that are going to be installed in the cell. Apart from designing & fabrication of the cell it helps in performing the robot simulations to generate offline program, collision free environment (this is how the level of flexibility achieved) for robots at operating stage and generating Augmented Reality applications. ,  The cell programming can be done in atleast two ways. Online programming where  teach pendant is used and other is offline programming where the simulation is done in a separate software like RoboDK and KUKA Sim4. This helps in visualising and performing collision free path generation for both the robots. The video below demonstrates the offline programming method where we can see two robots performing indexed type motion. The offline programming helps in virtual commissioning and without impacting the production.  ,  Simulation & Testing ,  Job work & research ,  Prototyping ,  Customer Order Proessing ,  Site Integration ,  Machine-as-a-service ,  <-Multi Process Robotic Cell ,  Mobile Collaborative Robot-> ,  Smart sensors are a prerequisite for creating the best possible basis for a future-oriented automation system. This is because the smart factory needs data that can principally only be provided by smart, intelligent and communication-enabled sensors. Communication-enabled means being able to exchange sensor data with a machine controller or a cloud-based application. Thus, for example, sensor parameters are automatically adapted to new production orders within seconds. Or a light barrier detects contamination of its optics and reports this directly to the control center.   Smart Sensors generate and receive data and information which goes beyond traditional switching signals or measured process parameters. They therefore enable substantial increases in efficiency, more flexibility, and better planning security for predictive plant maintenance. Depending on the requirement, Smart Sensors cover up to four dimensions of Smart Sensor technology.   1. Enhanced sensing 2. Efficient communication 3. Diagnostics 4. Smart tasks Just like smart sensors, smart actuators also have intelligence built into them. Some of the smart features possessed by different types of actuators are:   Open standards: Multi-protocol communication interface allow universal operation with diverse, ethernet-based communication protocols Web-based commissioning and diagnostics via integrated web server Comprehensive access to actuator data (e.g. torque or power), via web connector for preventive maintenance or database interfacing and data analysis Inbuilt smart sensors for capturing data Flexible configuration according to requirement Comprehensive condition monitoring for fast identification of critical conditions and comfortable analysis Simple connection to higher-level data systems without additional hardware Workpiece-dependent parameters setting guaranteeing quality results Integrated control system with browser-based operating system allows for information sharing across multi vendor data systems  ,  Robotic Welding Cell demonstrates a flexible manufacturing cell meaning it has an inventory of its own, material handling system, variety of parts with dynamic-order.This welding cell can be a part of production line and act as standalone system.Use of single or multiple robots may involve use of a PLC also.This cell uses a saftey PLC.This cell has all these features and the basis of selection can be done in a way that the cell will be programmed, utilization of peripheral devices (proximity sensors, pneumatic cylinders), safety devices and Automatic Identification & Data Capturing (AIDC) devices like RFID, vision camera etc. The cell has following level of flexibility but the decision can be made on the basis of the flexibility required as per the following parameters:1. Variety of parts for simultaneous production2. Change of schedule3. Ready for new partWorkstations and layout design :Workstations in the cell are as per the following given applications and subject to following parameters : 1. Load/Unload stations for the cell: It is the area where the raw materials are incepted in/out of the cell.2. Inventory storage area: An inventory storage where the storage of the raw material is kept.3. Inspection area: An area where the material post operations are inspected for quality. This is kept as a separate unit away from the cell but it can be an integral part of the cell itself.4. Operations area: An area where the operations like welding is performed. In the cell , this area is more of a workspace since two robots are responsible for performing welding on the material. And it can be anywhere in the robot's workspace. 5. Layout design: It is an integral part before identifying the robots and environment preparation and also plays a key role in safety of the cell.CAD Design & Simulation:The 3D visualization and detailing of the cell is done using a designing software. The robotic path simulation software asists in defining the best possible, collision free environment that is going to be the basis of the layout design and all other hardware that are going to be installed in the cell. Apart from designing & fabrication of the cell it helps in performing the robot simulations to generate offline program, collision free environment (this is how the level of flexibility achieved) for robots at operating stage and generating Augmented Reality applications. ,  AutomationIIoTRoboticsAugmented Reality ,  01Machine as a service ,  02Customer Order Proessing ,  03Job work and research ,  3D printing has the capability to be used to respond too many of the world\\u2019s changing megatrends. The physical object is made from a three-dimensional digital model, typically by laying down many thin layers of a material in succession. With 3D printing it is possible to go directly from digital design data to a final part with no intermediate production steps. 3D printing technologies therefore eliminate the need for tooling and the associated capital investment. The result is that companies that adopt 3D printing can disrupt the traditional economies of scale, by allowing cost-effective production of single-unit or low-volume batches with low-volume part production, products can be customized to local markets, or even to individual customer tastes, driving adoption within industries as diverse as fashion, health care and automotive. Moreover, with the ability to print on demand, businesses also have the opportunity to eliminate inventory and cut aftermarket lead-times by providing digital spare-parts catalogues that can be printed when needed. The smart companies of the future will be those that have a clear strategy for how and where 3D printing fits within their supply chain and their value chain. They will also understand the business drivers to adoption.   From the student\\u2019s study to the professional designer\\u2019s office, from the dental laboratory to the jewellery retailer, from the aerospace factory to the hospital basement, 3D printers have become invaluable business tools. Applications and reasons are as diverse as the users. What links all these applications and users is one underlying ability: to transition 3D information digitally and seamlessly from the virtual world to the real world with nothing but a computer and a3D printer \\u2013 from bytes to bits.   The benefits of 3D printing today go way beyond just making models and prototypes. 3D printing is becoming a way of making components, systems and products sold across the supply chain, from the bracket in the aircraft door to the dental aligner in the teenager\\u2019s mouth. It can also be used for the manufacturing of tools, jigs and fixtures in addition to rapid prototyping. ,  An AR application designed to run on HoloLens 2 to demonstrate the entire sequence for Motor Replacement in the FSM Smart Mechanism Kit.The application uses a model target to detect the real mechanism kit and then superimpose the AR kit.The application will guide in tool selection and then show the steps to replace the motor.Voice updates are given to the user with each step.The user can also control the application sequence using voice commands. ,  Augmented RealityMicrosoft HoloLens 2 ,  01Self-Guided Training ,  04Self-Guided Maintenance ,  02Action Latency Reduction ,  03Insight Latency Reduction ,  IITD-AIA Foundation For Smart Manufacturing presents a comprehensive Learning Module on  Industrial Automation and IoT using soft-PLC Program, visualize, execute remote monitoring, motion programming and more using soft-PLC on the upcoming Learning Module. This program is meant for Engineering Students and Industry Freshers wanting to gain practical learning in the field of Industrial Automation which is foundation for Smart Manufacturing implementation.Learning content prepared under guidance of Prof. Sunil Jha ,  IITD-AIA Foundation For Smart Manufacturing presents a 5 Days/10 Hours Online Self Learning Program on components and integration for Smart Manufacturing. This program is meant for Engineering Students and Industry Freshers wanting to gain practical learning in the field of Industrial Automation which is foundation for Smart Manufacturing implementation.Learning content prepared under guidance of Prof. Sunil Jha ,   ,  IITD-AIA Foundation For Smart Manufacturing presents 4 hours free awareness course on Industrial Automation Learning. This is a supplement course helpful for the upcoming 5 Days/10 Hours Online Self Learning Program on components and integration for Smart Manufacturing ,  or email us oninfo@iafsm.in ,  Smart Lathe Machine project is about retrofitting of Sensors and PLC for Digitizing the Cutting Parameters. Additionally for the monitoring of Power Consumption, the energy meter is in place to find out the power related parameters. The idea is to digitize the data and add operator and machine safety interlocks to avoid accidents in the shop floor. Also, the digitized data will be used in implementing Industrial IoT dashboards for monitoring purposes. The cutting parameters along with energy data is then used for training the machine model to predict the roughness or the remaining useful life of the tool depending on the vibration signals acquired through the vibration sensor. The Augmented Reality experience is created around the machine for giving basic nomenclature of Lathe machine. The animation of each process is also part of the experience. ,  AutomationIIoTMachine LearningAugmented Reality ,  01Augmented Reality for guiding the students learn the different components of the machine ,  04Real-Time Health Monitoring of Assets in Factory ,  02Augmented Reality with guided  exercises for maintenance. ,  03Machine learning for predicting the tool wear. ,  Contact us today for implementing ,  Call us for any query011-26582053, 8076197190 ,  or email us oninfo@iafsm.in   We\\u2019ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using twitter.com. You can see a list of supported browsers in our Help Center. ,  Help Center ,   Terms of Service Privacy Policy Cookie Policy Imprint Ads info       \\u00a9 2023 X Corp.      ,   Level 2 : After successful completion of Level-1, You will be redirected to the Stream Learning module which involves learning of specific domains of your choice. You can choose from the available domains and try out a maximum of 3 domains of your choice. You are then required to undergo and clear the assignments based on your selection and qualify the Level 2 assignments after which you shall be taken forward for Project Based Learning under Summer Internship 2023. The assignments are to be attempted and cleared latest by 28th May 2023. ,  Internship Projects: After successful completion of Level-2, Interns will be allocated projects based on domain preference, level-2 performance and interaction with the mentors. ,  Short term education training offered along with online learning and assessment tool. Participants are engaged for approximately 100 hours in different technologies that include Automation, Industrial IoT, Augmented Reality, Robotics, Digital Twin and etc. The learnings are divided into Awareness Level, Learning Level and Expert Level. ,  CPS facilities and the associated technologies will provide for one-stop shop for users whose needs are cut across multiple disciplines and who wants to witness comprehensive digital transformation before taking up the actual implementation. ,  We are providing following services: ,  Indian Institute of Technology Delhi (IITD) and Automation Industry Association (AIA) joined hands in May, 2017 to set up a center under auspices of Samarth Udyog - a project of the Ministry of Heavy Industries (MHI). The center is called Foundation for Smart Manufacturing (FSM), and it helps supports and develops technologies for right understanding and implementation of concepts of smart manufacturing. FSM is a demo-cum-experience facility in North India, vests in extensive skill building, MSME consultancy, multi-academia partnerships and research which will give a huge fillip to technology aided competitiveness of Indian manufacturing. The project will imbibe technologies from Europe, Japan, USA and India. 'Producing Smarter' with Technologies. FSM has been launched specifically for implementation of smart manufacturing in India which it undertakes to do effectively by: Awareness Building, Prototyping, Simulation and testing Services, Consulting Services, Site Integration Services, Education and Training, Skills Certification, Job work and Research. ,  Director ,  info@iafsm.in ,  FSM is providing an exciting opportunity for 100 individuals to participate in a summer internship program. The program is entirely online and will run full-time from June 1, 2023, to July 31, 2023, for a duration of two months. The focus of the internship is on the theme of \\ Smart Factory,\\  which is a rapidly growing industry. This internship program is an excellent chance for individuals to gain valuable knowledge and experience in this field. It is an excellent opportunity for those who are looking to expand their skills and gain practical experience in this exciting area. If you are interested, don't miss this chance to be a part of the program and enhance your career prospects. ,  FSM is focussed on enabling people from becoming Smart to Samarth (capable) fraternity by creating awareness, step-wise learning and becoming an expert from domains driving Industry 4.0 ,     \""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_chunks(context, chunk_size=512, stride=100):\n",
    "# chunk_size=512\n",
    "# stride=50\n",
    "    chunks = []\n",
    "    total_words = len(context.split())\n",
    "    start = 0\n",
    "    end=512\n",
    "    #print(total_words)\n",
    "    while end < total_words:\n",
    "        end = min(start + chunk_size, total_words)\n",
    "        print(start,end)\n",
    "        chunk= \" \".join(context.split()[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start = end-stride\n",
    "        \n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model/distilbert-custom'\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model='bert-large-uncased-whole-word-masking-finetuned-squad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 512\n",
      "412 924\n",
      "824 1336\n",
      "1236 1748\n",
      "1648 2160\n",
      "2060 2572\n",
      "2472 2984\n",
      "2884 3396\n",
      "3296 3808\n",
      "3708 4220\n",
      "4120 4632\n",
      "4532 5044\n",
      "4944 5456\n",
      "5356 5868\n",
      "5768 6280\n",
      "6180 6692\n",
      "6592 7104\n",
      "7004 7516\n",
      "7416 7928\n",
      "7828 8340\n",
      "8240 8752\n",
      "8652 9164\n",
      "9064 9576\n",
      "9476 9988\n",
      "9888 10400\n",
      "10300 10812\n",
      "10712 11224\n",
      "11124 11238\n",
      "loop: 1\n",
      "At FSM we provide various Client services and training under the domain of Smart Manufacturing. The services will enable clients to test and debug problems before installing the solution at the site & also allow them to experiment and innovate with an appropriate mix of standard and customized solutions. , Consulting , Skill Certification , Research , Foundation for Smart Manufacturing (FSM) helps, supports, and develops Smart Manufacturing concepts for Indian Industry to witness, ideate, and try out in their plants. FSM also aims for a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment.FSM Skills is a holistic platform for providing immersive training experience through Live lectures, Online learning, Live demonstrations, Live Labs & Self paced exercises on remotely accessible actual hardware. , Academic strength of IIT Delhi brought interdisciplinary learnings to FSM. Expert Faculty members from various departments contribute to it. , FSM has highly trained manpower to implement the Industry 4.0 projects in guidance with experienced faculty members and industry partners. , M.Tech and Ph.D students doing research in Smart manufacturing are contributing to FSM technologies and increase its knowledgebase. , FSM brought industry partners from MNCs operating all across the globe to bring rich experience in the smart manufacturing technologies. , The Automation Industries Association (AIA) in its quest to set up a Common Engineering Facility Center (CEFC) at IIT Delhi has brought together experts from various industries in the sector of automation. These experts look forward to work together and use their industrial experience along with various verticals to initiate smart manufacturing in India. The following firms have agreed to come together to set up the CEFC. They comprise Technology & Investment Partners, Simulation &amp; Integration Partners and Machinery Partners. , Fill out the online registration form Shortlisting based on the eligibility criteria Level 1: Learning modules (Approx. time: 24 hrs) will be made available on fsmskills website. To be completed by 20th May 2023. Post your signup on fsmskill, you will gain access to the Level-1 course of IAFSM. This step involves learning of Smart Manufacturing Concepts and is the foundation course that is mandatory for all interns to qualify latest by 20th May 2023. You are required to go through recorded lectures and study the content thoroughly to clear the assignments of Level-1 in maximum 2 attempts. After 2 attempts, if you are not able to qualify for Level-1, your candidature will no longer be considered for internship. Level 2 : After successful completion of Level-1, You will be redirected to the Stream Learning module which involves learning of specific domains of your choice. You can choose from the available domains and try out a maximum of 3 domains of your choice. You are then required to undergo and clear the assignments based on your selection and qualify the Level 2 assignments after which you shall be taken forward for Project Based Learning under Summer Internship 2023. The assignments are to be attempted and cleared latest by 28th May 2023. Internship Projects: After successful completion of Level-2, Interns will be allocated\n",
      "exact_answer Foundation for Smart Manufacturing\n",
      "confidence_score 0.9852763414382935\n",
      "foundation for smart manufacturing ( fsm ) helps, supports, and develops smart manufacturing concepts for indian industry to witness, ideate, and try out in their plants.\n",
      "loop: 2\n",
      "After successful completion of Level-1, You will be redirected to the Stream Learning module which involves learning of specific domains of your choice. You can choose from the available domains and try out a maximum of 3 domains of your choice. You are then required to undergo and clear the assignments based on your selection and qualify the Level 2 assignments after which you shall be taken forward for Project Based Learning under Summer Internship 2023. The assignments are to be attempted and cleared latest by 28th May 2023. Internship Projects: After successful completion of Level-2, Interns will be allocated projects based on domain preference, level-2 performance and interaction with the mentors. Final Selection and Project Allocation based on the Level 2 performance and preferences These are full-time internships and require 48 hours per week , The robot becomes the third arm of the human operator. This new form of collaboration opens up previously inconceivable possibilities for the smart factory of the future. As collaborative robots operate without physical safeguards, they have to permanently calculate the risk of colliding with humans, constantly checking this via the robot controller. Collaborative robots works hand in hand with the operator, thereby enabling him to work more efficiently, more ergonomically, more precisely and with greater concentration. As a robot that can genuinely be deployed universally, it is defining new standards on the road to the fourth industrial revolution. Collaborative robots can be programmed onsite by the employees and can be quickly re-tasked to do multiple jobs quickly. They are lightweight and can be moved around easily in the production facility. Collaborative robot have integrated sensors, passive compliance or over current detection as safety features. The integrated sensors will feel external forces and, if this force is too high, the robot will stop its movement. Passive compliance is produced by mechanical components. If an external force acts on a joint, this joint will submit itself to this force. So, in case of a collision, the joint will move in the opposite direction avoiding any injury. Also, an over current can be detected when a collision occurs. This is another safety feature, because the software can generate a security stop when it detects a current spike. Some of the applications of collaborative robots can be: Assembly Soldering Vision based quality inspection Machine Tending Gluing Screwing Pick and place Operating hand tools Laboratory work , Multi Process Robotic Cell demonstrates a flexible manufacturing cell. This cell is an assembly line where components of a main part gets assembled, the main part comprises of minimum of 7 sub-parts and more, which are then assembled by placing, inserting and part-screwing the main part. It has multiple stations which performs operation on the parts (like valve body assembly, vision inspection, testing, packaging). The main feature of the cell is exhibited using the programming, control and diagnosis of the robotic manipulator amongst other peripheral and safety devices. We call it as Multi Process robotic cell because it can be used for more than one manufacturing process. There are different stations in the robotic\n",
      "exact_answer .\n",
      "confidence_score 0.17592334747314453\n",
      "\n",
      "loop: 3\n",
      "line where components of a main part gets assembled, the main part comprises of minimum of 7 sub-parts and more, which are then assembled by placing, inserting and part-screwing the main part. It has multiple stations which performs operation on the parts (like valve body assembly, vision inspection, testing, packaging). The main feature of the cell is exhibited using the programming, control and diagnosis of the robotic manipulator amongst other peripheral and safety devices. We call it as Multi Process robotic cell because it can be used for more than one manufacturing process. There are different stations in the robotic cell: 1. Conveyor Station: Use to transfer the inventory tray or pallet to the place where robot can pick them.2. Assembly Station: All the parts (axisymmetric and prismatic parts) will be assembled and screwed on the valve body in this station. Along with that inventory scanning and vision inspection of the valve bodies will be done.3.Testing Station: All the pneumatic ports of the valve body will be tested in this station. If there is any leakage, valve body will be rejected.4. Hex-nut Assembly Station:- Hex nut will be assembled on the body in this station.5. Packaging Station: Assembled valve bodies will be placed in a box and packaging is done. A printing head will print the required details( type of bodies, number of bodies, date of assembly etc) on the box and then the box will be dispatched. , The video here demonstrates the standalone function of loading inventory using trays from conveyor station to assembly station. The tray has multiple arrays of different sized part but same variety. There are trays with 3/2, 5/2, 5/2 double solenoid, 5/3 solenoid valve body. The end-effector of the robot have more than one tool attachments. This is possible due to tool changer allowing robot to perform multiple actions like pick and place, part screwing, gripping via vacuum suction cup, bar code part scanning. , Training , <-Cyber Physical assembly line , Robotic Welding Cell-> , This Multi-purpose Robotic Cell is assembling different variants of direction control valves. It has different stations which performs different operations on the valve body. Assembly,Vision Inspection,Testing,Packaging are some of the operations that can be performed by this cell. The main feature of this cell is that all the programming is done on PLC, use of teach pendant or robot controller programming has been Bypassed. As we can use this cell for multiple purpose,we call it as Multi-Process Robotic Cell. , There are different station in the robotic cell:1.Conveyor station:- Use to transfer the inventory tray or pallet to the place where robot can pick them.2. Assembly Station:- All the parts (Axisymmetric and prismatic parts) will be assembled and screwed on the valve body in this station. Along with that inventory scanning and vision inspection of the valve bodies will be done in this station.3.Testing Station:- All the ports of the valve body will be tested in this station. If there is any leakage, valve body will be rejected.4.Hex nut assembly station:- Hex nut will be placed on the body\n",
      "exact_answer Multi-Process Robotic Cell\n",
      "confidence_score 0.7466012239456177\n",
      "\n",
      "loop: 4\n",
      ", There are different station in the robotic cell:1.Conveyor station:- Use to transfer the inventory tray or pallet to the place where robot can pick them.2. Assembly Station:- All the parts (Axisymmetric and prismatic parts) will be assembled and screwed on the valve body in this station. Along with that inventory scanning and vision inspection of the valve bodies will be done in this station.3.Testing Station:- All the ports of the valve body will be tested in this station. If there is any leakage, valve body will be rejected.4.Hex nut assembly station:- Hex nut will be placed on the body in this station.5. Packaging station :- Assembled valve bodies will be placed in a box and packaging is done. A printing head will print the required details( Type of bodies ,number of bodies, date of assembly etc…) on the box and then the box will be dispatched. , 1.Siemens PLC:- Siemens S7 1516 is the master plc in this station and it is responsible for all the programming in the cell.2. DI and DO: - 32-point digital input and 32 point digital output module is connected on the base rack with the plc.3. 6 Axis Kuka robot and one axis:- 6 Axis kuka robot performs all the motion operation in the cell.7th axis rotates the valve body during assembly and inspection.4. QR code scanner:- QR code scanner performs the inventory check as it scans the QR code present on body. After scanning a body, plc gets the data of that particular body and its location on the tray.5. Laser based Vision sensor:- This sensor inspects all the four faces of the body and if it is OK then the station will pass the body to next station or else it will reject the body and picks another body of the same type.6. Tool Changers :- Different slave tool changersare used for different operations. These slave tool changers engages with the master tool changer(Present on the Robot arm) when required. Tool changers in this cell are used for:- QR code scanner,Pneumatic gripper and Screwdriver, Vacuum Gripper , Software , Mobile Collaborative Robot , Cyber Physical Factory , We are providing following services: 3D printing Smart Manufacturing Training Kits for Industrial Automation learning MIG Welding (including Wire-arc-additive-manufacturing) , Multimaterial 3D printer , Smart Manufacturing Training Kits , MIG Welding Cell , A system consisting of 3 parts 1. Python code 2. Notification System 3. AR Application The system is designed to automatically detect any error occurring in the Work Station 1 and raising an alert, the user then using HoloLens 2 will follow the steps to resolve the error , IIoTAugmented Reality , The Multi-material Additive Manufacturing Machine is a versatile machine made by Hyrel 3D and AMS. It is not 'just a 3D printer'. It is a Large format, Rapid Prototyping, Research, Manufacturing and Educational Platform. This 3D printer is customizable on various levels: build volume, print bed, extruder, and more. It is equipped with the capacity to attach 5 tool heads simulatneously. We have tool heads for printing common FDM filaments(PLA, ABS,\n",
      "exact_answer Large format, Rapid Prototyping, Research, Manufacturing and Educational Platform\n",
      "confidence_score 0.10874813795089722\n",
      "\n",
      "loop: 5\n",
      "error occurring in the Work Station 1 and raising an alert, the user then using HoloLens 2 will follow the steps to resolve the error , IIoTAugmented Reality , The Multi-material Additive Manufacturing Machine is a versatile machine made by Hyrel 3D and AMS. It is not 'just a 3D printer'. It is a Large format, Rapid Prototyping, Research, Manufacturing and Educational Platform. This 3D printer is customizable on various levels: build volume, print bed, extruder, and more. It is equipped with the capacity to attach 5 tool heads simulatneously. We have tool heads for printing common FDM filaments(PLA, ABS, PC, PEEK), clays, biologicals, flexibles, UV-curables, RTV Silicones, etc. It is highly evolutive and also offers options for 4th and 5th axes, PCB milling tool, 3-phase machining tool and CO2 or Diode lasers (laser cutting). , Smart Manufacturing Training Kit-> , Cyber Physical Assembly Line demonstrates smart manufacturing and comes with different functionalities. It includes the Custom order processing, valve body, spool, solenoid, connector, valve functioning testing, packaging, inkjet printing. It consists of three work stations and one MPRC.Workstation 1: It is also known as Raw part storage, part loading and quality check. It uses the Rockwell PLC. It stores Product and do Pick & place arrangement for mounting the product on pallet. Workstation 2: It is also known as axisymmetric part storage quality check and inspection work station. It uses B & R PLC. It stores spool and do pick and place arrangement for inserting the spool in valve body. It uses proximity sensor for inventory check. Workstation 3: It is also known as Prismatic Part Assembly and Screwing Workstation. It uses the Mitsubishi PLC. It stores all prismatic parts. It is used to place and tighten all the parts to valve body.Multi Process Robotic Cell (MPRC) :Click here to know more. Conclusion: All the station can run in Auto/Manual Mode. This is how the cyber physical assembly line works. There are features in the line such as smart sensing, Machine to Machine communication, smart dashboard, remote monitoring, alerts and notifications on email, safety, remote maintenance and Augmented Reality. , Simulation & Testing Services , Prototyping, Consulting Services , Skills Certification , Site Integration Services , Job Work & Research , Multi Process Robotic Cell-> , Augmented reality is one of the cutting edge technologies involved in the industry 4.0 trend when talking about smart manufacturing, it is a technology which was seen just as a fancy toy until a few years back, but which has now reached the right level of maturity to be employed in a productive environment. AR applications can become even more powerful by augmenting them with data generated by another set of technologies, revolutionizing the marketplace called the Internet of Things (IoT). Combining AR and the IoT allows employees, such as field maintenance workers, to access vital machine operating statistics to assist in maintenance decisions, or an assembly worker to visually receive pick and place instructions and alerts if tools are working incorrectly or are out of tolerance. Key AR ecosystem components include device hardware, an\n",
      "exact_answer Augmented reality\n",
      "confidence_score 0.16315582394599915\n",
      "\n",
      "loop: 6\n",
      "years back, but which has now reached the right level of maturity to be employed in a productive environment. AR applications can become even more powerful by augmenting them with data generated by another set of technologies, revolutionizing the marketplace called the Internet of Things (IoT). Combining AR and the IoT allows employees, such as field maintenance workers, to access vital machine operating statistics to assist in maintenance decisions, or an assembly worker to visually receive pick and place instructions and alerts if tools are working incorrectly or are out of tolerance. Key AR ecosystem components include device hardware, an OS open to third-party application development, and a platform for software, as well as content creation and management. The standard device hardware for viewing AR applications has predominantly been smartphones and tablets due to their wide availability and exceptional compute power. The newer devices expected to accelerate enterprise AR adoption because they allow hands-free access to information are smart glasses, HMDs, and other digital eyewear solutions from companies such as Microsoft, ODG, Epson, and Vuzix. Augmented reality renders 3D objects in real time into your field of vision. For example, looking through the cover of a machine and seeing its internal component structure. Augmented Reality (AR) is a technology enriching the real world with digital information and media, such as 3D models and videos, overlaying in real-time the camera view of your smartphone, tablet, PC or connected glasses. On the spectrum between virtual reality, which creates immersive, computer-generated environments, and the real world, augmented reality is closer to the real world. Augmented reality adds graphics, sounds, haptic feedback and smell to the natural world as it exists. Both video games and cell phones are driving the development of augmented reality. The methods by which AR is achieved can generally be split into two broad categories: Marker-based, and markerless. Marker-based Systems: This technology uses physical-world symbols as a reference point for computer graphics to be overlaid. For example, a 2-dimensional printed marker is placed in front of a webcam. The computer then interprets this symbol to overlay an on-screen graphic as if it were directly on top of the marker in the physical world. There have been several notable uses, most commonly in marketing Markerless Systems: By contrast, this technological approach has given rise to ‘mobile augmented reality’, denoting use of the technology with devices such as smartphones and tablets. This method uses a combination of an electronic devices’ accelerometer, compass and location data (such as the Global Positioning System – GPS) to determine the position in the physical world, which way it is pointing and on which axis the device is operating. This location data can them be compared to a database to determine what the device is looking at, and thus allows computer data/graphics to be displayed on-screen. Applications of AR in industrial environment: 1. Data Reuse: AR applications allow more efficient reuse of existing enterprise application data. Enterprise application data can include maintenance records, service tickets, and usage logs—any combination of which can be tapped into to decorate an AR\n",
      "exact_answer Global Positioning System – GPS\n",
      "confidence_score 0.2149752974510193\n",
      "marker - based systems : this technology uses physical - world symbols as a reference point for computer graphics to be overlaid. for example, a 2 - dimensional printed marker is placed in front of a webcam. the computer then interprets this symbol to overlay an on - screen graphic as if it were directly on top of the marker in the physical world. there have been several notable uses, most commonly in marketing markerless systems : by contrast, this technological approach has given rise to ‘ mobile augmented reality ’, denoting use of the technology with devices such as smartphones and tablets.\n",
      "loop: 7\n",
      "data (such as the Global Positioning System – GPS) to determine the position in the physical world, which way it is pointing and on which axis the device is operating. This location data can them be compared to a database to determine what the device is looking at, and thus allows computer data/graphics to be displayed on-screen. Applications of AR in industrial environment: 1. Data Reuse: AR applications allow more efficient reuse of existing enterprise application data. Enterprise application data can include maintenance records, service tickets, and usage logs—any combination of which can be tapped into to decorate an AR experience that blends the physical and digital worlds. 2. Data Contextualization: AR applications can be used to better contextualize information across a range of industries and job functions. In manufacturing, this could mean giving linemen and plant personnel the ability to abstract backend systems information for 3D product navigation, step-by-step work instructions, and remote visual guidance. 3. Work Error Reduction: AR applications can reduce errors made by workers in various occupational tasks. Whether the error is caused by too little information, too much information, or poor quality information, AR applications place the right information and instructions at the location of the work task. 4. Workforce Multiplier: AR applications are a workforce multiplier in two ways. First, training resources are more effective and efficient. Training hours can be reduced because AR applications can include video instructions on repair/replacement tasks overlaid on the machines themselves. Second, workers can do more by themselves versus sending multiple workers or truck rolls to address the same problem or work task. 5. Safety: AR applications can also improve the safety of a work task. For instance, AR applications can include not only written instructions for removing or replacing a part on a machine, but can also include visual instructions. This assistance avoids unnecessary and possibly unsafe interaction with the machine or object. , The Mobile Collaborative Robot (MCR) is developed to achieve autonomous material transportation within the Cyber Physical Factory. The MCR consists of a TM5M700 collaborative robot mounted on top of an Addverb Automated Mobile Robot (AMR). The AMR uses a LIDAR and two depth cameras to navigate using Natural Navigation. It has a payload of 150 kg. The AMR runs on Robot Operating System (ROS). The collaborative robot mounted on top of the AMR has a camera on it. The cobot can be programmed using ROS or the TMFlow software. The feed from the camera can be used for object detection. The cobot has a payload of 6 Kg. The MCR can also be controlled using a Fleet Management System. The MCR can be dispatched to various locations in the map using REST Api communication through the Fleet Management System. , Coming Soon.. , <-Robotic Welding Cell , Cyber Physical Factory-> , Short-term education and training courses will be offered along with on-line learning and assessment tools to educators and users on a chargeable basis. All the 12 technology streams will be covered. , The domain of Smart Manufacturing is expected to open up a new\n",
      "exact_answer Global Positioning System – GPS\n",
      "confidence_score 0.14320145547389984\n",
      "[CLS]\n",
      "loop: 8\n",
      "be used for object detection. The cobot has a payload of 6 Kg. The MCR can also be controlled using a Fleet Management System. The MCR can be dispatched to various locations in the map using REST Api communication through the Fleet Management System. , Coming Soon.. , <-Robotic Welding Cell , Cyber Physical Factory-> , Short-term education and training courses will be offered along with on-line learning and assessment tools to educators and users on a chargeable basis. All the 12 technology streams will be covered. , The domain of Smart Manufacturing is expected to open up a new opportunity in industrial consulting, especially with regard to identification and removal of bottlenecks in current operations. The CEFC multi-disciplinary teams will undertake feasibility surveys, ROI analysis and process improvement studies for clients, prior to implementation and also post implementation. , Many times clients wish to test out the Proof-of-Concept on their actual production lines. The CEFC team assigned to the Client during concept formulation will undertake such site activities with a pool of industry solution providers and system integrators. , It is expected that Skill Councils such as Automotive Skill Council, Capital Goods Skill Council,Industrial Automation Skill Council and Tool Rooms will be creating their unique set of Role based competencies. The CEFC will offer them and their Training Partners, a gap filling option for theory and practical, and a brand-agnostic independent certification. , The research team will help users to bring uniqueness into their solution while providing adequate safeguards for IP protection. Users can sponsor prototyping or R&D projects as per their need. , IAFSM will take up research projects in consultation with industry for development of cyber physical systems for machine tools, industrial IoT, machine data cloud, machine controllers etc. to bridge the technology adoption gap in manufacturing. These research projects will be executed with clear objectives to meet focussed technology requirement for smart manufacturing and easy adoption by the industries. The developed technologies will be licensed further for commercialization to interested industries. , The CPS facility and the associated technologies will provide a one stop shop for users whose needs cut across multiple disciplines and who want to witness a comprehensive digital transformation before taking up for actual implementation. This will enable clients to experiment and innovate with an appropriate mix of standard and customised solutions. , The testing service will enable clients to test and debug problems before installing the solution at site. , Multi Process Robotic Cell , Smart Lathe Machine , Robotic Welding Cell , FSM AR Demo , Mechanism Kit Assembly and Disassembly , AR Maintenance Using HoloLens , Expert Maintenance System Using HoloLens , Cyber Physical Assembly Line , CP Lab Autonomy , Smart Mechanism Kit Realtime Values , PLC Kit Parts Introduction , Smart Mechanism Kit Motor Replacement , To create user defined webpages to control and monitor different devices (Appliances,machines) present in CP lab. , 01Remote Control and monitoring of assembly line, Compressor and MPRC , 02Remote control and monitoring of domestic appliances (lights,fans,AC) , 03User defined access to control the machines\n",
      "exact_answer FSM AR Demo\n",
      "confidence_score 0.1700964868068695\n",
      "what is fsm? [SEP] be used for object detection. the cobot has a payload of 6 kg. the mcr can also be controlled using a fleet management system. the mcr can be dispatched to various locations in the map using rest api communication through the fleet management system., coming soon.., < - robotic welding cell, cyber physical factory - >, short - term education and training courses will be offered along with on - line learning and assessment tools to educators and users on a chargeable basis. all the 12 technology streams will be covered., the domain of smart manufacturing is expected to open up a new opportunity in industrial consulting, especially with regard to identification and removal of bottlenecks in current operations.\n",
      "loop: 9\n",
      ", Smart Lathe Machine , Robotic Welding Cell , FSM AR Demo , Mechanism Kit Assembly and Disassembly , AR Maintenance Using HoloLens , Expert Maintenance System Using HoloLens , Cyber Physical Assembly Line , CP Lab Autonomy , Smart Mechanism Kit Realtime Values , PLC Kit Parts Introduction , Smart Mechanism Kit Motor Replacement , To create user defined webpages to control and monitor different devices (Appliances,machines) present in CP lab. , 01Remote Control and monitoring of assembly line, Compressor and MPRC , 02Remote control and monitoring of domestic appliances (lights,fans,AC) , 03User defined access to control the machines remotely , 04Activity logging of users , 05Remote Control of the training Kits to train people remotely , Traditionally, manufacturing has been considered as a process that convert raw materials into physical products in the factories by managing resources with best automation practices available. Today, drivers such as technology, sustainability, optimization and the need to meet customer demands have once again encouraged the transformation of the manufacturing industry to become adaptive, fully connected, and aware of its own power quality. One of the most significant trends in manufacturing is of improved information technology solutions involving the union of conventional automation with the information technology. Cyber-physical systems (CPS) are enabling technologies which bring the virtual and physical worlds together to create a truly networked world in which intelligent objects communicate and interact with each other. They are \\ enabling technologies\\ which make multiple innovative applications and processes a reality as the boundaries between the real and virtual worlds disappear. Cyber-physical systems provide the basis the creation of an Internet of Things (IoT) which makes smart services and products possible. A cyber-physical system (CPS) is a thing in the Internet of Things. It is a combination of mechanical, electronic and software components that communicate via a data infrastructure such as the Internet, react flexibly to external influences and exchange data with information systems and other CPSs. In manufacturing facilities, cyber-physical systems will communicate with intelligent, networked industrial production and logistics units-also known as cyber-physical production systems (CPPS). The CPSs exchange information, trigger actions in production and reciprocally control themselves autonomously. This enables industrial processes in manufacturing, engineering, use of materials, supply chain management and life cycle management to be fundamentally restructured and optimized. Currently, manufacturing data are segmented, detailed and planned for a single scope, stored within the legacy systems, thus preventing the digital continuity that would let use them in the optimal way, independently from where and how they have been collected. Cyber Physical System (CPS) will instead be able to provide the needed information from the physical world while cyber-physical-collaboration environment will enable an efficient analysis, management, sharing and usage of the data and the knowledge elaborated from them and from the experience of involved people. Cyber-physical systems also represent a paradigm break from existing business and market models, as revolutionary new applications, service providers and value chains become possible. , Being able to assist customers remotely, service technicians could support their customers at any time and from anywhere, without necessarily having\n",
      "exact_answer FSM AR Demo\n",
      "confidence_score 0.12018255889415741\n",
      "ar demo, mechanism kit assembly and disassembly, ar maintenance using hololens, expert maintenance system using hololens, cyber physical assembly line, cp lab autonomy, smart mechanism kit realtime values, plc kit parts introduction, smart mechanism kit motor replacement, to create user defined webpages to control and monitor different devices ( appliances, machines ) present in cp lab., 01remote control and monitoring of assembly line, compressor and mprc, 02remote control and monitoring of domestic appliances ( lights, fans, ac ), 03user defined access to control the machines remotely, 04activity logging of users, 05remote control of the training kits to train people remotely, traditionally, manufacturing has been considered as a process that convert raw materials into physical products in the factories by managing resources with best automation practices available. today, drivers such as technology, sustainability, optimization and the need to meet customer demands have once again encouraged the transformation of the manufacturing industry to become adaptive, fully connected, and aware of its own power quality.\n",
      "loop: 10\n",
      "independently from where and how they have been collected. Cyber Physical System (CPS) will instead be able to provide the needed information from the physical world while cyber-physical-collaboration environment will enable an efficient analysis, management, sharing and usage of the data and the knowledge elaborated from them and from the experience of involved people. Cyber-physical systems also represent a paradigm break from existing business and market models, as revolutionary new applications, service providers and value chains become possible. , Being able to assist customers remotely, service technicians could support their customers at any time and from anywhere, without necessarily having to visit the customer site. Remote access could also help to better prepare service technicians with the necessary information for their tasks. Knowing about the machine or system error in more detail beforehand saves valuable time because required spare parts or other equipment can ordered, prepared and brought along. Moreover, due to a shorter reaction time, the customer’s machines are up and running much faster, saving them from costly downtime. For a machine and equipment manufacturer, using remote access also means that the same number of service technicians could support more customers or offer additional services. A secure remote connection to distributed machinery and equipment is also the basis for many new concepts and services within Industry 4.0 such as predictive maintenance, where a secure connection is established to collect data from machines, equipment or devices. The data is than analyzed and used to detect errors and possible failures at an early stage to avoid unplanned downtime. , Software used for AR : Here are various software we are using for the smart manufacturing purpose in AR. , It is an AR application designed and developed to provide a complete 3D CAD model of the FSM Smart Kits. The application uses a pre-defined Image Target and superimposes a 3D CAD of the Smart Manufacturing Training Kits. The user can visualize the smart kit without having access to the physical kit. He/She can click on the individual parts to display information about them. He/She can also get an exploded view of the CAD to understand the disassembly process. All activity of the user is also being logged on the cloud and displayed on a dashboard, this allows us to track the progress of the user. , It is an AR application which uses the physical FSM Smart Kit as an Image Target and adds information about their individual components. The app also allows the user to click on the individual parts and learn about them. , It is an AR application to help the surgeon in verifying and sensing the correctness of the bent plate. The application uses a 2D Image Target to superimpose the CAD of the bent plate on the Image Target. The surgeon will try to match the physical plate to the superimposed cad to confirm the correct bent. , It is an AR application to guide the surgeon for drilling correct holes in the spine to insert screws. The application uses a 3D spine as the Model Target, then\n",
      "exact_answer Smart Kits\n",
      "confidence_score 0.42686566710472107\n",
      "\n",
      "loop: 11\n",
      "the user to click on the individual parts and learn about them. , It is an AR application to help the surgeon in verifying and sensing the correctness of the bent plate. The application uses a 2D Image Target to superimpose the CAD of the bent plate on the Image Target. The surgeon will try to match the physical plate to the superimposed cad to confirm the correct bent. , It is an AR application to guide the surgeon for drilling correct holes in the spine to insert screws. The application uses a 3D spine as the Model Target, then superimposes the screws on the CAD. This will guide the surgeon to determine the angle and location of the screws. , It is an AR application that provides a step-by-step process to assemble and disassemble the FSM Mechanism Kit. , It is an AR application that provides the user a 3D visualization of the Cobot joints' movements. Use sliders to move the joints and learn about the working of Cobots. , It is an AR application to scan the surroundings and place full-scale objects to confirm size requirements. , It is an AR application to get a 3D view of all the smart machines and kits at FSM. , It is an AR application that replicates the assembly process of the assembly line. It gives the user a complete visualization of every step of the assembly process. , Smart Catalogue & visualization , Education & Training , Use as a teaching tool , Assess machinery before purchase , Maintenance Tool , <-Smart Manufacturing Training Kits , Cyber Physical Facilities-> , Cyber physical factory (CPF) is also known as Discrete Micro Production Facility or simply Micro Production Facility. It demonstrates the convergence of the Informational Technology (IT) and Operational Technology (OT) at micro factory level where the machines are discretely located. It has 18 varieties of machines for different manufacturing operations. The key features that this factory has: Customer Order Management Production Order Management Material Management Performance Management Customer Relationship Operations Intelligence Quality Management Error-Proofing Maintenance Management Energy Management Workforce Management Environment and Safety We have converted legacy machines into digitized smart machines like lathe machine, shearing machine. The Mobile Collaborative Robot is used for inbound logistics. The following image demonstrates the material and manufacturing process for a typical product like a hydraulic pump flange. , <-Mobile Collaborative Robot , Services-> , This course is designed on a Simulation platform. It’s a self-paced online course where you get to learn different domains of Automation like Pneumatic, Electro-Pneumatics, PLC programming and Electrical Connections of a PLC. You will create different industrial projects and simulate them on the software during the course tenure. This course is a blend of lecture videos, Step-by-step documents, and Live sessions to give a complete idea and knowledge of Industrial Automation to you. By the end of the course, you will be ready to write a PLC program for machines with DI, DO, AI and AO. You will be able to understand and create pneumatic and electro-pneumatic circuits depending on\n",
      "exact_answer Mechanism Kit\n",
      "confidence_score 0.007085003890097141\n",
      "\n",
      "loop: 12\n",
      "online course where you get to learn different domains of Automation like Pneumatic, Electro-Pneumatics, PLC programming and Electrical Connections of a PLC. You will create different industrial projects and simulate them on the software during the course tenure. This course is a blend of lecture videos, Step-by-step documents, and Live sessions to give a complete idea and knowledge of Industrial Automation to you. By the end of the course, you will be ready to write a PLC program for machines with DI, DO, AI and AO. You will be able to understand and create pneumatic and electro-pneumatic circuits depending on the industrial application. , Pneumatic Components Introduction, Creating Pneumatic connections on software and creating an Industrial Application , Electro-Pneumatic Components Introduction, Creating Pneumatic and electrical connections on software and creating an Industrial Application , Hardware identification of PLC , PLC Programming on basic instructions, Timers, Counters, and Digital I/OsProject: Programming a PLC for an Industrial Application , PLC programming on compare instructions and Analog I/Os Project: Programming a PLC (with analog Inputs and Outputs) for an Industrial Application , Self- project where in the participants will be given an opportunity to try out the use case that they have in mind using the simulation software to simulate and test their application , Is this limited to any stream? Any knowledge of PLC is required before joining the course? Is this limited to any stream?No, Anyone interested in industrial Automation can join the course.Any knowledge of PLC is required before joining the course?No. You will be starting from the scratch but having prior knowledge will help you to complete the course early. , No, Anyone interested in industrial Automation can join the course. , No. You will be starting from the scratch but having prior knowledge will help you to complete the course early. , Workstation 1 is one of the assembly stations. This Station stores the raw part and inspects the parts using QR code scanner and vision sensor. Valve body is transferred from one station to another in a pallet. Pallet has a RFID tag,so that next station can read the value and get the information about the body present in the pallet. PLC Used: 1769-L33-ERM,Micrologix 1400 (Rockwell) Software Used: Studio 5000,RSlogix 500 and View ME(HMI designing) Programming: Ladder Logic Programming, Safety Sensors (IO Link master), Pneumatics and 4 Axes Motion Programming. Workstation 2 is the next assembly station. This station inserts the child part in the base part. PLC Used: BnR Software Used: Automation Studio Programming: Ladder Logic/Structured text Programming, Safety Sensors (IO Link master), Pneumatics and 3 Axes Motion Programming. Workstation 3 is one of the assembly stations. This Station assembles all the sub parts of Cotter joint assembly depending on the type of socket body approaching the station with the help of RFID. The Gripper Picks and Places the Cotter to engage socket and spigot. PLC Used: Mitsubishi MELSEC R-Series (Rack Type) Software Used: GX Works 3 Programming: Ladder Logic Programming, Safety Sensors, Pneumatics and 7 Axes Motion Programming. , AutomationAugmented RealityIIoTMachine LearningDigital Twin , 01Demonstration & Training\n",
      "exact_answer blend of lecture videos, Step-by-step documents, and Live sessions\n",
      "confidence_score 0.005145009607076645\n",
      "this course is a blend of lecture videos, step - by - step documents, and live sessions to give a complete idea and knowledge of industrial automation to you. by the end of the course, you will be ready to write a plc program for machines with di, do, ai and ao\n",
      "loop: 13\n",
      "BnR Software Used: Automation Studio Programming: Ladder Logic/Structured text Programming, Safety Sensors (IO Link master), Pneumatics and 3 Axes Motion Programming. Workstation 3 is one of the assembly stations. This Station assembles all the sub parts of Cotter joint assembly depending on the type of socket body approaching the station with the help of RFID. The Gripper Picks and Places the Cotter to engage socket and spigot. PLC Used: Mitsubishi MELSEC R-Series (Rack Type) Software Used: GX Works 3 Programming: Ladder Logic Programming, Safety Sensors, Pneumatics and 7 Axes Motion Programming. , AutomationAugmented RealityIIoTMachine LearningDigital Twin , 01Demonstration & Training , 04Flexible Assembling , 02Customer order processing , 03Realtime dashboard , An AR application to show information about FSM Smart Manufacturing Kits An AR application that gives the user a menu with 10 options for each of the FSM Smart Manufacturing Kit. The user can visualize all 3 components, the HMI, the Electronic Kit, and the Mechanism Kit. The user can click on the different parts and get to know about the parts. The user can also initiate the CAD explode view animation. , An augmented reality application to provide self-guided training on the FSM PLC Kits. The user can scan the ThingMark on the Kit to load up the experience or can FSM PLC Kit Parts Introduction 2 use model target detection by aligning the on-screen guide with the real hardware and then click on the parts to know about them , This course is completely designed on the Codesys platform using Soft-PLC. Throughout this self-paced online course, participants will be trained on the basics of ladder logic programming, Visualization of a Human-Machine Interface for controlling the program parameters, and Motion programming with a basic linear axis motion to rotary of single-axis motion. This course also explains the communication between the edge tier & platform tier using a data aggregator software, an interface that is created between the Soft-PLC and the data aggregator using OPC-UA Server and Client plug-in. By the end of the course, you will be ready for programming a codesys platform-based hardware with HMI features, programming motion controller with Open PLC blocks, knowledge of how OPC-UA Server-Client works and how to communicate the data of a Soft-PLC on Codesys Driver. , Basics of codesys software and the basic instructions used in the ladder logic programming. , Designing a front-end UI for the operator to operate the parameters/tags of the program in the HMI. , Overview of function block programming, explaining how the single-axis linear system and the single-axis rotary index system with multiple stations. , Extracting the data out of the PLC to control and monitor the application remotely within the network. , Self- project where in the participants will be given an opportunity to try out the use case that they have in mind using the Soft-PLC along with HMI screens and remote monitoring. , Minimum hardware requirement1. 4GB Ram, i3 processor with windows 8 or above version. 2. Windows is a must. Software doesn’t run on macos or linux , 1. 4GB Ram, i3 processor with\n",
      "exact_answer Smart Manufacturing Kits\n",
      "confidence_score 0.028708500787615776\n",
      "this course also explains the communication between the edge tier & platform tier using a data aggregator software, an interface that is created between the soft - plc and the data aggregator using opc - ua server and client plug - in. by the end of the course, you will be ready for programming a codesys platform - based hardware with hmi features, programming motion controller with open plc blocks, knowledge of how opc - ua server - client works and how to communicate the data of a soft - plc on codesys driver., basics of codesys software\n",
      "loop: 14\n",
      "programming, explaining how the single-axis linear system and the single-axis rotary index system with multiple stations. , Extracting the data out of the PLC to control and monitor the application remotely within the network. , Self- project where in the participants will be given an opportunity to try out the use case that they have in mind using the Soft-PLC along with HMI screens and remote monitoring. , Minimum hardware requirement1. 4GB Ram, i3 processor with windows 8 or above version. 2. Windows is a must. Software doesn’t run on macos or linux , 1. 4GB Ram, i3 processor with windows 8 or above version. 2. Windows is a must. Software doesn’t run on macos or linux , PrerequisitesNo prerequisites are required , No prerequisites are required , Laptop/ PC minimum requirements I don't know what PLC is should I join this course? Is this limited to any Stream? Laptop/ PC minimum requirements?4GB Ram, i3 processor with windows 8 or above version.I don't know what PLC is should I join this course?Yes, you will get a chance to learn more about it.Where can I find The Economist?Its not limited, anyone with Automation interest can join this course. , 4GB Ram, i3 processor with windows 8 or above version. , Yes, you will get a chance to learn more about it. , Its not limited, anyone with Automation interest can join this course. , Smart trainer kits are used to train industry and academic people and make them aware about Industry 4.0 technologies. It is a combination of three independent hardware accessories- PLC Trainer Kit, HMI Kit and Mechanism Kit. All these kits demonstrate the industry 4.0 technologies in the best possible way. These were designed, manufactured and integrated in FSM. Modules/Trainings covered in these kits: PLC Programming, Network Protocols HMI Designing Data Logging Dashboard Designing, NodeRed IIOT gateways and platforms Augmented Reality Machine Learning Smart Sensing Motion configuration and programming Vision System , This is one of the kits of the smart manufacturing trainer module. This kit has the brain of the other two kits (HMI Kit and Mechanism Kit) as programming is done in this kit. It has a PLC for programming and digital inputs/outputs, analog inputs/outputs to connect the required sensors with the PLC. It has an IO link module to connect the smart sensors, so alongwith the 24VDC or analog input this module communicates the sensor status with the PLC. Data logging and data collection is one of the critical steps for IIOT and for that we have integrated IOT gateway and other software platforms in this kit. To connect sensors with the PLC, banana connectors are used. It can communicate on a number of network protocols and it has the feature to communicate with multiple HMIs and Servo drives. In programming kit we have PLC hardwares from Rockwell, Siemens, Schneider, Omron, Delta, Turck and Mitsubishi for programming and various softwares. NUC is also integrated in the kit so that it can be used as CPU for softwares and PLC programming. So, this kit is more than sufficient to\n",
      "exact_answer demonstrate the industry 4.0 technologies\n",
      "confidence_score 0.0376809798181057\n",
      "its not limited, anyone with automation interest can join this course., 4gb ram, i3 processor with windows 8 or above version., yes, you will get a chance to learn more about it., its not limited, anyone with automation interest can join this course., smart trainer kits are used to train industry and academic people and make them aware about industry 4. 0 technologies. it is a combination of three independent hardware accessories - plc trainer kit, hmi kit and mechanism kit. all these kits demonstrate the industry 4. 0 technologies in the best possible way. these were designed, manufactured and integrated in fsm. modules / trainings covered in these kits : plc programming, network protocols hmi designing data logging dashboard designing, nodered iiot gateways and platforms augmented reality machine learning smart sensing motion configuration and programming vision system, this is one of the kits of the smart manufacturing trainer module. this kit has the brain of the other two kits ( hmi kit and mechanism kit ) as programming is done in this kit. it has a plc for programming and digital inputs / outputs, analog inputs / outputs to connect the required sensors with the plc. it has an io link module to connect the smart sensors, so alongwith the 24vd\n",
      "loop: 15\n",
      "critical steps for IIOT and for that we have integrated IOT gateway and other software platforms in this kit. To connect sensors with the PLC, banana connectors are used. It can communicate on a number of network protocols and it has the feature to communicate with multiple HMIs and Servo drives. In programming kit we have PLC hardwares from Rockwell, Siemens, Schneider, Omron, Delta, Turck and Mitsubishi for programming and various softwares. NUC is also integrated in the kit so that it can be used as CPU for softwares and PLC programming. So, this kit is more than sufficient to demonstrate the features of the PLC, gateways and software platforms (Data Logging, Augmented Reality ,IIOT gateways and platforms), Smart Sensing . , Human Machine Interface is used to monitor and access the PLC data. Screens can be created depending on the application.This is the second kit of the smart manufacturing trainer module. It has HMI to display the screens and monitor the PLC tags. The hardware buttons and LEDs as well which are connected with the PLC trainer kit using banana connectors, mostly like plug and play. These are used to test the PLC program and as input and output in the PLC program. HMIs used in these kits are smart HMIs which have smart features like OPC UA server/client, MQTT compatibility, user authentication on the screens, act as an edge device etc. So, kit is used to visualise the PLC logic. Additionally it demonstrates the HMI Designing and Dashboard designing feature. , This is the third kit of the smart trainer modules used to demonstrate a working manufacturing system. It has a servo motor and drive to rotate an indexing table. Along with the motion feature, it has four stations which can be used to demonstrate multiple operations. Each station has smart inductive sensors to sense the part's presence which consists of the distance and proximity sensors, servo drive, test product, RFID Reader, Solenoid, USB Camera mounted on them.Station 1: It has a RFID controller used to read and write the tag values of a product. It communicates with IO Link master (present in PLC trainer kit) and IO link master communicates the data with the PLC. So, RFID operation and use case is demonstrated. Station 2: This station consists of a distance sensor used to calculate the height or distance of the product. It is a smart sensor and communicates with IO Link master. So, along with the analog value it communicates it’s status to the PLC as well. Verification of product dimension is also demonstrated. Station 3: This station has a vision camera installed on it. This camera is used for image processing and product testing. Sorting operation is performed using the image processing feature. Station 4: This station has a solenoid which is directly connected with the digital output of the PLC. Extension and retraction of the solenoid is programmed in the PLC for this operation.This mechanism kit is used to demonstrate and train motion configuration and programming, Vision System, Smart Sensing, Machine Learning, Augmented Reality. , Programming\n",
      "exact_answer IO Link master\n",
      "confidence_score 0.23676550388336182\n",
      "station 1 : it has a rfid controller used to read and write the tag values of a product. it communicates with io link master ( present in plc trainer kit ) and io link master communicates the data with the plc. so, rfid operation and use case is demonstrated.\n",
      "loop: 16\n",
      "it communicates it’s status to the PLC as well. Verification of product dimension is also demonstrated. Station 3: This station has a vision camera installed on it. This camera is used for image processing and product testing. Sorting operation is performed using the image processing feature. Station 4: This station has a solenoid which is directly connected with the digital output of the PLC. Extension and retraction of the solenoid is programmed in the PLC for this operation.This mechanism kit is used to demonstrate and train motion configuration and programming, Vision System, Smart Sensing, Machine Learning, Augmented Reality. , Programming Kit , HMI Kit , Mechanism Kit , It is showing the working of Smart Manufacturing Kit , Education & Training , Device Services , Research & Skill Certification , Software-> , Traditionally, manufacturing has been considered as a process that convert raw materials into physical products in the factories by managing resources with best automation practices available. , The digital factory concept offers an integrated approach to enhance the product and production engineering processes and simulation is a key technology within this concept. , Until now, industrial robots always worked separately from humans in specially safeguarded protected spaces. Smart manufacturing has broken down this barrier with a new generation of collaborative industrial robots. , A key component in making Industry 4.0 a reality are machines that can produce the desired components faster, more flexibly and more precisely than ever before. Also Consumers want products that reflect their individuality. , Augmented reality is the integration of digital information with the user's environment in real time. Unlike virtual reality, which creates a totally artificial environment, augmented reality uses the existing environment and overlays new information on top of it. , Networked production and control processes in complex machine environments determine the industrial future and make Industry 4.0 possible in the first place. Smart Sensors already today support dynamic, real-time-optimized, and self-organized industry processes. , Being able to assist customers remotely, service technicians could support their customers at any time and from anywhere, without necessarily having to visit the customer site. Remote access could also help to better prepare service technicians with the necessary information for their tasks. Knowing about the machine or system error in more detail beforehand saves valuable time because required spare parts or other equipment can ordered, prepared and brought along. , The world of automation is merging with the IT world. Safety & security is an important prerequisite for the function of Industry 4.0 systems, which in contrast to traditional production plants have interfaces to their environment. , An Augmented reality application that allows the user to understand about the mechanism kit and scan the image target and place a CAD model of the Mechanism Kit to understand it clearly. The user can create a new account and can access the application using the registered email id and password. If the user forgets the password associated with the registered email id, they can use the forgot password option and can create a new password for the registered email id.\n",
      "exact_answer Augmented reality\n",
      "confidence_score 0.0002506128221284598\n",
      "\n",
      "loop: 17\n",
      "the function of Industry 4.0 systems, which in contrast to traditional production plants have interfaces to their environment. , An Augmented reality application that allows the user to understand about the mechanism kit and scan the image target and place a CAD model of the Mechanism Kit to understand it clearly. The user can create a new account and can access the application using the registered email id and password. If the user forgets the password associated with the registered email id, they can use the forgot password option and can create a new password for the registered email id. The user can the access the features of the application by using the main menu FSM Mechanism Kit Assembly and Disassembly 2 where different buttons are linked with the assembling and disassembling. The user can then play the animations of the screws, Allen Keys, screwdrivers, and the parts of mechanism kit. The steps can be played multiple times as per the requirements. The user can switch between the steps using the next and previous buttons. , Cloud DatabaseAugmented Reality , 03Remote Maintenance , Mandated Guidelines Awareness campaigns on Industry 4.0 Training for master trainers Active participation provisions for start-up / incubators Hand-holding of SMEs to plan and implement relevant Industry 4.0 projects to be done through consultancy services on a chargeable basis Collaborating with neighborhood universities for student training/internship programs Involving industry in SPV members model for sustainability Participating in a Government-formed platform for Industry 4.0 To make adequate provisions for e-waste management Involving as many clusters of 'capital goods' as possible , At FSM we are committed to demystify the smart manufacturing technologies by learning ourselves and then transfer the learning through various training programs to industry and academicians. We are engaging researchers to indigenously develop technologies to make it affordable by Indian MSME and facilitate adoption of Industry 4.0. Our state of art cyber physical lab showcase technologies available across globe through our strong partnership with the automation industries. , With a far-sighted approach, the Government of India has supported Automation Industry and IIT Delhi in creation of advanced engineering and software facilities for smart manufacturing. Prospective integrators, consultants and end users can use our training and tryout services to validate their proof-of-concept before scaling up. We help demystify and de-risk your investments in Industry 4.0 , Co-Creator , Dr. Sunil JhaDirector , Mr. Dilip SawhneyDirector , Dr. Anil WaliDirector , Sunil MehtaDirector , Mr. Anup WadhwaDirector Automation Industry Association , Mr. Ravi AgarwalDirector , The digital factory concept offers an integrated approach to enhance the product and production engineering processes and simulation is a key technology within this concept. Simulation helps to create digital models of products, production systems, logistic systems so that one can explore a system’s characteristics and optimize its performance. These digital models have the ability to run experiments and what-if scenarios without disturbing existing production systems or – when used in the planning process – long before the real production systems are installed. Extensive analysis tools, such as bottleneck analysis, statistics and charts give us\n",
      "exact_answer Automation Industry Association\n",
      "confidence_score 0.3712264597415924\n",
      "\n",
      "loop: 18\n",
      ", Mr. Ravi AgarwalDirector , The digital factory concept offers an integrated approach to enhance the product and production engineering processes and simulation is a key technology within this concept. Simulation helps to create digital models of products, production systems, logistic systems so that one can explore a system’s characteristics and optimize its performance. These digital models have the ability to run experiments and what-if scenarios without disturbing existing production systems or – when used in the planning process – long before the real production systems are installed. Extensive analysis tools, such as bottleneck analysis, statistics and charts give us an opportunity to evaluate different manufacturing scenarios. The results provide us with the information needed to make fast, reliable, smarter decisions in the early stages of production planning. In addition, we can also optimize material flow, resource utilization and logistics for all levels of plant planning from global production facilities, through local plants, to specific lines. This helps to fulfil the user’s need to deliver just-in-time (JIT) or just-in-sequence (JIS). Benefits Increase existing system productivity Optimize resource consumption and re-use Optimize systems for reduced energy consumption Shorten new product introduction, time-to market, and time-to-volume Improve production layout and minimize investments Ensure that machines and equipment are in the right place Ensure that sufficient material handling equipment is available Optimize buffer sizes Ensure that product handling is kept to a minimumApart from advance simulation another disruptive innovation is the concept of digital twin. With the growing deployments of Internet of Things (IoT) systems, the importance of the concept of a digital avatar of a physical thing has gathered significant interest in the recent years. A digital twin can be defined, fundamentally, as an evolving digital profile of the historical and current behavior of a physical object or process that helps optimize business performance.A digital twin enables flexibility in manufacturing to reduce time needed for product design, manufacturing process and system planning and production facility design. A digital twin improves quality and even supports new business models that offer opportunities for small- to mid-size companies to expand and bring more high-tech capability into their shops. Digital twins will help all companies become more flexible, reduce time to market, reduce cost, improve quality and increase productivity at all levels of the organization. Digital twin business values: 1. Quality Improve overall quality Predict and detect quality trend defects sooner Control quality escapes and be able to determine when quality issue started 2. Warranty cost and services Understand current configuration of equipment in the field to be able to service more efficiently Proactively and more accurately determine warranty and claims issues to reduce overall warranty cost and improve customer experiences 3. Operations cost Improve product design and engineering change execution Improve performance of manufacturing equipment Reduce operations and process variability 4. Record retention and serialization Create a digital record of serialized parts and raw materials to better manage recalls and warranty claims and meet mandated tracking requirements 5. New product introduction cost and lead time Reduce the time to market for a new product Reduce overall cost\n",
      "exact_answer digital factory concept\n",
      "confidence_score 0.0005223493790253997\n",
      "\n",
      "loop: 19\n",
      "Understand current configuration of equipment in the field to be able to service more efficiently Proactively and more accurately determine warranty and claims issues to reduce overall warranty cost and improve customer experiences 3. Operations cost Improve product design and engineering change execution Improve performance of manufacturing equipment Reduce operations and process variability 4. Record retention and serialization Create a digital record of serialized parts and raw materials to better manage recalls and warranty claims and meet mandated tracking requirements 5. New product introduction cost and lead time Reduce the time to market for a new product Reduce overall cost to produce new product 6. Revenue growth opportunities Identify products in the field that are ready for upgrade Improve efficiency and cost to service productThese digital twins use data from sensors that are installed on physical objects to represent their near real time status, working condition or position. Nonetheless, advances in computer science have made it possible to broaden the scope of the digital twin to include many more capabilities, information, inputs and outputs. It also helps you develop and introduce new products to the market much faster than ever. , Under Samarth Udyog Mission of the Ministry of Heavy Industry (MHI), Govt. of India, IIT Delhi, and Automation Industry Association (AIA) together with Industry sponsors have set up common engineering facilities under the aegis of the IITD - AIA Foundation for Smart Manufacturing (FSM). These facilities are meant to demonstrate, support, and develop Smart Manufacturing concepts for Indian Industry & try them out in their own plants. The collaboration is also aimed at developing a holistic educational curriculum and skill-building program through a vibrant incubation and administrative environment.As part of our commitment to make FSM infrastructure available for the student community to explore and learn smart manufacturing technologies, FSM is offering 100 nos. 2-Months full-time Online Summer Internship from 01-June-2023 to 31-July-2023 under the theme of Smart Factory”. , Registration Open , Last day to register , Short Listing , Orientation , Level 1 Learning Ends , Level 2 Technology Stream Learning Ends , Final Selection and Project Allocation , Orientation 2nd Programme & Internship Starts , Internship Ends , Registration Short Listing Level 1 Learning Level 2 Technology Stream Learning Final Selection Project Allocation Internship Commencement , Fill out the online registration form Shortlisting based on the eligibility criteria Level 1: Learning modules (Approx. time: 24 hrs) will be made available on fsmskills website. To be completed by 20th May 2023. Post your signup on fsmskill, you will gain access to the Level-1 course of IAFSM. This step involves learning of Smart Manufacturing Concepts and is the foundation course that is mandatory for all interns to qualify latest by 20th May 2023. You are required to go through recorded lectures and study the content thoroughly to clear the assignments of Level-1 in maximum 2 attempts. After 2 attempts, if you are not able to qualify for Level-1, your candidature will no longer be considered for internship. Level 2 : After successful completion of Level-1, You will be redirected to the\n",
      "exact_answer Foundation for Smart Manufacturing\n",
      "confidence_score 0.49130773544311523\n",
      "foundation for smart manufacturing ( fsm )\n",
      "loop: 20\n",
      "2023. Post your signup on fsmskill, you will gain access to the Level-1 course of IAFSM. This step involves learning of Smart Manufacturing Concepts and is the foundation course that is mandatory for all interns to qualify latest by 20th May 2023. You are required to go through recorded lectures and study the content thoroughly to clear the assignments of Level-1 in maximum 2 attempts. After 2 attempts, if you are not able to qualify for Level-1, your candidature will no longer be considered for internship. Level 2 : After successful completion of Level-1, You will be redirected to the Stream Learning module which involves learning of specific domains of your choice. You can choose from the available domains and try out a maximum of 3 domains of your choice. You are then required to undergo and clear the assignments based on your selection and qualify the Level 2 assignments after which you shall be taken forward for Project Based Learning under Summer Internship 2023. The assignments are to be attempted and cleared latest by 28th May 2023. Internship Projects: After successful completion of Level-2, Interns will be allocated projects based on domain preference, level-2 performance and interaction with the mentors. Final Selection and Project Allocation based on the Level 2 performance and preferences These are full-time internships and require 48 hours per week , AR-based fault diagnosis of RWC Implementing AR for complete Demonstration of Robotic Welding Cell Unity ROS Cobot FSM AMR AR FSM Interactive lab introduction , 02Digital Twin , Digital Twin of Robotic Welding Cell for process optimization and Predictive Maintenance. Digital twin for Advanced Milling Machine Centre , 03Industrial Automation , CP Lab Autonomy Phase - 2 Multi Process Robotic Cell Simulation on a simulation platform Robotic Welding Cell Simulation on a simulation platform Training Course on Rockwell Kit Training Course on Siemens Kit , 04Industrial IoT , Implementing IIoT on CPL Autonomy Implementing IIoT for Plant Owner on Robotic Welding Cell , 05Machine Learning , Remaining Usable Life Estimation (NASA Turbine Dataset) Power Line Fault Detection Computer Vision to detect defects in PCB Power Line Fault Detection Steel Defect Detection Using Computer Vision , 06Manufacturing Execution System , Digital quality report generation for 3d prints. Admin & customer pages for Order Management Portal (RWC) , 07Real Time Dashboard , Visualization of Multi-Process Robotic Cell Interactive Portal for RWC: Supervisor , 08Robotics , MPRC OLP Generation using Sim4.1 for a product Use of AMR-Cobot to place pallet ROS Integration of AMR Integration of computer vision with Cobot Computer Vision Integration with Cobot , 0Project Domains , 0No. of projects done , 0Candidates completed the Internship , 0Candidates applied , 0Candidates achieved Level 1 proficiency , 0Candidates were awarded with prize of INR 5000/- for Best Project Award , 0Candidates were shortlisted , 0Candidates were selected for presentation before Jury Members , 0Research papers given merit certificate , 01Augmented Reality , 02Industrial Automation , 03Industrial IoT , 04Machine Learning , 05Real Time Dashboard , 06Robotics , Here are some videos of our interns presenting their final projects in\n",
      "exact_answer Interactive lab introduction\n",
      "confidence_score 0.023783469572663307\n",
      "level 2 : after successful completion of level - 1, you will be redirected to the stream learning module which involves learning of specific domains of your choice. you can choose from the available domains and try out a maximum of 3 domains of your choice. you are then required to undergo and clear the assignments based on your selection and qualify the level 2 assignments after which you shall be taken forward for project based learning under summer internship 2023. the assignments are to be attempted and cleared latest by 28th may 2023. internship projects : after successful completion of level - 2, interns will be allocated projects based on domain preference, level - 2 performance and interaction with the mentors. final selection and project allocation based on the level 2 performance and preferences these are full - time internships and require 48 hours per week, ar - based fault diagnosis of rwc implementing ar for complete demonstration of robotic welding cell unity ros cobot\n",
      "loop: 21\n",
      "ROS Integration of AMR Integration of computer vision with Cobot Computer Vision Integration with Cobot , 0Project Domains , 0No. of projects done , 0Candidates completed the Internship , 0Candidates applied , 0Candidates achieved Level 1 proficiency , 0Candidates were awarded with prize of INR 5000/- for Best Project Award , 0Candidates were shortlisted , 0Candidates were selected for presentation before Jury Members , 0Research papers given merit certificate , 01Augmented Reality , 02Industrial Automation , 03Industrial IoT , 04Machine Learning , 05Real Time Dashboard , 06Robotics , Here are some videos of our interns presenting their final projects in front of the jury members and their mentors. Jury members were invited from different industries with their expertise in respective domains. In the presentation, our interns explained their whole journey and gave the detailing of the projects. After reviewing all these projects, the top 10 interns got awarded the best project award in their domain and a cash prize of 5000. , The term safety denotes the functional safety of machinery or, put another way, the protection of people and the environment against threats that can proceed from machinery. Safety demands that residual risks arising from a plant or machine do not exceed acceptable values. This includes hazards to the plant environment (e.g. environmental damage) as well as hazards within the plant or machine (e.g. people inside the plant). One option for the worst case is simply to interrupt the energy supply straight away and bring the machine to a hard stop. The traditional way of providing scope for this is by means of special safety wiring and components such as safety relays. Because this approach is very much hardware-based and therefore static, it is not particularly suitable for intelligent manufacturing processes where plant layouts continually need to be changed. A hard shutdown is generally associated with further disadvantages, whether these involve loss of productivity, extended downtimes due to more complex recommissioning procedures or a restriction in the machine’s operating and maintenance concept. An alternative is offered by dynamic safety concepts based on an integrated view of changing automation processes and functional safety requirements. This changes the view of safety itself; it is regarded less as a hardware characteristic and more as a cross-device function. This approach allows processes to be operated in a safely controlled manner without any need to interrupt them immediately every time a fault occurs. But the dynamic approach can only be implemented efficiently if functional safety is built into automation projects from the moment they are planned. , An Augmented Reality application to show the Real-time Values of the 4 stations of the FSM Smart Mechanism Kit by connecting with KEPServer and getting tag values , Augmented RealityIIoT , 02Realtime Monitoring , Robotic Welding Cell demonstrates a flexible manufacturing cell meaning it has an inventory of its own, material handling system, variety of parts with dynamic-order.This welding cell can be a part of production line and act as standalone system.Use of single or multiple robots may involve use of a PLC also.This cell uses a saftey PLC.This\n",
      "exact_answer Smart Mechanism Kit\n",
      "confidence_score 0.9693934917449951\n",
      "\n",
      "loop: 22\n",
      "built into automation projects from the moment they are planned. , An Augmented Reality application to show the Real-time Values of the 4 stations of the FSM Smart Mechanism Kit by connecting with KEPServer and getting tag values , Augmented RealityIIoT , 02Realtime Monitoring , Robotic Welding Cell demonstrates a flexible manufacturing cell meaning it has an inventory of its own, material handling system, variety of parts with dynamic-order.This welding cell can be a part of production line and act as standalone system.Use of single or multiple robots may involve use of a PLC also.This cell uses a saftey PLC.This cell has all these features and the basis of selection can be done in a way that the cell will be programmed, utilization of peripheral devices (proximity sensors, pneumatic cylinders), safety devices and Automatic Identification & Data Capturing (AIDC) devices like RFID, vision camera etc. The cell has following level of flexibility but the decision can be made on the basis of the flexibility required as per the following parameters:1. Variety of parts for simultaneous production 2. Change of schedule3. Ready for new partWorkstations and layout design :Workstations in the cell are as per the following given applications and subject to following parameters : 1. Load/Unload stations for the cell: It is the area where the raw materials are incepted in/out of the cell.2. Inventory storage area: An inventory storage where the storage of the raw material is kept.3. Inspection area: An area where the material post operations are inspected for quality. This is kept as a separate unit away from the cell but it can be an integral part of the cell itself.4. Operations area: An area where the operations like welding is performed. In the cell , this area is more of a workspace since two robots are responsible for performing welding on the material. And it can be anywhere in the robot's workspace. 5. Layout design: It is an integral part before identifying the robots and environment preparation and also plays a key role in safety of the cell.CAD Design & Simulation: The 3D visualization and detailing of the cell is done using a designing software. The robotic path simulation software asists in defining the best possible, collision free environment that is going to be the basis of the layout design and all other hardware that are going to be installed in the cell. Apart from designing & fabrication of the cell it helps in performing the robot simulations to generate offline program, collision free environment (this is how the level of flexibility achieved) for robots at operating stage and generating Augmented Reality applications. , The cell programming can be done in atleast two ways. Online programming where teach pendant is used and other is offline programming where the simulation is done in a separate software like RoboDK and KUKA Sim4. This helps in visualising and performing collision free path generation for both the robots. The video below demonstrates the offline programming method where we can see two robots performing indexed type motion. The offline programming helps in virtual\n",
      "exact_answer Smart Mechanism Kit\n",
      "confidence_score 0.9530340433120728\n",
      "smart mechanism kit by connecting with kepserver and getting tag values, augmented realityiiot, 02realtime monitoring, robotic welding cell demonstrates a flexible manufacturing cell meaning it has an inventory of its own, material handling system, variety of parts with dynamic - order. this welding cell can be a part of production line and act as standalone system. use of single or multiple robots may involve use of a plc also. this cell uses a saftey plc. this cell has all these features and the basis of selection can be done in a way that the cell will be programmed, utilization of peripheral devices ( proximity sensors, pneumatic cylinders ), safety devices and automatic identification & data capturing ( aidc ) devices like rfid, vision camera etc. the cell has following level of flexibility but the decision can be made on the basis of the flexibility required as per the following parameters : 1. variety of parts for simultaneous production 2. change of schedule3. ready for new partworkstations and layout design : workstations in the cell are as per the following given applications and subject to following parameters : 1. load / unload stations for the cell : it is the area where the raw materials are incepted in / out of the cell. 2. inventory storage area : an inventory storage where the storage of the raw material is kept. 3. inspection area : an area where the material post operations are inspected for quality. this is kept as a separate unit away from the cell but it can be an integral part of the cell itself. 4. operations area : an area where the operations like welding is performed. in the cell, this area is more of a workspace since two robots are responsible for performing welding on the material. and it can be anywhere in the robot ' s workspace. 5. layout design : it is an integral part before identifying the robots and environment preparation and also plays a key role in safety of the cell.\n",
      "loop: 23\n",
      "to generate offline program, collision free environment (this is how the level of flexibility achieved) for robots at operating stage and generating Augmented Reality applications. , The cell programming can be done in atleast two ways. Online programming where teach pendant is used and other is offline programming where the simulation is done in a separate software like RoboDK and KUKA Sim4. This helps in visualising and performing collision free path generation for both the robots. The video below demonstrates the offline programming method where we can see two robots performing indexed type motion. The offline programming helps in virtual commissioning and without impacting the production. , Simulation & Testing , Job work & research , Prototyping , Customer Order Proessing , Site Integration , Machine-as-a-service , <-Multi Process Robotic Cell , Mobile Collaborative Robot-> , Smart sensors are a prerequisite for creating the best possible basis for a future-oriented automation system. This is because the smart factory needs data that can principally only be provided by smart, intelligent and communication-enabled sensors. Communication-enabled means being able to exchange sensor data with a machine controller or a cloud-based application. Thus, for example, sensor parameters are automatically adapted to new production orders within seconds. Or a light barrier detects contamination of its optics and reports this directly to the control center. Smart Sensors generate and receive data and information which goes beyond traditional switching signals or measured process parameters. They therefore enable substantial increases in efficiency, more flexibility, and better planning security for predictive plant maintenance. Depending on the requirement, Smart Sensors cover up to four dimensions of Smart Sensor technology. 1. Enhanced sensing 2. Efficient communication 3. Diagnostics 4. Smart tasks Just like smart sensors, smart actuators also have intelligence built into them. Some of the smart features possessed by different types of actuators are: Open standards: Multi-protocol communication interface allow universal operation with diverse, ethernet-based communication protocols Web-based commissioning and diagnostics via integrated web server Comprehensive access to actuator data (e.g. torque or power), via web connector for preventive maintenance or database interfacing and data analysis Inbuilt smart sensors for capturing data Flexible configuration according to requirement Comprehensive condition monitoring for fast identification of critical conditions and comfortable analysis Simple connection to higher-level data systems without additional hardware Workpiece-dependent parameters setting guaranteeing quality results Integrated control system with browser-based operating system allows for information sharing across multi vendor data systems , Robotic Welding Cell demonstrates a flexible manufacturing cell meaning it has an inventory of its own, material handling system, variety of parts with dynamic-order.This welding cell can be a part of production line and act as standalone system.Use of single or multiple robots may involve use of a PLC also.This cell uses a saftey PLC.This cell has all these features and the basis of selection can be done in a way that the cell will be programmed, utilization of peripheral devices (proximity sensors, pneumatic cylinders), safety devices and Automatic Identification & Data Capturing (AIDC) devices like RFID, vision camera etc. The cell has following level of flexibility but the decision can\n",
      "exact_answer Robotic Welding Cell\n",
      "confidence_score 0.20305699110031128\n",
      "communication - enabled means being able to exchange sensor data with a machine controller or a cloud - based application. thus, for example, sensor parameters are automatically adapted to new production orders within seconds. or a light barrier detects contamination of its optics and reports this directly to the control center. smart sensors generate and receive data and information which goes beyond traditional switching signals or measured process parameters. they therefore enable substantial increases in efficiency, more flexibility, and better planning security for predictive plant maintenance. depending on the requirement, smart sensors cover up to four dimensions of smart sensor technology. 1. enhanced sensing 2. efficient communication 3. diagnostics 4. smart tasks just like smart sensors, smart actuators also have intelligence built into them. some of the smart features possessed by different types of actuators are : open standards : multi - protocol communication interface allow universal operation with diverse, ethernet - based communication protocols web - based commissioning and diagnostics via integrated web server comprehensive access to actuator data ( e. g. torque or power ), via web connector for preventive maintenance or database interfacing and data analysis inbuilt smart sensors for capturing data flexible configuration according to requirement comprehensive condition monitoring for fast identification of critical conditions and comfortable analysis simple connection to higher - level data systems without additional hardware workpiece - dependent parameters setting guaranteeing quality results integrated control system with browser - based operating system allows for information sharing across multi vendor data systems\n",
      "loop: 24\n",
      "an inventory of its own, material handling system, variety of parts with dynamic-order.This welding cell can be a part of production line and act as standalone system.Use of single or multiple robots may involve use of a PLC also.This cell uses a saftey PLC.This cell has all these features and the basis of selection can be done in a way that the cell will be programmed, utilization of peripheral devices (proximity sensors, pneumatic cylinders), safety devices and Automatic Identification & Data Capturing (AIDC) devices like RFID, vision camera etc. The cell has following level of flexibility but the decision can be made on the basis of the flexibility required as per the following parameters:1. Variety of parts for simultaneous production2. Change of schedule3. Ready for new partWorkstations and layout design :Workstations in the cell are as per the following given applications and subject to following parameters : 1. Load/Unload stations for the cell: It is the area where the raw materials are incepted in/out of the cell.2. Inventory storage area: An inventory storage where the storage of the raw material is kept.3. Inspection area: An area where the material post operations are inspected for quality. This is kept as a separate unit away from the cell but it can be an integral part of the cell itself.4. Operations area: An area where the operations like welding is performed. In the cell , this area is more of a workspace since two robots are responsible for performing welding on the material. And it can be anywhere in the robot's workspace. 5. Layout design: It is an integral part before identifying the robots and environment preparation and also plays a key role in safety of the cell.CAD Design & Simulation:The 3D visualization and detailing of the cell is done using a designing software. The robotic path simulation software asists in defining the best possible, collision free environment that is going to be the basis of the layout design and all other hardware that are going to be installed in the cell. Apart from designing & fabrication of the cell it helps in performing the robot simulations to generate offline program, collision free environment (this is how the level of flexibility achieved) for robots at operating stage and generating Augmented Reality applications. , AutomationIIoTRoboticsAugmented Reality , 01Machine as a service , 02Customer Order Proessing , 03Job work and research , 3D printing has the capability to be used to respond too many of the world’s changing megatrends. The physical object is made from a three-dimensional digital model, typically by laying down many thin layers of a material in succession. With 3D printing it is possible to go directly from digital design data to a final part with no intermediate production steps. 3D printing technologies therefore eliminate the need for tooling and the associated capital investment. The result is that companies that adopt 3D printing can disrupt the traditional economies of scale, by allowing cost-effective production of single-unit or low-volume batches with low-volume part production, products can be customized to local markets, or even to individual\n",
      "exact_answer 3D printing\n",
      "confidence_score 0.10304515808820724\n",
      "\n",
      "loop: 25\n",
      "changing megatrends. The physical object is made from a three-dimensional digital model, typically by laying down many thin layers of a material in succession. With 3D printing it is possible to go directly from digital design data to a final part with no intermediate production steps. 3D printing technologies therefore eliminate the need for tooling and the associated capital investment. The result is that companies that adopt 3D printing can disrupt the traditional economies of scale, by allowing cost-effective production of single-unit or low-volume batches with low-volume part production, products can be customized to local markets, or even to individual customer tastes, driving adoption within industries as diverse as fashion, health care and automotive. Moreover, with the ability to print on demand, businesses also have the opportunity to eliminate inventory and cut aftermarket lead-times by providing digital spare-parts catalogues that can be printed when needed. The smart companies of the future will be those that have a clear strategy for how and where 3D printing fits within their supply chain and their value chain. They will also understand the business drivers to adoption. From the student’s study to the professional designer’s office, from the dental laboratory to the jewellery retailer, from the aerospace factory to the hospital basement, 3D printers have become invaluable business tools. Applications and reasons are as diverse as the users. What links all these applications and users is one underlying ability: to transition 3D information digitally and seamlessly from the virtual world to the real world with nothing but a computer and a3D printer – from bytes to bits. The benefits of 3D printing today go way beyond just making models and prototypes. 3D printing is becoming a way of making components, systems and products sold across the supply chain, from the bracket in the aircraft door to the dental aligner in the teenager’s mouth. It can also be used for the manufacturing of tools, jigs and fixtures in addition to rapid prototyping. , An AR application designed to run on HoloLens 2 to demonstrate the entire sequence for Motor Replacement in the FSM Smart Mechanism Kit.The application uses a model target to detect the real mechanism kit and then superimpose the AR kit.The application will guide in tool selection and then show the steps to replace the motor.Voice updates are given to the user with each step.The user can also control the application sequence using voice commands. , Augmented RealityMicrosoft HoloLens 2 , 01Self-Guided Training , 04Self-Guided Maintenance , 02Action Latency Reduction , 03Insight Latency Reduction , IITD-AIA Foundation For Smart Manufacturing presents a comprehensive Learning Module on Industrial Automation and IoT using soft-PLC Program, visualize, execute remote monitoring, motion programming and more using soft-PLC on the upcoming Learning Module. This program is meant for Engineering Students and Industry Freshers wanting to gain practical learning in the field of Industrial Automation which is foundation for Smart Manufacturing implementation.Learning content prepared under guidance of Prof. Sunil Jha , IITD-AIA Foundation For Smart Manufacturing presents a 5 Days/10 Hours Online Self Learning Program on components and integration for Smart\n",
      "exact_answer Smart Mechanism Kit\n",
      "confidence_score 0.9166739583015442\n",
      "with the ability to print on demand, businesses also have the opportunity to eliminate inventory and cut aftermarket lead - times by providing digital spare - parts catalogues that can be printed when needed. the smart companies of the future will be those that have a clear strategy for how and where 3d printing fits within their supply chain and their value chain. they will also understand the business drivers to adoption. from the student ’ s study to the professional designer ’ s office, from the dental laboratory to the jewellery retailer, from the aerospace factory to the hospital basement, 3d printers have become invaluable business tools. applications and reasons are as diverse as the users. what links all these applications and users is one underlying ability : to transition 3d information digitally and seamlessly from the virtual world to the real world with nothing but a computer and a3d printer – from bytes to bits. the benefits of 3d printing today go way beyond just making models and prototypes. 3d printing is becoming a way of making components, systems and products sold across the supply chain, from the bracket in the aircraft door to the dental aligner in the teenager ’ s mouth. it can also be used for the manufacturing of tools, jigs and fixtures in addition to rapid prototyping., an ar application designed to run on hololens 2 to demonstrate the entire sequence for motor replacement in the fsm smart mechanism kit. the application uses a model target to detect the real mechanism kit and then superimpose the ar kit. the application will guide in tool selection and then show the steps to replace the motor. voice updates are given to the user with each step. the user can also control the application sequence using voice commands., augmented realitymicrosoft\n",
      "loop: 26\n",
      "Maintenance , 02Action Latency Reduction , 03Insight Latency Reduction , IITD-AIA Foundation For Smart Manufacturing presents a comprehensive Learning Module on Industrial Automation and IoT using soft-PLC Program, visualize, execute remote monitoring, motion programming and more using soft-PLC on the upcoming Learning Module. This program is meant for Engineering Students and Industry Freshers wanting to gain practical learning in the field of Industrial Automation which is foundation for Smart Manufacturing implementation.Learning content prepared under guidance of Prof. Sunil Jha , IITD-AIA Foundation For Smart Manufacturing presents a 5 Days/10 Hours Online Self Learning Program on components and integration for Smart Manufacturing. This program is meant for Engineering Students and Industry Freshers wanting to gain practical learning in the field of Industrial Automation which is foundation for Smart Manufacturing implementation.Learning content prepared under guidance of Prof. Sunil Jha , , IITD-AIA Foundation For Smart Manufacturing presents 4 hours free awareness course on Industrial Automation Learning. This is a supplement course helpful for the upcoming 5 Days/10 Hours Online Self Learning Program on components and integration for Smart Manufacturing , or email us oninfo@iafsm.in , Smart Lathe Machine project is about retrofitting of Sensors and PLC for Digitizing the Cutting Parameters. Additionally for the monitoring of Power Consumption, the energy meter is in place to find out the power related parameters. The idea is to digitize the data and add operator and machine safety interlocks to avoid accidents in the shop floor. Also, the digitized data will be used in implementing Industrial IoT dashboards for monitoring purposes. The cutting parameters along with energy data is then used for training the machine model to predict the roughness or the remaining useful life of the tool depending on the vibration signals acquired through the vibration sensor. The Augmented Reality experience is created around the machine for giving basic nomenclature of Lathe machine. The animation of each process is also part of the experience. , AutomationIIoTMachine LearningAugmented Reality , 01Augmented Reality for guiding the students learn the different components of the machine , 04Real-Time Health Monitoring of Assets in Factory , 02Augmented Reality with guided exercises for maintenance. , 03Machine learning for predicting the tool wear. , Contact us today for implementing , Call us for any query011-26582053, 8076197190 , or email us oninfo@iafsm.in We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using twitter.com. You can see a list of supported browsers in our Help Center. , Help Center , Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2023 X Corp. , Level 2 : After successful completion of Level-1, You will be redirected to the Stream Learning module which involves learning of specific domains of your choice. You can choose from the available domains and try out a maximum of 3 domains of your choice. You are then required to undergo and clear the assignments based on your selection and qualify the Level 2 assignments after which you shall be taken forward for Project Based Learning under Summer Internship 2023. The\n",
      "exact_answer Terms of Service Privacy Policy\n",
      "confidence_score 0.15574389696121216\n",
      "\n",
      "loop: 27\n",
      "Center. , Help Center , Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2023 X Corp. , Level 2 : After successful completion of Level-1, You will be redirected to the Stream Learning module which involves learning of specific domains of your choice. You can choose from the available domains and try out a maximum of 3 domains of your choice. You are then required to undergo and clear the assignments based on your selection and qualify the Level 2 assignments after which you shall be taken forward for Project Based Learning under Summer Internship 2023. The assignments are to be attempted and cleared latest by 28th May 2023. , Internship Projects: After successful completion of Level-2, Interns will be allocated projects based on domain preference, level-2 performance and interaction with the mentors. , Short term education training offered along with online learning and assessment tool. Participants are engaged for approximately 100 hours in different technologies that include Automation, Industrial IoT, Augmented Reality, Robotics, Digital Twin and etc. The learnings are divided into Awareness Level, Learning Level and Expert Level. , CPS facilities and the associated technologies will provide for one-stop shop for users whose needs are cut across multiple disciplines and who wants to witness comprehensive digital transformation before taking up the actual implementation. , We are providing following services: , Indian Institute of Technology Delhi (IITD) and Automation Industry Association (AIA) joined hands in May, 2017 to set up a center under auspices of Samarth Udyog - a project of the Ministry of Heavy Industries (MHI). The center is called Foundation for Smart Manufacturing (FSM), and it helps supports and develops technologies for right understanding and implementation of concepts of smart manufacturing. FSM is a demo-cum-experience facility in North India, vests in extensive skill building, MSME consultancy, multi-academia partnerships and research which will give a huge fillip to technology aided competitiveness of Indian manufacturing. The project will imbibe technologies from Europe, Japan, USA and India. 'Producing Smarter' with Technologies. FSM has been launched specifically for implementation of smart manufacturing in India which it undertakes to do effectively by: Awareness Building, Prototyping, Simulation and testing Services, Consulting Services, Site Integration Services, Education and Training, Skills Certification, Job work and Research. , Director , info@iafsm.in , FSM is providing an exciting opportunity for 100 individuals to participate in a summer internship program. The program is entirely online and will run full-time from June 1, 2023, to July 31, 2023, for a duration of two months. The focus of the internship is on the theme of \\ Smart Factory,\\ which is a rapidly growing industry. This internship program is an excellent chance for individuals to gain valuable knowledge and experience in this field. It is an excellent opportunity for those who are looking to expand their skills and gain practical experience in this exciting area. If you are interested, don't miss this chance to be a part of the program and enhance your career prospects. , FSM is focussed on enabling people from becoming Smart to Samarth (capable) fraternity by\n",
      "exact_answer Foundation for Smart Manufacturing\n",
      "confidence_score 0.6221765279769897\n",
      "foundation for smart manufacturing ( fsm ), and it helps supports and develops technologies for right understanding and implementation of concepts of smart manufacturing.\n",
      "loop: 28\n",
      "for a duration of two months. The focus of the internship is on the theme of \\ Smart Factory,\\ which is a rapidly growing industry. This internship program is an excellent chance for individuals to gain valuable knowledge and experience in this field. It is an excellent opportunity for those who are looking to expand their skills and gain practical experience in this exciting area. If you are interested, don't miss this chance to be a part of the program and enhance your career prospects. , FSM is focussed on enabling people from becoming Smart to Samarth (capable) fraternity by creating awareness, step-wise learning and becoming an expert from domains driving Industry 4.0 ,\n",
      "exact_answer enabling people from becoming Smart to Samarth (capable) fraternity\n",
      "confidence_score 0.26786136627197266\n",
      "\n",
      "Final Answer: ['foundation for smart manufacturing ( fsm ) helps, supports, and develops smart manufacturing concepts for indian industry to witness, ideate, and try out in their plants.', '', '', \"smart mechanism kit by connecting with kepserver and getting tag values, augmented realityiiot, 02realtime monitoring, robotic welding cell demonstrates a flexible manufacturing cell meaning it has an inventory of its own, material handling system, variety of parts with dynamic - order. this welding cell can be a part of production line and act as standalone system. use of single or multiple robots may involve use of a plc also. this cell uses a saftey plc. this cell has all these features and the basis of selection can be done in a way that the cell will be programmed, utilization of peripheral devices ( proximity sensors, pneumatic cylinders ), safety devices and automatic identification & data capturing ( aidc ) devices like rfid, vision camera etc. the cell has following level of flexibility but the decision can be made on the basis of the flexibility required as per the following parameters : 1. variety of parts for simultaneous production 2. change of schedule3. ready for new partworkstations and layout design : workstations in the cell are as per the following given applications and subject to following parameters : 1. load / unload stations for the cell : it is the area where the raw materials are incepted in / out of the cell. 2. inventory storage area : an inventory storage where the storage of the raw material is kept. 3. inspection area : an area where the material post operations are inspected for quality. this is kept as a separate unit away from the cell but it can be an integral part of the cell itself. 4. operations area : an area where the operations like welding is performed. in the cell, this area is more of a workspace since two robots are responsible for performing welding on the material. and it can be anywhere in the robot ' s workspace. 5. layout design : it is an integral part before identifying the robots and environment preparation and also plays a key role in safety of the cell.\", 'with the ability to print on demand, businesses also have the opportunity to eliminate inventory and cut aftermarket lead - times by providing digital spare - parts catalogues that can be printed when needed. the smart companies of the future will be those that have a clear strategy for how and where 3d printing fits within their supply chain and their value chain. they will also understand the business drivers to adoption. from the student ’ s study to the professional designer ’ s office, from the dental laboratory to the jewellery retailer, from the aerospace factory to the hospital basement, 3d printers have become invaluable business tools. applications and reasons are as diverse as the users. what links all these applications and users is one underlying ability : to transition 3d information digitally and seamlessly from the virtual world to the real world with nothing but a computer and a3d printer – from bytes to bits. the benefits of 3d printing today go way beyond just making models and prototypes. 3d printing is becoming a way of making components, systems and products sold across the supply chain, from the bracket in the aircraft door to the dental aligner in the teenager ’ s mouth. it can also be used for the manufacturing of tools, jigs and fixtures in addition to rapid prototyping., an ar application designed to run on hololens 2 to demonstrate the entire sequence for motor replacement in the fsm smart mechanism kit. the application uses a model target to detect the real mechanism kit and then superimpose the ar kit. the application will guide in tool selection and then show the steps to replace the motor. voice updates are given to the user with each step. the user can also control the application sequence using voice commands., augmented realitymicrosoft', 'foundation for smart manufacturing ( fsm ), and it helps supports and develops technologies for right understanding and implementation of concepts of smart manufacturing.']\n"
     ]
    }
   ],
   "source": [
    "question=\"What is FSM?\"\n",
    "question_tokens = tokenizer(question, return_tensors='pt')\n",
    "question_tokens = tokenizer.tokenize(question, return_tensors='pt')\n",
    "selected_quesion=[\"[CLS]\", \"what\" , \"is\" , \"explain\" ,\"[SEP]\",\"?\",\".\",\"where\",\n",
    "\"how\",\"when\",\"which\",\"who\",\"whom\",\"whose\",\"whether\",\"why\",\"give\",\"provide\",\"describe\"]\n",
    "result_token=[]\n",
    "for tokens in question_tokens:\n",
    "   if tokens not in selected_quesion:\n",
    "        result_token.append(tokens)\n",
    "target_words=\" \".join(result_token)\n",
    "print(target_words)\n",
    "\n",
    "# Divide the large context into chunks.\n",
    "chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "answers = []\n",
    "count=0\n",
    "# Iterate through each chunk and get the answer using the transformer model.\n",
    "for chunk in chunks:\n",
    "    # Combine the chunk with the question.\n",
    "    # count+=1\n",
    "    # print(\"loop:\",count)\n",
    "    # print(chunk)\n",
    "    #input_text = question + \" \" + \" \".join(chunk)\n",
    "    result = qa_pipeline(question=question, context=chunk)\n",
    "\n",
    "    # Extract answer and confidence score\n",
    "    exact_answer = result['answer']\n",
    "    print(\"exact_answer\",exact_answer)\n",
    "    confidence_score = result['score']\n",
    "    print(\"confidence_score\",confidence_score)\n",
    "    # Tokenize the combined text.\n",
    "    inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "#print(len(input_ids))\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Get the start and end positions of the answer using the model.\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Find the answer span within the chunk.\n",
    "      # +1 to include the end token.\n",
    "\n",
    "    # Convert token indices back to answer text.\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "   \n",
    "        \n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "    #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "    print (answer) \n",
    "    def word_search(target_words):\n",
    "        import re\n",
    "        lines = re.split(r'[.!?]', answer)\n",
    "    \n",
    "    # Create an empty list to store the sentences/phrases containing the target word\n",
    "        lines_with_word = []\n",
    "    \n",
    "    # Loop through each sentence/phrase and check if it contains the target word\n",
    "        for line in lines:\n",
    "            if target_words in line:\n",
    "                lines_with_word.append(line.strip())\n",
    "        if(len(lines_with_word)==0):\n",
    "             return False\n",
    "        return True\n",
    "\n",
    "    if(confidence_score>=0.28 or  word_search(target_words)):\n",
    "        \n",
    "        answers.append(answer)\n",
    "    \n",
    "\n",
    "\n",
    "final_answer = answers\n",
    "\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 512\n",
      "412 924\n",
      "824 1336\n",
      "1236 1748\n",
      "1648 2160\n",
      "2060 2572\n",
      "2472 2984\n",
      "2884 3396\n",
      "3296 3808\n",
      "3708 4220\n",
      "4120 4632\n",
      "4532 5044\n",
      "4944 5456\n",
      "5356 5868\n",
      "5768 6280\n",
      "6180 6692\n",
      "6592 7104\n",
      "7004 7516\n",
      "7416 7928\n",
      "7828 8340\n",
      "8240 8752\n",
      "8652 9164\n",
      "9064 9576\n",
      "9476 9988\n",
      "9888 10400\n",
      "10300 10812\n",
      "10712 11224\n",
      "11124 11238\n",
      "exact_answer Stream Learning module\n",
      "confidence_score 0.00019515212625265121\n",
      "\n",
      "exact_answer valve body assembly\n",
      "confidence_score 0.03292633220553398\n",
      "internship projects : after successful completion of level - 2, interns will be allocated projects based on domain preference, level - 2 performance and interaction with the mentors. final selection and project allocation based on the level 2 performance and preferences these are full - time internships and require 48 hours per week, the robot becomes the third arm of the human operator. this new form of collaboration opens up previously inconceivable possibilities for the smart factory of the future. as collaborative robots operate without physical safeguards, they have to permanently calculate the risk of colliding with humans, constantly checking this via the robot controller. collaborative robots works hand in hand with the operator, thereby enabling him to work more efficiently, more ergonomically, more precisely and with greater concentration. as a robot that can genuinely be deployed universally, it is defining new standards on the road to the fourth industrial revolution. collaborative robots can be programmed onsite by the employees and can be quickly re - tasked to do multiple jobs quickly. they are lightweight and can be moved around easily in the production facility.\n",
      "exact_answer 1.Conveyor station\n",
      "confidence_score 0.21818815171718597\n",
      "\n",
      "exact_answer Work Station 1\n",
      "confidence_score 0.48241326212882996\n",
      "axis kuka robot performs all the motion operation in the cell. 7th axis rotates the valve body during assembly and inspection. 4. qr code scanner : - qr code scanner performs the inventory check as it scans the qr code present on body. after scanning a body, plc gets the data of that particular body and its location on the tray\n",
      "exact_answer Multi Process\n",
      "confidence_score 0.22720621526241302\n",
      "1 and raising an alert, the user then using hololens 2 will follow the steps to resolve the error, iiotaugmented reality, the multi - material additive manufacturing machine is a versatile machine made by hyrel 3d and ams. it is not ' just a 3d printer '. it is a large format, rapid prototyping, research, manufacturing and educational platform. this 3d printer is customizable on various levels : build volume, print bed, extruder, and more. it is equipped with the capacity to attach 5 tool heads simulatneously. we have tool heads for printing common fdm filaments ( pla, abs, pc, peek ), clays, biologicals, flexibles, uv - curables, rtv silicones, etc. it is highly evolutive and also offers options for 4th and 5th axes, pcb milling tool, 3 - phase machining tool and co2 or diode lasers ( laser cutting )., smart manufacturing training kit - >, cyber physical assembly line demonstrates smart manufacturing and comes with different functionalities. it includes the custom order processing, valve body, spool, solenoid, connector, valve functioning testing, packaging, inkjet printing. it consists of three work stations and one mprc. workstation 1 : it is also known as raw part storage, part loading and quality check. it uses the rockwell plc. it stores product and do pick & place arrangement for mounting the product on pallet. workstation 2 : it is also known as axisymmetric part storage quality check and inspection work station. it uses b & r plc. it stores spool and do pick and place arrangement for inserting the spool in valve body. it uses proximity sensor for inventory check. workstation 3 : it is also known as prismatic part assembly and screwing workstation. it uses the mitsubishi plc. it stores all prismatic parts. it is used to place and tighten all the parts to valve body. multi process robotic cell ( mprc ) : click here to know more. conclusion : all the station can run in auto / manual mode. this is how the cyber physical assembly line works. there are features in the line such as smart sensing, machine to machine communication, smart dashboard, remote monitoring, alerts and notifications on email, safety, remote maintenance and augmented reality., simulation & testing services, prototyping\n",
      "exact_answer cell phones\n",
      "confidence_score 0.00027875439263880253\n",
      "marker - based systems : this technology uses physical - world symbols as a reference point for computer graphics to be overlaid. for example, a 2 - dimensional printed marker is placed in front of a webcam. the computer then interprets this symbol to overlay an on - screen graphic as if it were directly on top of the marker in the physical world. there have been several notable uses, most commonly in marketing markerless systems : by contrast, this technological approach has given rise to ‘ mobile augmented reality ’, denoting use of the technology with devices such as smartphones and tablets\n",
      "exact_answer Robotic Welding\n",
      "confidence_score 0.22345520555973053\n",
      "work error reduction : ar applications can reduce errors made by workers in various occupational tasks. whether the error is caused by too little information, too much information, or poor quality information, ar applications place the right information and instructions at the location of the work task. 4. workforce multiplier : ar applications are a workforce multiplier in two ways. first, training resources are more effective and efficient. training hours can be reduced because ar applications can include video instructions on repair / replacement tasks overlaid on the machines themselves. second, workers can do more by themselves versus sending multiple workers or truck rolls to address the same problem or work task. 5. safety : ar applications can also improve the safety of a work task. for instance, ar applications can include not only written instructions for removing or replacing a part on a machine, but can also include visual instructions. this assistance avoids unnecessary and possibly unsafe interaction with the machine or object., the mobile collaborative robot ( mcr ) is developed to achieve autonomous material transportation within the cyber physical factory. the mcr consists of a tm5m700 collaborative robot mounted on top of an addverb automated mobile robot ( amr ). the amr uses a lidar and two depth cameras to navigate using natural navigation. it has a payload of 150 kg. the amr runs on robot operating system ( ros ). the collaborative robot mounted on top of the amr has a camera on it\n",
      "exact_answer Smart Lathe\n",
      "confidence_score 0.2624082565307617\n",
      "all the 12 technology streams will be covered., the domain of smart manufacturing is expected to open up a new opportunity in industrial consulting, especially with regard to identification and removal of bottlenecks in current operations.\n",
      "exact_answer Smart Lathe Machine , Robotic Welding Cell\n",
      "confidence_score 0.009639836847782135\n",
      "cyber - physical systems provide the basis the creation of an internet of things ( iot ) which makes smart services and products possible. a cyber - physical system ( cps ) is a thing in the internet of things. it is a combination of mechanical, electronic and software components that communicate via a data infrastructure such as the internet, react flexibly to external influences and exchange data with information systems and other cpss. in manufacturing facilities, cyber - physical systems will communicate with intelligent, networked industrial production and logistics units - also known as cyber - physical production systems ( cpps )\n",
      "exact_answer .\n",
      "confidence_score 4.3796347881652764e-08\n",
      "smart kits. the application uses a pre - defined image target and superimposes a 3d cad of the smart manufacturing training kits. the user can visualize the smart kit without having access to the physical kit. he / she can click on the individual parts to display information about them\n",
      "exact_answer Electrical Connections of a PLC\n",
      "confidence_score 0.0010284442687407136\n",
      "\n",
      "exact_answer Workstation 2\n",
      "confidence_score 0.02561892941594124\n",
      "workstation 1 is one of the assembly stations. this station stores the raw part and inspects the parts using qr code scanner and vision sensor. valve body is transferred from one station to another in a pallet\n",
      "exact_answer single-axis rotary index\n",
      "confidence_score 0.10045157372951508\n",
      "workstation 3 is one of the assembly stations. this station assembles all the sub parts of cotter joint assembly depending on the type of socket body approaching the station with the help of rfid. the gripper picks and places the cotter to engage socket and spigot. plc used : mitsubishi melsec r - series ( rack type ) software used : gx works 3 programming : ladder logic programming, safety sensors, pneumatics and 7 axes motion programming., automationaugmented realityiiotmachine learningdigital twin, 01demonstration & training, 04flexible assembling, 02customer order processing, 03realtime dashboard, an ar application to show information about fsm smart manufacturing kits an ar application that gives the user a menu with 10 options for each of the fsm smart manufacturing kit. the user can visualize all 3 components, the hmi, the electronic kit, and the mechanism kit. the user can click on the different parts and get to know about the parts. the user can also initiate the cad explode view animation., an augmented reality application to provide self - guided training on the fsm plc kits. the user can scan the thingmark on the kit to load up the experience or can fsm plc kit parts introduction 2 use model target detection by aligning the on - screen guide with the real hardware and then click on the parts to know about them, this course is completely designed on the codesys platform using soft - plc. throughout this self - paced online course, participants will be trained on the basics of ladder logic programming, visualization of a human - machine interface for controlling the program parameters, and motion programming with a basic linear axis motion to rotary of single - axis motion\n",
      "exact_answer single-axis rotary index\n",
      "confidence_score 0.003104008501395583\n",
      "all these kits demonstrate the industry 4. 0 technologies in the best possible way. these were designed, manufactured and integrated in fsm. modules / trainings covered in these kits : plc programming, network protocols\n",
      "exact_answer Station 3\n",
      "confidence_score 0.07628076523542404\n",
      "station 1 : it has a rfid controller used to read and write the tag values of a product. it communicates with io link master ( present in plc trainer kit ) and io link master communicates the data with the plc. so, rfid operation and use case is demonstrated.\n",
      "exact_answer Station 3\n",
      "confidence_score 0.0008103233412839472\n",
      "station 4 : this station has a solenoid which is directly connected with the digital output of the plc. extension and retraction of the solenoid is programmed in the plc for this operation. this mechanism kit is used to demonstrate and train motion configuration and programming, vision system, smart sensing, machine learning, augmented reality., programming kit, hmi kit, mechanism kit, it is showing the working of smart manufacturing kit, education & training, device services, research & skill certification, software - >, traditionally, manufacturing has been considered as a process that convert raw materials into physical products in the factories by managing resources with best automation practices available., the digital factory concept offers an integrated approach to enhance the product and production engineering processes and simulation is a key technology within this concept., until now, industrial robots always worked separately from humans in specially safeguarded protected spaces. smart manufacturing has broken down this barrier with a new generation of collaborative industrial robots., a key component in making industry 4. 0 a reality are machines that can produce the desired components faster, more flexibly and more precisely than ever before. also consumers want products that reflect their individuality., augmented reality is the integration of digital information with the user ' s environment in real time. unlike virtual reality, which creates a totally artificial environment, augmented reality uses the existing environment and overlays new information on top of it., networked production and control processes in complex machine environments determine the industrial future and make industry 4. 0 possible in the first place. smart sensors already today support dynamic, real - time - optimized, and self - organized industry processes., being able to assist customers remotely, service technicians could support their customers at any time and from anywhere, without necessarily having to visit the customer site. remote access could also help to better prepare service technicians with the necessary information for their tasks. knowing about the machine or system error in more detail beforehand saves valuable time because required spare parts or other equipment can ordered, prepared and brought along., the world of automation is merging with the it world.\n",
      "exact_answer simulation\n",
      "confidence_score 0.0005545796011574566\n",
      "\n",
      "exact_answer Record\n",
      "confidence_score 0.0005795108154416084\n",
      "\n",
      "exact_answer fsmskill, you will gain access to the Level-1\n",
      "confidence_score 0.0004747099883388728\n",
      "\n",
      "exact_answer pallet ROS\n",
      "confidence_score 0.00014126826135907322\n",
      "\n",
      "exact_answer Welding\n",
      "confidence_score 0.07730977237224579\n",
      "after reviewing all these projects, the top 10 interns got awarded the best project award in their domain and a cash prize of 5000., the term safety denotes the functional safety of machinery or, put another way, the protection of people and the environment against threats that can proceed from machinery. safety demands that residual risks arising from a plant or machine do not exceed acceptable values. this includes hazards to the plant environment ( e. g. environmental damage ) as well as hazards within the plant or machine ( e. g. people inside the plant ). one option for the worst case is simply to interrupt the energy supply straight away and bring the machine to a hard stop. the traditional way of providing scope for this is by means of special safety wiring and components such as safety relays. because this approach is very much hardware - based and therefore static, it is not particularly suitable for intelligent manufacturing processes where plant layouts continually need to be changed.\n",
      "exact_answer Load/Unload\n",
      "confidence_score 0.04043000563979149\n",
      "\n",
      "exact_answer Multi Process\n",
      "confidence_score 0.7646507024765015\n",
      "communication - enabled means being able to exchange sensor data with a machine controller or a cloud - based application. thus, for example, sensor parameters are automatically adapted to new production orders within seconds. or a light barrier detects contamination of its optics and reports this directly to the control center. smart sensors generate and receive data and information which goes beyond traditional switching signals or measured process parameters. they therefore enable substantial increases in efficiency, more flexibility, and better planning security for predictive plant maintenance. depending on the requirement, smart sensors cover up to four dimensions of smart sensor technology. 1. enhanced sensing 2. efficient communication 3. diagnostics 4. smart tasks just like smart sensors, smart actuators also have intelligence built into them. some of the smart features possessed by different types of actuators are : open standards : multi - protocol communication interface allow universal operation with diverse, ethernet - based communication protocols web - based commissioning and diagnostics via integrated web server comprehensive access to actuator data ( e. g. torque or power ), via web connector for preventive maintenance or database interfacing and data analysis inbuilt smart sensors for capturing data flexible configuration according to requirement comprehensive condition monitoring for fast identification of critical conditions and comfortable analysis simple connection to higher - level data systems without additional hardware workpiece - dependent parameters setting guaranteeing quality results integrated control system with browser - based operating system allows for information sharing across multi\n",
      "exact_answer Load/Unload\n",
      "confidence_score 0.0320366732776165\n",
      "\n",
      "exact_answer soft-PLC\n",
      "confidence_score 0.000199573376448825\n",
      "with the ability to print on demand, businesses also have the opportunity to eliminate inventory and cut aftermarket lead - times by providing digital spare - parts catalogues that can be printed when needed. the smart companies of the future will be those that have a clear strategy for how and where 3d printing fits within their supply chain and their value chain. they will also understand the business drivers to adoption. from the student ’ s study to the professional designer ’ s office, from the dental laboratory to the jewellery retailer, from the aerospace factory to the hospital basement, 3d printers have become invaluable business tools.\n",
      "exact_answer Stream Learning module\n",
      "confidence_score 0.018441908061504364\n",
      "\n",
      "exact_answer online\n",
      "confidence_score 4.186695514363237e-05\n",
      "\n",
      "exact_answer Smart Factory\n",
      "confidence_score 0.00021580418979283422\n",
      "\n",
      "Final Answer: ['communication - enabled means being able to exchange sensor data with a machine controller or a cloud - based application. thus, for example, sensor parameters are automatically adapted to new production orders within seconds. or a light barrier detects contamination of its optics and reports this directly to the control center. smart sensors generate and receive data and information which goes beyond traditional switching signals or measured process parameters. they therefore enable substantial increases in efficiency, more flexibility, and better planning security for predictive plant maintenance. depending on the requirement, smart sensors cover up to four dimensions of smart sensor technology. 1. enhanced sensing 2. efficient communication 3. diagnostics 4. smart tasks just like smart sensors, smart actuators also have intelligence built into them. some of the smart features possessed by different types of actuators are : open standards : multi - protocol communication interface allow universal operation with diverse, ethernet - based communication protocols web - based commissioning and diagnostics via integrated web server comprehensive access to actuator data ( e. g. torque or power ), via web connector for preventive maintenance or database interfacing and data analysis inbuilt smart sensors for capturing data flexible configuration according to requirement comprehensive condition monitoring for fast identification of critical conditions and comfortable analysis simple connection to higher - level data systems without additional hardware workpiece - dependent parameters setting guaranteeing quality results integrated control system with browser - based operating system allows for information sharing across multi']\n"
     ]
    }
   ],
   "source": [
    "question=\"What Conveyer station in robotic cell?\"\n",
    "question_tokens = tokenizer(question, return_tensors='pt')\n",
    "question_tokens = tokenizer.tokenize(question, return_tensors='pt')\n",
    "selected_quesion=[\"[CLS]\", \"what\" , \"is\" , \"explain\" ,\"[SEP]\",\"?\",\".\",\"where\",\n",
    "\"how\",\"when\",\"which\",\"who\",\"whom\",\"whose\",\"whether\",\"why\",\"give\",\"provide\",\"describe\"]\n",
    "result_token=[]\n",
    "for tokens in question_tokens:\n",
    "   if tokens not in selected_quesion:\n",
    "        result_token.append(tokens)\n",
    "target_words=\" \".join(result_token)\n",
    "print(target_words)\n",
    "\n",
    "# Divide the large context into chunks.\n",
    "chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "answers = []\n",
    "count=0\n",
    "# Iterate through each chunk and get the answer using the transformer model.\n",
    "for chunk in chunks:\n",
    "    # Combine the chunk with the question.\n",
    "    # count+=1\n",
    "    # print(\"loop:\",count)\n",
    "    # print(chunk)\n",
    "    #input_text = question + \" \" + \" \".join(chunk)\n",
    "    result = qa_pipeline(question=question, context=chunk)\n",
    "\n",
    "    # Extract answer and confidence score\n",
    "    exact_answer = result['answer']\n",
    "    print(\"exact_answer\",exact_answer)\n",
    "    confidence_score = result['score']\n",
    "    print(\"confidence_score\",confidence_score)\n",
    "    # Tokenize the combined text.\n",
    "    inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "#print(len(input_ids))\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Get the start and end positions of the answer using the model.\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Find the answer span within the chunk.\n",
    "      # +1 to include the end token.\n",
    "\n",
    "    # Convert token indices back to answer text.\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "   \n",
    "        \n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "    #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "    print (answer) \n",
    "    def word_search(target_words):\n",
    "        import re\n",
    "        lines = re.split(r'[.!?]', answer)\n",
    "    \n",
    "    # Create an empty list to store the sentences/phrases containing the target word\n",
    "        lines_with_word = []\n",
    "    \n",
    "    # Loop through each sentence/phrase and check if it contains the target word\n",
    "        for line in lines:\n",
    "            if target_words in line:\n",
    "                lines_with_word.append(line.strip())\n",
    "        if(len(lines_with_word)==0):\n",
    "             return False\n",
    "        return True\n",
    "\n",
    "    if(confidence_score>=0.28 or  word_search(target_words)):\n",
    "        \n",
    "        answers.append(answer)\n",
    "    \n",
    "\n",
    "\n",
    "final_answer = answers\n",
    "\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 512\n",
      "412 924\n",
      "824 1336\n",
      "1236 1748\n",
      "1648 2160\n",
      "2060 2572\n",
      "2472 2984\n",
      "2884 3396\n",
      "3296 3808\n",
      "3708 4220\n",
      "4120 4632\n",
      "4532 5044\n",
      "4944 5456\n",
      "5356 5868\n",
      "5768 6280\n",
      "6180 6692\n",
      "6592 7104\n",
      "7004 7516\n",
      "7416 7928\n",
      "7828 8340\n",
      "8240 8752\n",
      "8652 9164\n",
      "9064 9576\n",
      "9476 9988\n",
      "9888 10400\n",
      "10300 10812\n",
      "10712 11224\n",
      "11124 11238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact_answer Project Based Learning\n",
      "confidence_score 0.6857701539993286\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m# Iterate through each chunk and get the answer using the transformer model.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunks:\n\u001b[0;32m     11\u001b[0m     \u001b[39m# Combine the chunk with the question.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[39m# count+=1\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[39m# print(\"loop:\",count)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[39m# print(chunk)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[39m#input_text = question + \" \" + \" \".join(chunk)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     result \u001b[39m=\u001b[39m qa_pipeline(question\u001b[39m=\u001b[39;49mquestion, context\u001b[39m=\u001b[39;49mchunk)\n\u001b[0;32m     18\u001b[0m     \u001b[39m# Extract answer and confidence score\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     exact_answer \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:390\u001b[0m, in \u001b[0;36mQuestionAnsweringPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m examples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args_parser(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(examples, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(examples) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(examples[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    391\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(examples, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:1112\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1111\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ChunkPipeline):\n\u001b[1;32m-> 1112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[0;32m   1113\u001b[0m         \u001b[39miter\u001b[39;49m(\n\u001b[0;32m   1114\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_iterator(\n\u001b[0;32m   1115\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1116\u001b[0m             )\n\u001b[0;32m   1117\u001b[0m         )\n\u001b[0;32m   1118\u001b[0m     )\n\u001b[0;32m   1119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[39mreturn\u001b[39;00m accumulator\n\u001b[0;32m    265\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last:\n\u001b[1;32m--> 266\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(\u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed, torch\u001b[39m.\u001b[39mTensor):\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:1026\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1024\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1025\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m-> 1026\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[0;32m   1027\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1028\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:513\u001b[0m, in \u001b[0;36mQuestionAnsweringPipeline._forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m example \u001b[39m=\u001b[39m inputs[\u001b[39m\"\u001b[39m\u001b[39mexample\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    512\u001b[0m model_inputs \u001b[39m=\u001b[39m {k: inputs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mmodel_input_names}\n\u001b[1;32m--> 513\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs)\n\u001b[0;32m    514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    515\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m\"\u001b[39m: output[\u001b[39m\"\u001b[39m\u001b[39mstart_logits\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m: output[\u001b[39m\"\u001b[39m\u001b[39mend_logits\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mexample\u001b[39m\u001b[39m\"\u001b[39m: example, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs}\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1848\u001b[0m, in \u001b[0;36mBertForQuestionAnswering.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1836\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1837\u001b[0m \u001b[39mstart_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1838\u001b[0m \u001b[39m    Labels for position (index) of the start of the labelled span for computing the token classification loss.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1844\u001b[0m \u001b[39m    are not taken into account for computing the loss.\u001b[39;00m\n\u001b[0;32m   1845\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1846\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1848\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1849\u001b[0m     input_ids,\n\u001b[0;32m   1850\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1851\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1852\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1853\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1854\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1855\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1856\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1857\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1858\u001b[0m )\n\u001b[0;32m   1860\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1862\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqa_outputs(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[1;32m-> 1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1021\u001b[0m     embedding_output,\n\u001b[0;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1023\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1024\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1025\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1026\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1027\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1028\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1029\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1031\u001b[0m )\n\u001b[0;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1033\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    603\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    608\u001b[0m     )\n\u001b[0;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    611\u001b[0m         hidden_states,\n\u001b[0;32m    612\u001b[0m         attention_mask,\n\u001b[0;32m    613\u001b[0m         layer_head_mask,\n\u001b[0;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    616\u001b[0m         past_key_value,\n\u001b[0;32m    617\u001b[0m         output_attentions,\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    493\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    494\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    496\u001b[0m         hidden_states,\n\u001b[0;32m    497\u001b[0m         attention_mask,\n\u001b[0;32m    498\u001b[0m         head_mask,\n\u001b[0;32m    499\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    500\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    501\u001b[0m     )\n\u001b[0;32m    502\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    504\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:425\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    416\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    417\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    424\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 425\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    426\u001b[0m         hidden_states,\n\u001b[0;32m    427\u001b[0m         attention_mask,\n\u001b[0;32m    428\u001b[0m         head_mask,\n\u001b[0;32m    429\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    430\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    431\u001b[0m         past_key_value,\n\u001b[0;32m    432\u001b[0m         output_attentions,\n\u001b[0;32m    433\u001b[0m     )\n\u001b[0;32m    434\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[0;32m    435\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:307\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey(hidden_states))\n\u001b[1;32m--> 307\u001b[0m     value_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue(hidden_states))\n\u001b[0;32m    309\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n\u001b[0;32m    311\u001b[0m use_cache \u001b[39m=\u001b[39m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NIKITA_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "question=\"What is the process for Internship 2023?\"\n",
    "question_tokens = tokenizer(question, return_tensors='pt')\n",
    "question_tokens = tokenizer.tokenize(question, return_tensors='pt')\n",
    "selected_quesion=[\"[CLS]\", \"what\" , \"is\" , \"explain\" ,\"[SEP]\",\"?\",\".\",\"where\",\n",
    "\"how\",\"when\",\"which\",\"who\",\"whom\",\"whose\",\"whether\",\"why\",\"give\",\"provide\",\"describe\"]\n",
    "result_token=[]\n",
    "for tokens in question_tokens:\n",
    "   if tokens not in selected_quesion:\n",
    "        result_token.append(tokens)\n",
    "target_words=\" \".join(result_token)\n",
    "print(target_words)\n",
    "\n",
    "# Divide the large context into chunks.\n",
    "chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "answers = []\n",
    "count=0\n",
    "# Iterate through each chunk and get the answer using the transformer model.\n",
    "for chunk in chunks:\n",
    "    # Combine the chunk with the question.\n",
    "    # count+=1\n",
    "    # print(\"loop:\",count)\n",
    "    # print(chunk)\n",
    "    #input_text = question + \" \" + \" \".join(chunk)\n",
    "    result = qa_pipeline(question=question, context=chunk)\n",
    "\n",
    "    # Extract answer and confidence score\n",
    "    exact_answer = result['answer']\n",
    "    print(\"exact_answer\",exact_answer)\n",
    "    confidence_score = result['score']\n",
    "    print(\"confidence_score\",confidence_score)\n",
    "    # Tokenize the combined text.\n",
    "    inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "#print(len(input_ids))\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Get the start and end positions of the answer using the model.\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Find the answer span within the chunk.\n",
    "      # +1 to include the end token.\n",
    "\n",
    "    # Convert token indices back to answer text.\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "   \n",
    "        \n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "    #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "    print (answer) \n",
    "    def word_search(target_words):\n",
    "        import re\n",
    "        lines = re.split(r'[.!?]', answer)\n",
    "    \n",
    "    # Create an empty list to store the sentences/phrases containing the target word\n",
    "        lines_with_word = []\n",
    "    \n",
    "    # Loop through each sentence/phrase and check if it contains the target word\n",
    "        for line in lines:\n",
    "            if target_words in line:\n",
    "                lines_with_word.append(line.strip())\n",
    "        if(len(lines_with_word)==0):\n",
    "             return False\n",
    "        return True\n",
    "\n",
    "    if(confidence_score>=0.28 or  word_search(target_words)):\n",
    "        \n",
    "        answers.append(answer)\n",
    "    \n",
    "\n",
    "\n",
    "final_answer = answers\n",
    "\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digital twin\n",
      "0 512\n",
      "412 924\n",
      "824 1336\n",
      "1236 1748\n",
      "1648 2160\n",
      "2060 2572\n",
      "2472 2984\n",
      "2884 3396\n",
      "3296 3808\n",
      "3708 4220\n",
      "4120 4632\n",
      "4532 5044\n",
      "4944 5456\n",
      "5356 5868\n",
      "5768 6280\n",
      "6180 6692\n",
      "6592 7104\n",
      "7004 7516\n",
      "7416 7928\n",
      "7828 8340\n",
      "8240 8752\n",
      "8652 9164\n",
      "9064 9576\n",
      "9476 9988\n",
      "9888 10400\n",
      "10300 10812\n",
      "10712 11224\n",
      "11124 11238\n",
      "exact_answer Stream Learning module\n",
      "confidence_score 0.3572915494441986\n",
      "\n",
      "exact_answer Stream Learning module\n",
      "confidence_score 3.203770756954327e-05\n",
      "internship projects : after successful completion of level - 2, interns will be allocated projects based on domain preference, level - 2 performance and interaction with the mentors. final selection and project allocation based on the level 2 performance and preferences these are full - time internships and require 48 hours per week, the robot becomes the third arm of the human operator. this new form of collaboration opens up previously inconceivable possibilities for the smart factory of the future. as collaborative robots operate without physical safeguards, they have to permanently calculate the risk of colliding with humans, constantly checking this via the robot controller. collaborative robots works hand in hand with the operator, thereby enabling him to work more efficiently, more ergonomically, more precisely and with greater concentration. as a robot that can genuinely be deployed universally, it is defining new standards on the road to the fourth industrial revolution. collaborative robots can be programmed onsite by the employees and can be quickly re - tasked to do multiple jobs quickly. they are lightweight and can be moved around easily in the production facility.\n",
      "exact_answer teach pendant\n",
      "confidence_score 0.08260510861873627\n",
      "\n",
      "exact_answer Multimaterial 3D printer\n",
      "confidence_score 0.08019987493753433\n",
      "hex nut assembly station : - hex nut will be placed on the body in this station. 5. packaging station : - assembled valve bodies will be placed in a box and packaging is done. a printing head will print the required details ( type of bodies, number of bodies, date of assembly etc … ) on the box and then the box will be dispatched., 1. siemens plc : - siemens s7 1516 is the master plc in this station and it is responsible for all the programming in the cell. 2. di and do : - 32 - point digital input and 32 point digital output module is connected on the base rack with the plc. 3. 6 axis kuka robot and one axis : - 6 axis kuka robot performs all the motion operation in the cell. 7th axis rotates the valve body during assembly and inspection. 4. qr code scanner : - qr code scanner performs the inventory check as it scans the qr code present on body. after scanning a body, plc gets the data of that particular body and its location on the tray\n",
      "exact_answer Augmented reality\n",
      "confidence_score 0.10733582079410553\n",
      "workstation 2 : it is also known as axisymmetric part storage quality check and inspection work station. it uses b & r plc. it stores spool and do pick and place arrangement for inserting the spool in valve body. it uses proximity sensor for inventory check. workstation 3 : it is also known as prismatic part assembly and screwing workstation. it uses the mitsubishi plc. it stores all prismatic parts. it is used to place and tighten all the parts to valve body. multi process robotic cell ( mprc ) : click here to know more.\n",
      "exact_answer 3D models and videos\n",
      "confidence_score 0.04905922710895538\n",
      "\n",
      "exact_answer TMFlow software\n",
      "confidence_score 0.03579659387469292\n",
      "the mobile collaborative robot ( mcr ) is developed to achieve autonomous material transportation within the cyber physical factory. the mcr consists of a tm5m700 collaborative robot mounted on top of an addverb automated mobile robot ( amr )\n",
      "exact_answer Cyber Physical Assembly Line\n",
      "confidence_score 0.5793643593788147\n",
      "all the 12 technology streams will be covered., the domain of smart manufacturing is expected to open up a new opportunity in industrial consulting, especially with regard to identification and removal of bottlenecks in current operations.\n",
      "exact_answer digital continuity\n",
      "confidence_score 0.08877679705619812\n",
      "cyber - physical system ( cps ) is a thing in the internet of things. it is a combination of mechanical, electronic and software components that communicate via a data infrastructure such as the internet, react flexibly to external influences and exchange data with information systems and other cpss. in manufacturing facilities, cyber - physical systems will communicate with intelligent, networked industrial production and logistics units - also known as cyber - physical production systems ( cpps )\n",
      "exact_answer Cyber Physical System\n",
      "confidence_score 2.8434108116925927e-06\n",
      "\n",
      "exact_answer an AR application that replicates the assembly process of the assembly line\n",
      "confidence_score 0.0001288627681788057\n",
      "\n",
      "exact_answer AutomationAugmented RealityIIoTMachine LearningDigital\n",
      "confidence_score 0.8071109056472778\n",
      "online course where you get to learn different domains of automation like pneumatic, electro - pneumatics, plc programming and electrical connections of a plc. you will create different industrial projects and simulate them on the software during the course tenure. this course is a blend of lecture videos, step - by - step documents, and live sessions to give a complete idea and knowledge of industrial automation to you. by the end of the course, you will be ready to write a plc program for machines with di, do, ai and ao\n",
      "exact_answer AutomationAugmented RealityIIoTMachine LearningDigital\n",
      "confidence_score 0.5513930916786194\n",
      "this course also explains the communication between the edge tier & platform tier using a data aggregator software, an interface that is created between the soft - plc and the data aggregator using opc - ua server and client plug - in. by the end of the course, you will be ready for programming a codesys platform - based hardware with hmi features, programming motion controller with open plc blocks, knowledge of how opc - ua server - client works and how to communicate the data of a soft - plc on codesys driver., basics of codesys software\n",
      "exact_answer PLC\n",
      "confidence_score 0.014050549827516079\n",
      "all these kits demonstrate the industry 4. 0 technologies in the best possible way. these were designed, manufactured and integrated in fsm. modules / trainings covered in these kits : plc programming, network protocols hmi designing data logging dashboard designing, nodered iiot gateways and platforms augmented reality machine learning smart sensing motion configuration and programming vision system, this is one of the kits of the smart manufacturing trainer module. this kit has the brain of the other two kits ( hmi kit and mechanism kit ) as programming is done in this kit. it has a plc for programming and digital inputs / outputs, analog inputs / outputs to connect the required sensors with the plc. it has an io link module to connect the smart sensors, so alongwith the 24vd\n",
      "exact_answer IO Link master\n",
      "confidence_score 0.10208535939455032\n",
      "station 1 : it has a rfid controller used to read and write the tag values of a product. it communicates with io link master ( present in plc trainer kit ) and io link master communicates the data with the plc. so, rfid operation and use case is demonstrated.\n",
      "exact_answer Augmented reality\n",
      "confidence_score 0.05029310658574104\n",
      "\n",
      "exact_answer simulation\n",
      "confidence_score 0.2116871476173401\n",
      "\n",
      "exact_answer evolving digital profile of the historical and current behavior of a physical object or process\n",
      "confidence_score 0.055932749062776566\n",
      "a digital twin enables flexibility in manufacturing to reduce time needed for product design, manufacturing process and system planning and production facility design. a digital twin improves quality and even supports new business models that offer opportunities for small - to mid - size companies to expand and bring more high - tech capability into their shops. digital twins will help all companies become more flexible, reduce time to market, reduce cost, improve quality and increase productivity at all levels of the organization. digital twin business values : 1. quality improve overall quality predict and detect quality trend defects sooner control quality escapes and be able to determine when quality issue started\n",
      "exact_answer use data from sensors that are installed on physical objects\n",
      "confidence_score 0.2048882246017456\n",
      "\n",
      "exact_answer Robotic Welding Cell for process optimization and Predictive Maintenance\n",
      "confidence_score 0.37208038568496704\n",
      "\n",
      "exact_answer Augmented RealityIIoT , 02Realtime Monitoring\n",
      "confidence_score 0.006587831769138575\n",
      "the traditional way of providing scope for this is by means of special safety wiring and components such as safety relays. because this approach is very much hardware - based and therefore static, it is not particularly suitable for intelligent manufacturing processes where plant layouts continually need to be changed.\n",
      "exact_answer Online programming where teach pendant\n",
      "confidence_score 0.00024326234415639192\n",
      "\n",
      "exact_answer PLC also.This cell uses a saftey PLC\n",
      "confidence_score 0.07472829520702362\n",
      "communication - enabled means being able to exchange sensor data with a machine controller or a cloud - based application. thus, for example, sensor parameters are automatically adapted to new production orders within seconds. or a light barrier detects contamination of its optics and reports this directly to the control center. smart sensors generate and receive data and information which goes beyond traditional switching signals or measured process parameters. they therefore enable substantial increases in efficiency, more flexibility, and better planning security for predictive plant maintenance. depending on the requirement, smart sensors cover up to four dimensions of smart sensor technology. 1. enhanced sensing 2. efficient communication 3. diagnostics 4. smart tasks just like smart sensors, smart actuators also have intelligence built into them. some of the smart features possessed by different types of actuators are : open standards : multi - protocol communication interface allow universal operation with diverse, ethernet - based communication protocols web - based commissioning and diagnostics via integrated web server comprehensive access to actuator data ( e. g. torque or power ), via web connector for preventive maintenance or database interfacing and data analysis inbuilt smart sensors for capturing data flexible configuration according to requirement comprehensive condition monitoring for fast identification of critical conditions and comfortable analysis simple connection to higher - level data systems without additional hardware workpiece - dependent parameters setting guaranteeing quality results integrated control system with browser - based operating system allows for information sharing across multi vendor data systems\n",
      "exact_answer three-dimensional digital model\n",
      "confidence_score 0.10464037209749222\n",
      "\n",
      "exact_answer transition 3D information digitally and seamlessly from the virtual world to the real world\n",
      "confidence_score 0.017539365217089653\n",
      "with the ability to print on demand, businesses also have the opportunity to eliminate inventory and cut aftermarket lead - times by providing digital spare - parts catalogues that can be printed when needed. the smart companies of the future will be those that have a clear strategy for how and where 3d printing fits within their supply chain and their value chain. they will also understand the business drivers to adoption. from the student ’ s study to the professional designer ’ s office, from the dental laboratory to the jewellery retailer, from the aerospace factory to the hospital basement, 3d printers have become invaluable business tools.\n",
      "exact_answer JavaScript is disabled in this browser\n",
      "confidence_score 0.008142118342220783\n",
      "\n",
      "exact_answer online\n",
      "confidence_score 0.17600762844085693\n",
      "fsm has been launched specifically for implementation of smart manufacturing in india which it undertakes to do effectively by : awareness building, prototyping, simulation and testing services, consulting services, site integration services, education and training, skills certification, job work and research., director, info @ iafsm. in, fsm is providing an exciting opportunity for 100 individuals to participate in a summer internship program. the program is entirely online and\n",
      "exact_answer .\n",
      "confidence_score 0.08826086670160294\n",
      "\n",
      "Final Answer: ['', 'all the 12 technology streams will be covered., the domain of smart manufacturing is expected to open up a new opportunity in industrial consulting, especially with regard to identification and removal of bottlenecks in current operations.', 'online course where you get to learn different domains of automation like pneumatic, electro - pneumatics, plc programming and electrical connections of a plc. you will create different industrial projects and simulate them on the software during the course tenure. this course is a blend of lecture videos, step - by - step documents, and live sessions to give a complete idea and knowledge of industrial automation to you. by the end of the course, you will be ready to write a plc program for machines with di, do, ai and ao', 'this course also explains the communication between the edge tier & platform tier using a data aggregator software, an interface that is created between the soft - plc and the data aggregator using opc - ua server and client plug - in. by the end of the course, you will be ready for programming a codesys platform - based hardware with hmi features, programming motion controller with open plc blocks, knowledge of how opc - ua server - client works and how to communicate the data of a soft - plc on codesys driver., basics of codesys software', 'a digital twin enables flexibility in manufacturing to reduce time needed for product design, manufacturing process and system planning and production facility design. a digital twin improves quality and even supports new business models that offer opportunities for small - to mid - size companies to expand and bring more high - tech capability into their shops. digital twins will help all companies become more flexible, reduce time to market, reduce cost, improve quality and increase productivity at all levels of the organization. digital twin business values : 1. quality improve overall quality predict and detect quality trend defects sooner control quality escapes and be able to determine when quality issue started', '']\n"
     ]
    }
   ],
   "source": [
    "question=\"What is Digital Twin?\"\n",
    "question_tokens = tokenizer(question, return_tensors='pt')\n",
    "question_tokens = tokenizer.tokenize(question, return_tensors='pt')\n",
    "selected_quesion=[\"[CLS]\", \"what\" , \"is\" , \"explain\" ,\"[SEP]\",\"?\",\".\",\"where\",\n",
    "\"how\",\"when\",\"which\",\"who\",\"whom\",\"whose\",\"whether\",\"why\",\"give\",\"provide\",\"describe\"]\n",
    "result_token=[]\n",
    "for tokens in question_tokens:\n",
    "   if tokens not in selected_quesion:\n",
    "        result_token.append(tokens)\n",
    "target_words=\" \".join(result_token)\n",
    "print(target_words)\n",
    "\n",
    "# Divide the large context into chunks.\n",
    "chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "answers = []\n",
    "count=0\n",
    "# Iterate through each chunk and get the answer using the transformer model.\n",
    "for chunk in chunks:\n",
    "    # Combine the chunk with the question.\n",
    "    # count+=1\n",
    "    # print(\"loop:\",count)\n",
    "    # print(chunk)\n",
    "    #input_text = question + \" \" + \" \".join(chunk)\n",
    "    result = qa_pipeline(question=question, context=chunk)\n",
    "\n",
    "    # Extract answer and confidence score\n",
    "    exact_answer = result['answer']\n",
    "    print(\"exact_answer\",exact_answer)\n",
    "    confidence_score = result['score']\n",
    "    print(\"confidence_score\",confidence_score)\n",
    "    # Tokenize the combined text.\n",
    "    inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "#print(len(input_ids))\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Get the start and end positions of the answer using the model.\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Find the answer span within the chunk.\n",
    "      # +1 to include the end token.\n",
    "\n",
    "    # Convert token indices back to answer text.\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "   \n",
    "        \n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "    #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "    print (answer) \n",
    "    def word_search(target_words):\n",
    "        import re\n",
    "        lines = re.split(r'[.!?]', answer)\n",
    "    \n",
    "    # Create an empty list to store the sentences/phrases containing the target word\n",
    "        lines_with_word = []\n",
    "    \n",
    "    # Loop through each sentence/phrase and check if it contains the target word\n",
    "        for line in lines:\n",
    "            if target_words in line:\n",
    "                lines_with_word.append(line.strip())\n",
    "        if(len(lines_with_word)==0):\n",
    "             return False\n",
    "        return True\n",
    "\n",
    "    if(confidence_score>=0.28 or  word_search(target_words)):\n",
    "        \n",
    "        answers.append(answer)\n",
    "    \n",
    "\n",
    "\n",
    "final_answer = answers\n",
    "\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digital twin\n"
     ]
    }
   ],
   "source": [
    "question=\"What is Digital Twin?\"\n",
    "question_tokens = tokenizer.tokenize(question, return_tensors='pt')\n",
    "selected_quesion=[\"[CLS]\", \"what\" , \"is\" , \"explain\" ,\"[SEP]\",\"?\",\".\",\"where\",\n",
    "\"how\",\"when\",\"which\",\"who\",\"whom\",\"whose\",\"whether\",\"why\",\"give\",\"provide\",\"describe\"]\n",
    "target_words=[]\n",
    "for tokens in question_tokens:\n",
    "   if tokens not in selected_quesion:\n",
    "        target_words.append(tokens)\n",
    "result_token=\" \".join(target_words)\n",
    "print(result_token)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "101, 2054, 2003,4863,102,1029,1012,2073,2129,2043,2029,2040,3183,3005,3251,2339,2507,3073,6235\n",
    "start, what , is , explain ,sep,question mark,dot,where,how,when,which,who,whom,whose,whether,why,give,provide,describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 4863, 3617, 5519, 1029,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is collaborative robot?\"\n",
    "question_tokens = tokenizer(question, return_tensors='pt')\n",
    "question_tokens = tokenizer.tokenize(question, return_tensors='pt')\n",
    "selected_quesion=[\"[CLS]\", \"what\" , \"is\" , \"explain\" ,\"[SEP]\",\"?\",\".\",\"where\",\n",
    "\"how\",\"when\",\"which\",\"who\",\"whom\",\"whose\",\"whether\",\"why\",\"give\",\"provide\",\"describe\"]\n",
    "result_token=[]\n",
    "for tokens in question_tokens:\n",
    "   if tokens not in selected_quesion:\n",
    "        result_token.append(tokens)\n",
    "target_words=\" \".join(result_token)\n",
    "print(target_words)\n",
    "\n",
    "# Divide the large context into chunks.\n",
    "chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "answers = []\n",
    "count=0\n",
    "# Iterate through each chunk and get the answer using the transformer model.\n",
    "for chunk in chunks:\n",
    "    # Combine the chunk with the question.\n",
    "    # count+=1\n",
    "    # print(\"loop:\",count)\n",
    "    # print(chunk)\n",
    "    #input_text = question + \" \" + \" \".join(chunk)\n",
    "    result = qa_pipeline(question=question, context=chunk)\n",
    "\n",
    "    # Extract answer and confidence score\n",
    "    exact_answer = result['answer']\n",
    "    print(\"exact_answer\",exact_answer)\n",
    "    confidence_score = result['score']\n",
    "    print(\"confidence_score\",confidence_score)\n",
    "    # Tokenize the combined text.\n",
    "    inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "#print(len(input_ids))\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Get the start and end positions of the answer using the model.\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Find the answer span within the chunk.\n",
    "      # +1 to include the end token.\n",
    "\n",
    "    # Convert token indices back to answer text.\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "   \n",
    "        \n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "    #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "    print (answer) \n",
    "    def word_search(target_words):\n",
    "        import re\n",
    "        lines = re.split(r'[.!?]', answer)\n",
    "    \n",
    "    # Create an empty list to store the sentences/phrases containing the target word\n",
    "        lines_with_word = []\n",
    "    \n",
    "    # Loop through each sentence/phrase and check if it contains the target word\n",
    "        for line in lines:\n",
    "            if target_words in line:\n",
    "                lines_with_word.append(line.strip())\n",
    "        if(len(lines_with_word)==0):\n",
    "             return False\n",
    "        return True\n",
    "\n",
    "    if(confidence_score>=0.28 or  word_search(target_words)):\n",
    "        \n",
    "        answers.append(answer)\n",
    "    \n",
    "\n",
    "\n",
    "final_answer = answers\n",
    "\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is Foundation for Smart Manufacturing?\"\n",
    "question_tokens = tokenizer(question, return_tensors='pt')\n",
    "question_tokens = tokenizer.tokenize(question, return_tensors='pt')\n",
    "selected_quesion=[\"[CLS]\", \"what\" , \"is\" , \"explain\" ,\"[SEP]\",\"?\",\".\",\"where\",\n",
    "\"how\",\"when\",\"which\",\"who\",\"whom\",\"whose\",\"whether\",\"why\",\"give\",\"provide\",\"describe\"]\n",
    "result_token=[]\n",
    "for tokens in question_tokens:\n",
    "   if tokens not in selected_quesion:\n",
    "        result_token.append(tokens)\n",
    "target_words=\" \".join(result_token)\n",
    "print(target_words)\n",
    "\n",
    "# Divide the large context into chunks.\n",
    "chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "answers = []\n",
    "count=0\n",
    "# Iterate through each chunk and get the answer using the transformer model.\n",
    "for chunk in chunks:\n",
    "    # Combine the chunk with the question.\n",
    "    # count+=1\n",
    "    # print(\"loop:\",count)\n",
    "    # print(chunk)\n",
    "    #input_text = question + \" \" + \" \".join(chunk)\n",
    "    result = qa_pipeline(question=question, context=chunk)\n",
    "\n",
    "    # Extract answer and confidence score\n",
    "    exact_answer = result['answer']\n",
    "    print(\"exact_answer\",exact_answer)\n",
    "    confidence_score = result['score']\n",
    "    print(\"confidence_score\",confidence_score)\n",
    "    # Tokenize the combined text.\n",
    "    inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "#print(len(input_ids))\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Get the start and end positions of the answer using the model.\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Find the answer span within the chunk.\n",
    "      # +1 to include the end token.\n",
    "\n",
    "    # Convert token indices back to answer text.\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "   \n",
    "        \n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "    #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "    print (answer) \n",
    "    def word_search(target_words):\n",
    "        import re\n",
    "        lines = re.split(r'[.!?]', answer)\n",
    "    \n",
    "    # Create an empty list to store the sentences/phrases containing the target word\n",
    "        lines_with_word = []\n",
    "    \n",
    "    # Loop through each sentence/phrase and check if it contains the target word\n",
    "        for line in lines:\n",
    "            if target_words in line:\n",
    "                lines_with_word.append(line.strip())\n",
    "        if(len(lines_with_word)==0):\n",
    "             return False\n",
    "        return True\n",
    "\n",
    "    if(confidence_score>=0.28 or  word_search(target_words)):\n",
    "        \n",
    "        answers.append(answer)\n",
    "    \n",
    "\n",
    "\n",
    "final_answer = answers\n",
    "\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is the CEFC?\"\n",
    "question_tokens = tokenizer(question, return_tensors='pt')\n",
    "question_tokens = tokenizer.tokenize(question, return_tensors='pt')\n",
    "selected_quesion=[\"[CLS]\", \"what\" , \"is\" , \"explain\" ,\"[SEP]\",\"?\",\".\",\"where\",\n",
    "\"how\",\"when\",\"which\",\"who\",\"whom\",\"whose\",\"whether\",\"why\",\"give\",\"provide\",\"describe\"]\n",
    "result_token=[]\n",
    "for tokens in question_tokens:\n",
    "   if tokens not in selected_quesion:\n",
    "        result_token.append(tokens)\n",
    "target_words=\" \".join(result_token)\n",
    "print(target_words)\n",
    "\n",
    "# Divide the large context into chunks.\n",
    "chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "answers = []\n",
    "count=0\n",
    "# Iterate through each chunk and get the answer using the transformer model.\n",
    "for chunk in chunks:\n",
    "    # Combine the chunk with the question.\n",
    "    # count+=1\n",
    "    # print(\"loop:\",count)\n",
    "    # print(chunk)\n",
    "    #input_text = question + \" \" + \" \".join(chunk)\n",
    "    result = qa_pipeline(question=question, context=chunk)\n",
    "\n",
    "    # Extract answer and confidence score\n",
    "    exact_answer = result['answer']\n",
    "    print(\"exact_answer\",exact_answer)\n",
    "    confidence_score = result['score']\n",
    "    print(\"confidence_score\",confidence_score)\n",
    "    # Tokenize the combined text.\n",
    "    inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "#print(len(input_ids))\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Get the start and end positions of the answer using the model.\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Find the answer span within the chunk.\n",
    "      # +1 to include the end token.\n",
    "\n",
    "    # Convert token indices back to answer text.\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "   \n",
    "        \n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "    #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "    print (answer) \n",
    "    def word_search(target_words):\n",
    "        import re\n",
    "        lines = re.split(r'[.!?]', answer)\n",
    "    \n",
    "    # Create an empty list to store the sentences/phrases containing the target word\n",
    "        lines_with_word = []\n",
    "    \n",
    "    # Loop through each sentence/phrase and check if it contains the target word\n",
    "        for line in lines:\n",
    "            if target_words in line:\n",
    "                lines_with_word.append(line.strip())\n",
    "        if(len(lines_with_word)==0):\n",
    "             return False\n",
    "        return True\n",
    "\n",
    "    if(confidence_score>=0.28 or  word_search(target_words)):\n",
    "        \n",
    "        answers.append(answer)\n",
    "    \n",
    "\n",
    "\n",
    "final_answer = answers\n",
    "\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Explain FSM?\"\n",
    "question_tokens = tokenizer(question, return_tensors='pt')\n",
    "question_tokens = tokenizer.tokenize(question, return_tensors='pt')\n",
    "selected_quesion=[\"[CLS]\", \"what\" , \"is\" , \"explain\" ,\"[SEP]\",\"?\",\".\",\"where\",\n",
    "\"how\",\"when\",\"which\",\"who\",\"whom\",\"whose\",\"whether\",\"why\",\"give\",\"provide\",\"describe\"]\n",
    "result_token=[]\n",
    "for tokens in question_tokens:\n",
    "   if tokens not in selected_quesion:\n",
    "        result_token.append(tokens)\n",
    "target_words=\" \".join(result_token)\n",
    "print(target_words)\n",
    "\n",
    "# Divide the large context into chunks.\n",
    "chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "answers = []\n",
    "count=0\n",
    "# Iterate through each chunk and get the answer using the transformer model.\n",
    "for chunk in chunks:\n",
    "    # Combine the chunk with the question.\n",
    "    # count+=1\n",
    "    # print(\"loop:\",count)\n",
    "    # print(chunk)\n",
    "    #input_text = question + \" \" + \" \".join(chunk)\n",
    "    result = qa_pipeline(question=question, context=chunk)\n",
    "\n",
    "    # Extract answer and confidence score\n",
    "    exact_answer = result['answer']\n",
    "    print(\"exact_answer\",exact_answer)\n",
    "    confidence_score = result['score']\n",
    "    print(\"confidence_score\",confidence_score)\n",
    "    # Tokenize the combined text.\n",
    "    inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "#print(len(input_ids))\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Get the start and end positions of the answer using the model.\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Find the answer span within the chunk.\n",
    "      # +1 to include the end token.\n",
    "\n",
    "    # Convert token indices back to answer text.\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "   \n",
    "        \n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "    #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "    print (answer) \n",
    "    def word_search(target_words):\n",
    "        import re\n",
    "        lines = re.split(r'[.!?]', answer)\n",
    "    \n",
    "    # Create an empty list to store the sentences/phrases containing the target word\n",
    "        lines_with_word = []\n",
    "    \n",
    "    # Loop through each sentence/phrase and check if it contains the target word\n",
    "        for line in lines:\n",
    "            if target_words in line:\n",
    "                lines_with_word.append(line.strip())\n",
    "        if(len(lines_with_word)==0):\n",
    "             return False\n",
    "        return True\n",
    "\n",
    "    if(confidence_score>=0.28 or  word_search(target_words)):\n",
    "        \n",
    "        answers.append(answer)\n",
    "    \n",
    "\n",
    "\n",
    "final_answer = answers\n",
    "\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer with GUI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr # used Gradio for interface\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers_generator(question):\n",
    "    \n",
    "    question_tokens = tokenizer.tokenize(question, return_tensors='pt')\n",
    "    selected_quesion=[\"[CLS]\", \"what\" , \"is\" , \"explain\" ,\"[SEP]\",\"?\",\".\",\"where\",\n",
    "    \"how\",\"when\",\"which\",\"who\",\"whom\",\"whose\",\"whether\",\"why\",\"give\",\"provide\",\"describe\"]\n",
    "    result_token=[]\n",
    "    for tokens in question_tokens:\n",
    "        if tokens not in selected_quesion:\n",
    "                result_token.append(tokens)\n",
    "        target_words=\" \".join(result_token)\n",
    "        print(target_words)\n",
    "\n",
    "    # Divide the large context into chunks.\n",
    "    chunks = divide_into_chunks(context, chunk_size=512, stride=100)\n",
    "\n",
    "    answers = []\n",
    "    count=0\n",
    "    # Iterate through each chunk and get the answer using the transformer model.\n",
    "    for chunk in chunks:\n",
    "        # Combine the chunk with the question.\n",
    "        # count+=1\n",
    "        # print(\"loop:\",count)\n",
    "        # print(chunk)\n",
    "        #input_text = question + \" \" + \" \".join(chunk)\n",
    "        result = qa_pipeline(question=question, context=chunk)\n",
    "\n",
    "        # Extract answer and confidence score\n",
    "        exact_answer = result['answer']\n",
    "        print(\"exact_answer\",exact_answer)\n",
    "        confidence_score = result['score']\n",
    "        print(\"confidence_score\",confidence_score)\n",
    "        # Tokenize the combined text.\n",
    "        inputs = tokenizer.encode_plus(question,chunk, return_tensors='pt',truncation=True, max_length=512,padding=True)\n",
    "        input_ids = inputs['input_ids']\n",
    "    #print(len(input_ids))\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        # Get the start and end positions of the answer using the model.\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Find the answer span within the chunk.\n",
    "        # +1 to include the end token.\n",
    "\n",
    "        # Convert token indices back to answer text.\n",
    "        answer_start = torch.argmax(output.start_logits)\n",
    "        answer_end = torch.argmax(output.end_logits)\n",
    "    \n",
    "            \n",
    "        \n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end + 1]))    \n",
    "        #answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx])\n",
    "        print (answer) \n",
    "        def word_search(target_words):\n",
    "            import re\n",
    "            lines = re.split(r'[.!?]', answer)\n",
    "        \n",
    "        # Create an empty list to store the sentences/phrases containing the target word\n",
    "            lines_with_word = []\n",
    "        \n",
    "        # Loop through each sentence/phrase and check if it contains the target word\n",
    "            for line in lines:\n",
    "                if target_words in line:\n",
    "                    lines_with_word.append(line.strip())\n",
    "            if(len(lines_with_word)==0):\n",
    "                return False\n",
    "            return True\n",
    "\n",
    "        if(confidence_score>=0.28 or  word_search(target_words)):\n",
    "            \n",
    "            answers.append(answer)\n",
    "        \n",
    "\n",
    "    return answers\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message,history):\n",
    "    history=history or []\n",
    "    message=message.lower()\n",
    "    responses=[]\n",
    "    if message.startswith(\"hi\"):\n",
    "        response=\"hello\"\n",
    "    elif message.startswith(\"hello\"):\n",
    "        response=\"hi\"\n",
    "    elif message.startswith(\"how are you?\"):\n",
    "         response=\"I'm fine, what about you?\"\n",
    "\n",
    "    else:\n",
    "         responses=answers_generator(message)\n",
    "         response= \" \".join(responses)\n",
    "    history.append((message,response))\n",
    "    return response\n",
    "#chatbot=gr.Chatbot().style(color_map=(\"green\",\"blue\"))\n",
    "interface=gr.ChatInterface(fn=chat)\n",
    "\n",
    "   #,allow_flagging=\"never\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interface=gr.Interface(fn=answers_generator,inputs=\"text\",outputs=\"text\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
